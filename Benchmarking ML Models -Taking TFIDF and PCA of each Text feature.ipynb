{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook reads text data from data extract created from FSHA Forms and runs predictive Models to predict the value 'Is there a potential for microbial growth in the product?' , based on the Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all necessary modules\n",
    "from __future__ import print_function\n",
    "import logging\n",
    "from optparse import OptionParser\n",
    "import sys\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import nltk\n",
    "import string\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import re\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from scipy import signal\n",
    "import random\n",
    "import string\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_selection import f_classif\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.svm import SVC \n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB,BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.utils.extmath import density\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import models\n",
    "from tensorflow.python.keras import initializers\n",
    "from tensorflow.python.keras import regularizers\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.layers import Dropout\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File name and other important parameters like ngram_range set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#These parameters will be input from command line\n",
    "ngram_range_inp=(1,2)\n",
    "filename = \"C:/Pepsico/FSHA RPA - 25 July 2019 - 209Files.xlsm\"\n",
    "#n_components = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define reusable modular method for Text Normalization (removal of stopwords, changing to lower case, removal of punctuation etc) - Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exclude = set(string.punctuation) \n",
    "wpt = nltk.WordPunctTokenizer()\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "newStopWords = ['from']\n",
    "stop_words.extend(newStopWords)\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "porter = PorterStemmer()\n",
    "\n",
    "def normalize_document(doc):\n",
    "    # tokenize document\n",
    "    tokens = doc.split()\n",
    "    # remove punctuation from each word\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "    # convert to lower case\n",
    "    lower_tokens = [w.lower() for w in tokens]\n",
    "    #remove spaces\n",
    "    stripped = [w.strip() for w in lower_tokens]\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    words = [word for word in stripped if word.isalpha()]\n",
    "    # filter stopwords out of document\n",
    "    filtered_tokens = [token for token in words if token not in stop_words]\n",
    "    # re-create document from filtered tokens\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "    return doc\n",
    "\n",
    "normalize_corpus = np.vectorize(normalize_document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the data extract file (tabular format with Input data(X) and target(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fsha_data = pd.read_excel(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File Name</th>\n",
       "      <th>projName</th>\n",
       "      <th>accolNumber</th>\n",
       "      <th>PDA_projName</th>\n",
       "      <th>projType</th>\n",
       "      <th>projDesc</th>\n",
       "      <th>formulaNumber</th>\n",
       "      <th>owner</th>\n",
       "      <th>sector</th>\n",
       "      <th>center</th>\n",
       "      <th>...</th>\n",
       "      <th>Table1_Row6_Molluscs</th>\n",
       "      <th>Table1_Row6_Mustard</th>\n",
       "      <th>Table1_Row6_Sesame Seeds</th>\n",
       "      <th>Table1_Row6_Sulphites</th>\n",
       "      <th>Table1_Row1_Moulluscs</th>\n",
       "      <th>Table1_Row2_Moulluscs</th>\n",
       "      <th>Table1_Row3_Moulluscs</th>\n",
       "      <th>Table1_Row4_Moulluscs</th>\n",
       "      <th>Table1_Row5_Moulluscs</th>\n",
       "      <th>Table1_Row6_Moulluscs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#46565 FSHA 5.4.1Star Project G3 v2 + FS input...</td>\n",
       "      <td>S-T3-Star-• POL Star Puff (Chrupki) quality –POL</td>\n",
       "      <td>46565</td>\n",
       "      <td>1SKU Star Puffs Onion\\n2 SKU Star Puffs Cheese...</td>\n",
       "      <td>Brand Refresh</td>\n",
       "      <td>Star Puffs Cheese &amp; STar Hyper Cheese\\nSeasoni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Weronika Baranowska</td>\n",
       "      <td>ESSA</td>\n",
       "      <td>Warsaw</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#53697 FSHA HT Baguette 4 Cheese UA 2.07.19.xlsm</td>\n",
       "      <td>HT Baguette Four Cheese Flavor</td>\n",
       "      <td>53697</td>\n",
       "      <td>Hrusteam Baguette</td>\n",
       "      <td>Refresh</td>\n",
       "      <td>Launch new seasoning 4 Cheese NL-502-352-9 on ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Anna Nikonova</td>\n",
       "      <td>ESSA</td>\n",
       "      <td>Moscow</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#57686 FSHA 5.4.1 Red Caviar  Azov.xlsm</td>\n",
       "      <td>Lay's Caviar IO 2019 RUS Asov</td>\n",
       "      <td>57686</td>\n",
       "      <td>Lay's Red Caviar</td>\n",
       "      <td>Refresh</td>\n",
       "      <td>Idea is to launch I&amp;O flavour under New Year p...</td>\n",
       "      <td>Not provided</td>\n",
       "      <td>Evgeniy Shklovskiy +79163257848</td>\n",
       "      <td>ESSA</td>\n",
       "      <td>Moscow</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#57686 FSHA 5.4.1 Red Caviar Kashira.xlsm</td>\n",
       "      <td>Lay's Caviar IO 2019 RUS Kashira</td>\n",
       "      <td>57686</td>\n",
       "      <td>Lay's Red Caviar</td>\n",
       "      <td>Refresh</td>\n",
       "      <td>Idea is to launch I&amp;O flavour under New Year p...</td>\n",
       "      <td>Not provided</td>\n",
       "      <td>Evgeniy Shklovskiy +79163257848</td>\n",
       "      <td>ESSA</td>\n",
       "      <td>Moscow</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53354-FSHA-In Process 13.12.18.xlsm</td>\n",
       "      <td>Soft and Mild Iberia 2019</td>\n",
       "      <td>53354</td>\n",
       "      <td>Cheetos Palomito</td>\n",
       "      <td>Re Launch</td>\n",
       "      <td>Re Launch of Cheetos Palomitos, Soft Extruded ...</td>\n",
       "      <td>CP2019</td>\n",
       "      <td>David Labrado 07770646572</td>\n",
       "      <td>ESSA</td>\n",
       "      <td>Beaumont Park</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 136 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           File Name  \\\n",
       "0  #46565 FSHA 5.4.1Star Project G3 v2 + FS input...   \n",
       "1   #53697 FSHA HT Baguette 4 Cheese UA 2.07.19.xlsm   \n",
       "2            #57686 FSHA 5.4.1 Red Caviar  Azov.xlsm   \n",
       "3          #57686 FSHA 5.4.1 Red Caviar Kashira.xlsm   \n",
       "4                53354-FSHA-In Process 13.12.18.xlsm   \n",
       "\n",
       "                                            projName accolNumber  \\\n",
       "0  S-T3-Star-• POL Star Puff (Chrupki) quality –POL        46565   \n",
       "1                     HT Baguette Four Cheese Flavor       53697   \n",
       "2                      Lay's Caviar IO 2019 RUS Asov       57686   \n",
       "3                   Lay's Caviar IO 2019 RUS Kashira       57686   \n",
       "4                          Soft and Mild Iberia 2019       53354   \n",
       "\n",
       "                                        PDA_projName       projType  \\\n",
       "0  1SKU Star Puffs Onion\\n2 SKU Star Puffs Cheese...  Brand Refresh   \n",
       "1                                  Hrusteam Baguette        Refresh   \n",
       "2                                  Lay's Red Caviar         Refresh   \n",
       "3                                  Lay's Red Caviar         Refresh   \n",
       "4                                   Cheetos Palomito      Re Launch   \n",
       "\n",
       "                                            projDesc formulaNumber  \\\n",
       "0  Star Puffs Cheese & STar Hyper Cheese\\nSeasoni...           NaN   \n",
       "1  Launch new seasoning 4 Cheese NL-502-352-9 on ...           NaN   \n",
       "2  Idea is to launch I&O flavour under New Year p...  Not provided   \n",
       "3  Idea is to launch I&O flavour under New Year p...  Not provided   \n",
       "4  Re Launch of Cheetos Palomitos, Soft Extruded ...        CP2019   \n",
       "\n",
       "                             owner sector         center  \\\n",
       "0              Weronika Baranowska   ESSA         Warsaw   \n",
       "1                    Anna Nikonova   ESSA         Moscow   \n",
       "2  Evgeniy Shklovskiy +79163257848   ESSA         Moscow   \n",
       "3  Evgeniy Shklovskiy +79163257848   ESSA         Moscow   \n",
       "4        David Labrado 07770646572   ESSA  Beaumont Park   \n",
       "\n",
       "           ...          Table1_Row6_Molluscs Table1_Row6_Mustard  \\\n",
       "0          ...                           0.0                   1   \n",
       "1          ...                           0.0                   1   \n",
       "2          ...                           0.0                   0   \n",
       "3          ...                           0.0                   0   \n",
       "4          ...                           0.0                   0   \n",
       "\n",
       "  Table1_Row6_Sesame Seeds Table1_Row6_Sulphites Table1_Row1_Moulluscs  \\\n",
       "0                        0                     0                   NaN   \n",
       "1                        0                     0                   NaN   \n",
       "2                        0                     0                   NaN   \n",
       "3                        0                     0                   NaN   \n",
       "4                        0                     0                   NaN   \n",
       "\n",
       "  Table1_Row2_Moulluscs Table1_Row3_Moulluscs Table1_Row4_Moulluscs  \\\n",
       "0                   NaN                   NaN                   NaN   \n",
       "1                   NaN                   NaN                   NaN   \n",
       "2                   NaN                   NaN                   NaN   \n",
       "3                   NaN                   NaN                   NaN   \n",
       "4                   NaN                   NaN                   NaN   \n",
       "\n",
       "  Table1_Row5_Moulluscs Table1_Row6_Moulluscs  \n",
       "0                   NaN                   NaN  \n",
       "1                   NaN                   NaN  \n",
       "2                   NaN                   NaN  \n",
       "3                   NaN                   NaN  \n",
       "4                   NaN                   NaN  \n",
       "\n",
       "[5 rows x 136 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fsha_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['File Name', 'projName', 'accolNumber', 'PDA_projName', 'projType',\n",
       "       'projDesc', 'formulaNumber', 'owner', 'sector', 'center',\n",
       "       ...\n",
       "       'Table1_Row6_Molluscs', 'Table1_Row6_Mustard',\n",
       "       'Table1_Row6_Sesame Seeds', 'Table1_Row6_Sulphites',\n",
       "       'Table1_Row1_Moulluscs', 'Table1_Row2_Moulluscs',\n",
       "       'Table1_Row3_Moulluscs', 'Table1_Row4_Moulluscs',\n",
       "       'Table1_Row5_Moulluscs', 'Table1_Row6_Moulluscs'],\n",
       "      dtype='object', length=136)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fsha_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cookedOrHeated</th>\n",
       "      <th>specificStorage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No</td>\n",
       "      <td>Keep at temperature 25 °C, &lt;75% humidity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no</td>\n",
       "      <td>store the product for no more than 24 hours at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no</td>\n",
       "      <td>store the product for no more than 24 hours at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NO</td>\n",
       "      <td>Ensure the bag is closed and consumed after 2 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cookedOrHeated                                    specificStorage\n",
       "0             No                                                 No\n",
       "1             No           Keep at temperature 25 °C, <75% humidity\n",
       "2             no  store the product for no more than 24 hours at...\n",
       "3             no  store the product for no more than 24 hours at...\n",
       "4             NO  Ensure the bag is closed and consumed after 2 ..."
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check few categorical values\n",
    "fsha_data[['cookedOrHeated', 'specificStorage']][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['File Name', 'projName', 'accolNumber', 'PDA_projName', 'projType',\n",
       "       'projDesc', 'formulaNumber', 'owner', 'sector', 'center',\n",
       "       'Current TSG Stage', 'FSAssessors', 'FSDate', 'WHTD',\n",
       "       'manufacSite', 'PlantTrial', 'packMaterial', 'CPD-ProdName',\n",
       "       'CPD-ProdName-Desc', 'procPlat', 'intrinsicProd', 'preservatives',\n",
       "       'pH', 'waterActivity', 'packaging', 'otherFSA', 'allergens',\n",
       "       'prodStorageDist', 'shelfLife', 'TCG', 'foodSafetyProdClaims',\n",
       "       'cookedOrHeated', 'specificStorage', 'labelingInstructions',\n",
       "       'mishandled'], dtype=object)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fsha_data.columns[:35].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Based on Analysis select the Features (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#selecting set of columns as Features\n",
    "features_df=fsha_data[['preservatives', 'pH', 'waterActivity', 'packaging','otherFSA',\n",
    "            'prodStorageDist', 'foodSafetyProdClaims','targetMarket','allergens','newIngredient','allergensLabeledIMAF']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardize Categorical Columns (those columns which have values in a fixed set, ex: packaging) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prod_storageDist from extract\n",
      "prod_storageDist after transformation\n",
      "0    Keep away from sun\n",
      "1                    NA\n",
      "2                    NA\n",
      "3                    NA\n",
      "4    Keep away from sun\n",
      "Name: prod_storageDist_label, dtype: object\n",
      "packaging from extract\n",
      "packaging after data transformation\n",
      "0                 atmosphere\n",
      "1                        n/a\n",
      "2                   standard\n",
      "3                   standard\n",
      "4    window with clear film.\n",
      "Name: packaging_label, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#ph value label\n",
    "features_df['PH_label']=features_df['pH'].apply(lambda x:re.findall(r'[0-9]+', str(x)) if bool(re.search(r'\\d', str(x))) else str(0))\n",
    "def ph_process(x):\n",
    "    if(len(x)>0):\n",
    "        x = str(x[0])\n",
    "    else:\n",
    "        x = str(x)\n",
    "    return x\n",
    "features_df['PH_label']=features_df['PH_label'].apply(lambda x:ph_process(x))    \n",
    "\n",
    "\"\"\"\n",
    "#'specificStorage'column label\n",
    "print(\"specificStorage from extract\")\n",
    "def specificStorage(x):\n",
    "    x=str(x.lower())\n",
    "    print(x)\n",
    "    if x.__contains__('do not store'):\n",
    "        return 'do not store open product'\n",
    "    elif x.__contains__('ambient')  :\n",
    "        return 'ambient storage'\n",
    "    elif x.__contains__('no')  :\n",
    "        return 'no'\n",
    "    else:\n",
    "        return 'NA'\n",
    "features_df['specificStorage_label']=features_df['specificStorage'].apply(lambda x:specificStorage(x))   \n",
    "print(\"specificStorage after transformation\")\n",
    "print(features_df['specificStorage_label'])\n",
    "\n",
    "#'cookedorHeated'column label\n",
    "def cookedOrHeated(x):\n",
    "    x=str(x.lower())\n",
    "    #print(x)\n",
    "    if x.__contains__('no'):\n",
    "        return 'no'\n",
    "    elif x.__contains__('ready to eat')  :\n",
    "        return 'no'\n",
    "    else:\n",
    "        return 'NA'\n",
    "features_df['cookedOrHeated_label']=features_df['cookedOrHeated'].apply(lambda x:cookedOrHeated(x))    \n",
    "#print(features_df['cookedOrHeated_label'])\n",
    "\"\"\"\n",
    "#'prod_storageDist'column label\n",
    "print(\"prod_storageDist from extract\")\n",
    "def prod_storageDist(x):\n",
    "    \n",
    "    x=str(x)\n",
    "    x=x.lower()\n",
    "   # print(x)\n",
    "    if x.__contains__('sun'):\n",
    "            return 'Keep away from sun'\n",
    "    elif x.__contains__('ambient')  :\n",
    "              return 'ambient'\n",
    "    elif x.__contains__('rte'):\n",
    "        return 'RTE'\n",
    "    else:\n",
    "        return 'NA'\n",
    "features_df['prod_storageDist_label']=features_df['prodStorageDist'].apply(lambda x:prod_storageDist(x))      \n",
    "print(\"prod_storageDist after transformation\")\n",
    "print(features_df['prod_storageDist_label'][:5])\n",
    "\n",
    "#water activity\n",
    "def water_activity(x):\n",
    "    x=str(x)\n",
    "    x=x.lower()\n",
    "    if x.__contains__('low'):\n",
    "        return 'low'\n",
    "    elif x.__contains__('max'):\n",
    "        return 'max'\n",
    "    elif x==str(np.nan):\n",
    "        return 'NA'\n",
    "    else:\n",
    "        return(x)\n",
    "features_df['waterActivity_label']=features_df['waterActivity'].apply(lambda x:water_activity(x))                                                              \n",
    " \n",
    "#packaging'\n",
    "print(\"packaging from extract\")\n",
    "def packaging(x):\n",
    "    x=str(x)\n",
    "    x=x.lower()\n",
    "    #print(x)\n",
    "    if x.__contains__('no') and x.__contains__('nitrogen'):\n",
    "        return 'no nitrogen'\n",
    "    elif x.__contains__('not') and x.__contains__('n2'):\n",
    "        return 'no nitrogen'\n",
    "    elif x.__contains__('nitrogen') and not x.__contains__('no'):\n",
    "        return 'nitrogen'\n",
    "    elif x.__contains__('atmosphere'):\n",
    "        return 'atmosphere'\n",
    "    elif x==str(np.nan):\n",
    "        return 'NA'\n",
    "    else:\n",
    "        return(x)\n",
    "    \n",
    "features_df['packaging_label']=features_df['packaging'].apply(lambda x: packaging(x))  \n",
    "print(\"packaging after data transformation\")\n",
    "print(features_df['packaging_label'][:5])\n",
    "  \n",
    "#'preservatives'\n",
    "def preservatives(x):\n",
    "    x=str(x)\n",
    "    x=x.lower()\n",
    "    if x.__contains__('sodium'):\n",
    "        return 'Not used as preservatives'\n",
    "    elif x.__contains__('not') and x.__contains__('seasoning'):\n",
    "        return 'No Seasoning'\n",
    "    elif bool(re.search('topping|seasoning',x)):\n",
    "        return 'Used in seasoning'\n",
    "    else:\n",
    "        return ('NA')\n",
    "    \n",
    "features_df['preservatives_label']=features_df['preservatives'].apply(lambda x:preservatives(x))\n",
    "\n",
    "#' otherFSA'\n",
    "def otherFSA(x):\n",
    "    x=str(x)\n",
    "    x=x.lower()\n",
    "    if bool(re.search('moisture',x)):\n",
    "        return 'Moisture'\n",
    "    else:\n",
    "        return 'NA'\n",
    "features_df['otherFSA_label']=features_df['otherFSA'].apply(lambda x:otherFSA(x))\n",
    "\n",
    "\n",
    "def foodsafety_prodclaims(x):\n",
    "    x=str(x)\n",
    "    x=x.lower()\n",
    "    if bool(re.search('^claim',x)):\n",
    "        return 'Claims Made'\n",
    "    elif x.__contains__('no claims'):\n",
    "        return 'No Claims Made'\n",
    "    elif x.__contains__('allergen'):\n",
    "        return 'Allergen'\n",
    "    elif bool(re.search('none|n/a',x)):\n",
    "        return 'NA'\n",
    "    else:\n",
    "        return(x)\n",
    "\n",
    "features_df['foodSafety_prodClaims_label']=features_df['foodSafetyProdClaims'].apply(lambda x:foodsafety_prodclaims(x))  \n",
    "\n",
    "#' targetMarket'\n",
    "def targetMarket(x):\n",
    "    x=str(x)\n",
    "    x=x.lower()\n",
    "    if (x.__contains__('choking') or x.__contains__('choke')) and x.__contains__('children'):\n",
    "        return 'Choking hazard for children'\n",
    "    elif x.__contains__('allerg'):\n",
    "        return 'Allergy'\n",
    "    elif x.__contains__('no') and x.__contains__('change'):\n",
    "        return 'no'\n",
    "    else:\n",
    "        return(x)\n",
    "features_df['targetMarket_label']=features_df['targetMarket'].apply(lambda x:targetMarket(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop the raw columns and retain transformed columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_df=features_df.drop(['preservatives', 'pH', 'waterActivity', 'packaging','otherFSA','prodStorageDist','foodSafetyProdClaims','targetMarket'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_str(x):\n",
    "    \n",
    "    x=str(x)\n",
    "    x=x.lower()\n",
    "    return (x)\n",
    " \n",
    "features_df['allergens']=features_df['allergens'].apply(lambda x:conv_str(x))  \n",
    "features_df['newIngredient']=features_df['newIngredient'].apply(lambda x:conv_str(x))  \n",
    "features_df['allergensLabeledIMAF']=features_df['allergensLabeledIMAF'].apply(lambda x:conv_str(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>allergens</th>\n",
       "      <th>newIngredient</th>\n",
       "      <th>allergensLabeledIMAF</th>\n",
       "      <th>PH_label</th>\n",
       "      <th>prod_storageDist_label</th>\n",
       "      <th>waterActivity_label</th>\n",
       "      <th>packaging_label</th>\n",
       "      <th>preservatives_label</th>\n",
       "      <th>otherFSA_label</th>\n",
       "      <th>foodSafety_prodClaims_label</th>\n",
       "      <th>targetMarket_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allergens in seasonings:\\ncq69 vegetable blend...</td>\n",
       "      <td>yes</td>\n",
       "      <td>milk, lactose : milk, lactose</td>\n",
       "      <td>0</td>\n",
       "      <td>Keep away from sun</td>\n",
       "      <td>low</td>\n",
       "      <td>atmosphere</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>Claims Made</td>\n",
       "      <td>Allergy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no new allergen to the line from seasonings. 4...</td>\n",
       "      <td>yes</td>\n",
       "      <td>milk, lactose, sulphites 1ppm, gluten &lt; 3ppm.</td>\n",
       "      <td>0</td>\n",
       "      <td>NA</td>\n",
       "      <td>low</td>\n",
       "      <td>n/a</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>inherent: milk, lactose, wheat, gluten, fish c...</td>\n",
       "      <td>no</td>\n",
       "      <td>milk, lactose, wheat and gluten &lt; 3ppm, sulphi...</td>\n",
       "      <td>0</td>\n",
       "      <td>NA</td>\n",
       "      <td>low</td>\n",
       "      <td>standard</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>Allergy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>inherent :  inherent: milk, lactose, wheat, gl...</td>\n",
       "      <td>no</td>\n",
       "      <td>milk, lactose, wheat and gluten &lt; 3ppm, sulphi...</td>\n",
       "      <td>0</td>\n",
       "      <td>NA</td>\n",
       "      <td>low</td>\n",
       "      <td>standard</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>Allergy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>milk from seasoning.</td>\n",
       "      <td>no</td>\n",
       "      <td>na : na : milk</td>\n",
       "      <td>0</td>\n",
       "      <td>Keep away from sun</td>\n",
       "      <td>low</td>\n",
       "      <td>window with clear film.</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>gluten free?</td>\n",
       "      <td>kids from  4-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           allergens newIngredient  \\\n",
       "0  allergens in seasonings:\\ncq69 vegetable blend...           yes   \n",
       "1  no new allergen to the line from seasonings. 4...           yes   \n",
       "2  inherent: milk, lactose, wheat, gluten, fish c...            no   \n",
       "3  inherent :  inherent: milk, lactose, wheat, gl...            no   \n",
       "4                               milk from seasoning.            no   \n",
       "\n",
       "                                allergensLabeledIMAF PH_label  \\\n",
       "0                      milk, lactose : milk, lactose        0   \n",
       "1      milk, lactose, sulphites 1ppm, gluten < 3ppm.        0   \n",
       "2  milk, lactose, wheat and gluten < 3ppm, sulphi...        0   \n",
       "3  milk, lactose, wheat and gluten < 3ppm, sulphi...        0   \n",
       "4                                     na : na : milk        0   \n",
       "\n",
       "  prod_storageDist_label waterActivity_label          packaging_label  \\\n",
       "0     Keep away from sun                 low               atmosphere   \n",
       "1                     NA                 low                      n/a   \n",
       "2                     NA                 low                 standard   \n",
       "3                     NA                 low                 standard   \n",
       "4     Keep away from sun                 low  window with clear film.   \n",
       "\n",
       "  preservatives_label otherFSA_label foodSafety_prodClaims_label  \\\n",
       "0                  NA             NA                 Claims Made   \n",
       "1                  NA             NA                          NA   \n",
       "2                  NA             NA                          NA   \n",
       "3                  NA             NA                          NA   \n",
       "4                  NA             NA                gluten free?   \n",
       "\n",
       "  targetMarket_label  \n",
       "0            Allergy  \n",
       "1                 no  \n",
       "2            Allergy  \n",
       "3            Allergy  \n",
       "4    kids from  4-10  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    202\n",
       "3      7\n",
       "Name: PH_label, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.PH_label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define reusable code to Vectorize Text column (ex: Allergens) using TF-IDF Vectorizer, after doing Text data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vectorization of text data using TF-IDF Vectorizer\n",
    "\n",
    "# Range (inclusive) of n-gram sizes for tokenizing text.\n",
    "#NGRAM_RANGE \n",
    "\n",
    "# Limit on the number of features. We use the top 20K features.\n",
    "#TOP_K = 20000\n",
    "\n",
    "# Whether text should be split into word or character n-grams.\n",
    "# One of 'word', 'char'.\n",
    "TOKEN_MODE = 'word'\n",
    "\n",
    "# Minimum document/corpus frequency below which a token will be discarded.\n",
    "MIN_DOCUMENT_FREQUENCY = 2\n",
    "\n",
    "# Limit on the length of text sequences. Sequences longer than this\n",
    "# will be truncated.\n",
    "MAX_SEQUENCE_LENGTH = 500\n",
    "\n",
    "\n",
    "def ngram_vectorize(train_texts, train_labels,ngram_range):\n",
    "    \"\"\"Vectorizes texts as ngram vectors.\n",
    "\n",
    "    1 text = 1 tf-idf vector the length of vocabulary of uni-grams + bi-grams.\n",
    "\n",
    "    # Arguments\n",
    "        train_texts: list, training text strings.\n",
    "        train_labels: np.ndarray, training labels.\n",
    "        val_texts: list, validation text strings.\n",
    "\n",
    "    # Returns\n",
    "        x_train, x_val: vectorized training and validation texts\n",
    "    \"\"\"\n",
    "    # Create keyword arguments to pass to the 'tf-idf' vectorizer.\n",
    "    kwargs = {\n",
    "            'ngram_range': ngram_range,  # Use 1-grams + 2-grams.\n",
    "            'dtype': 'int32',\n",
    "            'strip_accents': 'unicode',\n",
    "            'decode_error': 'replace',\n",
    "            'analyzer': TOKEN_MODE,  # Split text into word tokens.\n",
    "            'min_df': MIN_DOCUMENT_FREQUENCY,\n",
    "    }\n",
    "    vectorizer = TfidfVectorizer(**kwargs)\n",
    "\n",
    "    # Learn vocabulary from training texts and vectorize training texts.\n",
    "    x_train = vectorizer.fit_transform(train_texts)\n",
    "\n",
    "    # Select top 'k' of the vectorized features.\n",
    "    #selector = SelectKBest(f_classif, k=min(TOP_K, x_train.shape[1]))\n",
    "    #selector.fit(x_train, train_labels)\n",
    "    #x_train = selector.transform(x_train)\n",
    "\n",
    "    x_train = x_train.astype('float32')\n",
    "    return x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "norm_allergens = normalize_corpus(train_df['allergens'])\n",
    "norm_preservatives = normalize_corpus(train_df['preservatives_label'])\n",
    "norm_pH = normalize_corpus(train_df['PH_label'])\n",
    "norm_waterActivity = normalize_corpus(train_df['waterActivity_label'])\n",
    "norm_packaging = normalize_corpus(train_df['packaging_label'])\n",
    "norm_otherFSA = normalize_corpus(train_df['otherFSA_label'])\n",
    "norm_prodStorageDist = normalize_corpus(train_df['prod_storageDist_label'])\n",
    "norm_foodSafetyProdClaims = normalize_corpus(train_df['foodSafety_prodClaims_label'])\n",
    "norm_targetMarket = normalize_corpus(train_df['targetMarket_label'])\n",
    "norm_newIngredient = normalize_corpus(train_df['newIngredient'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define method to perform Text standardization (categorical data, text data). This method peforms a number of steps. It standardizes and vectorizes Text features, performs  Dimensionality Reduction (PCA), and finally concatenates the columns to create the Feature Matrix (X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "whiten = False\n",
    "random_state = 42\n",
    "svd_solver=\"full\"\n",
    "def preprocess_text(train_df,y,n_comp,n_gram_range):\n",
    "\n",
    "    train_df['newIngredient'] = train_df['newIngredient'].astype('category').cat.codes\n",
    "    train_df['norm_allergens'] = normalize_corpus(train_df['allergens'])\n",
    "    train_df['norm_preservatives'] = normalize_corpus(train_df['preservatives_label'])\n",
    "    train_df['norm_waterActivity'] = normalize_corpus(train_df['waterActivity_label'])\n",
    "    train_df['norm_packaging'] = normalize_corpus(train_df['packaging_label'])\n",
    "    train_df['norm_otherFSA'] = normalize_corpus(train_df['otherFSA_label'])\n",
    "    train_df['norm_prodStorageDist'] = normalize_corpus(train_df['prod_storageDist_label'])\n",
    "    train_df['norm_foodSafetyProdClaims'] = normalize_corpus(train_df['foodSafety_prodClaims_label'])\n",
    "    train_df['norm_targetMarket'] = normalize_corpus(train_df['targetMarket_label'])\n",
    "    train_df = train_df.drop(['allergens','preservatives_label','PH_label','waterActivity_label',\n",
    "                              'packaging_label','otherFSA_label','prod_storageDist_label',\n",
    "                               'foodSafety_prodClaims_label','targetMarket_label'],axis = 1)\n",
    "\n",
    "    train_labels = y\n",
    "    \n",
    "    #Vectorize the text data for each column\n",
    "    x_ngram_allergens = ngram_vectorize(train_df['norm_allergens'], train_labels,n_gram_range).toarray()\n",
    "    x_ngram_preservatives = ngram_vectorize(train_df['norm_preservatives'], train_labels,n_gram_range).toarray()\n",
    "    x_ngram_waterActivity = ngram_vectorize(train_df['norm_waterActivity'], train_labels,n_gram_range).toarray()\n",
    "    x_ngram_packaging = ngram_vectorize(train_df['norm_packaging'],train_labels,n_gram_range).toarray()\n",
    "    x_ngram_otherFSA = ngram_vectorize(train_df['norm_otherFSA'],train_labels,n_gram_range).toarray()\n",
    "    x_ngram_prodStorageDist = ngram_vectorize(train_df['norm_prodStorageDist'],train_labels,n_gram_range).toarray()\n",
    "    x_ngram_foodSafetyProdClaims = ngram_vectorize(train_df['norm_foodSafetyProdClaims'],train_labels,n_gram_range).toarray()\n",
    "    x_ngram_targetMarket = ngram_vectorize(train_df['norm_targetMarket'],train_labels,n_gram_range).toarray()\n",
    "       \n",
    "    #Apply PCA on each column\n",
    "    pca = PCA(n_components=n_comp,svd_solver=svd_solver,whiten=whiten, random_state=42)\n",
    "    x_pca_allergens = pca.fit_transform(x_ngram_allergens)\n",
    "    \n",
    "    x_pca_preservatives = pca.fit_transform(x_ngram_preservatives)\n",
    "    x_pca_waterActivity = pca.fit_transform(x_ngram_waterActivity)\n",
    "    x_pca_packaging = pca.fit_transform(x_ngram_packaging)\n",
    "    x_pca_otherFSA = pca.fit_transform(x_ngram_otherFSA)\n",
    "    x_pca_prodStorageDist = pca.fit_transform(x_ngram_prodStorageDist)\n",
    "    x_pca_foodSafetyProdClaims = pca.fit_transform(x_ngram_foodSafetyProdClaims)\n",
    "    x_pca_targetMarket = pca.fit_transform(x_ngram_targetMarket)\n",
    "    x_newIngredient=train_df['newIngredient'].values\n",
    "    \n",
    "    x_train = np.concatenate((x_pca_allergens,x_pca_preservatives,x_pca_waterActivity,x_pca_packaging,x_pca_otherFSA,x_pca_prodStorageDist,x_pca_foodSafetyProdClaims,x_pca_targetMarket),axis =1)\n",
    "    \n",
    "    print(x_train.shape)\n",
    "    return x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform Target (potentialMicrobial) into binary value (1=Yes, 0=No)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statistics \n",
    "\n",
    "def impute_target(fsha_data,targetName):\n",
    "    train_y=[]\n",
    "    for i in range (len(fsha_data)):\n",
    "        if str(fsha_data[targetName][i]).strip().lower() =='yes':\n",
    "            train_y.append(1)\n",
    "        elif str(fsha_data[targetName][i]).strip().lower() =='no':\n",
    "            train_y.append(0)\n",
    "        else:\n",
    "            train_y.append(-1)\n",
    "               \n",
    "    mode_y = statistics.mode(train_y)\n",
    "\n",
    "    for i in range (len(fsha_data)):\n",
    "        if train_y[i]==-1:\n",
    "            train_y[i] = mode_y\n",
    "            \n",
    "    return train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df[\"tags\"] = impute_target(fsha_data,\"potentialMicrobial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    205\n",
       "1      4\n",
       "Name: tags, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = train_df[\"tags\"]\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process the data (Vectorize the features using the functions defined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(209, 16)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(209, 16)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_components=2\n",
    "ngram_range_inp=(1,2)\n",
    "x_train = preprocess_text(train_df,y,n_components,ngram_range_inp)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check a row of X matrix (corresponding to one FSHA Form), how it looks after vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-9.72680748e-02, -1.35703497e-02, -6.50971681e-02, -4.53446154e-03,\n",
       "       -1.28027618e-01, -3.91945662e-03,  6.83378041e-01,  7.52314106e-02,\n",
       "       -1.35331033e-02,  1.15504086e-07,  7.87282050e-01,  7.75708199e-01,\n",
       "       -4.40530449e-01, -1.78784415e-01, -2.48379186e-01, -2.24912643e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check target - y (potentialMicrobial) distribution after binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    205\n",
       "1      4\n",
       "Name: tags, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# This shows the data is highly imbalanced, there are 3 counts of Yes(1), and rest are No(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train=pd.DataFrame(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y.rename(columns={0:'target'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = x_train,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the final X matrix (Vectorized form of the Text Inputs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.097268</td>\n",
       "      <td>-0.013570</td>\n",
       "      <td>-0.065097</td>\n",
       "      <td>-0.004534</td>\n",
       "      <td>-0.128028</td>\n",
       "      <td>-0.003919</td>\n",
       "      <td>0.683378</td>\n",
       "      <td>0.075231</td>\n",
       "      <td>-0.013533</td>\n",
       "      <td>1.155041e-07</td>\n",
       "      <td>0.787282</td>\n",
       "      <td>0.775708</td>\n",
       "      <td>-0.440530</td>\n",
       "      <td>-0.178784</td>\n",
       "      <td>-0.248379</td>\n",
       "      <td>-0.224913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.182251</td>\n",
       "      <td>-0.054384</td>\n",
       "      <td>-0.065097</td>\n",
       "      <td>-0.004534</td>\n",
       "      <td>-0.128038</td>\n",
       "      <td>-0.003921</td>\n",
       "      <td>-0.368444</td>\n",
       "      <td>-0.421074</td>\n",
       "      <td>-0.013533</td>\n",
       "      <td>-2.034859e-08</td>\n",
       "      <td>0.883008</td>\n",
       "      <td>-0.635261</td>\n",
       "      <td>-0.549706</td>\n",
       "      <td>0.776129</td>\n",
       "      <td>-0.164104</td>\n",
       "      <td>-0.084490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.132213</td>\n",
       "      <td>-0.003500</td>\n",
       "      <td>-0.065097</td>\n",
       "      <td>-0.004535</td>\n",
       "      <td>-0.128036</td>\n",
       "      <td>-0.003921</td>\n",
       "      <td>-0.210076</td>\n",
       "      <td>-0.099517</td>\n",
       "      <td>-0.013533</td>\n",
       "      <td>-2.034860e-08</td>\n",
       "      <td>0.883008</td>\n",
       "      <td>-0.635262</td>\n",
       "      <td>-0.549712</td>\n",
       "      <td>0.776119</td>\n",
       "      <td>-0.248380</td>\n",
       "      <td>-0.224912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.143493</td>\n",
       "      <td>0.015549</td>\n",
       "      <td>-0.065097</td>\n",
       "      <td>-0.004535</td>\n",
       "      <td>-0.128041</td>\n",
       "      <td>-0.003921</td>\n",
       "      <td>-0.210075</td>\n",
       "      <td>-0.099516</td>\n",
       "      <td>-0.013533</td>\n",
       "      <td>-2.034860e-08</td>\n",
       "      <td>0.883008</td>\n",
       "      <td>-0.635262</td>\n",
       "      <td>-0.549703</td>\n",
       "      <td>0.776138</td>\n",
       "      <td>-0.248380</td>\n",
       "      <td>-0.224913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.129592</td>\n",
       "      <td>-0.091374</td>\n",
       "      <td>-0.065097</td>\n",
       "      <td>-0.004535</td>\n",
       "      <td>-0.128034</td>\n",
       "      <td>-0.003922</td>\n",
       "      <td>-0.284982</td>\n",
       "      <td>-0.318154</td>\n",
       "      <td>-0.013533</td>\n",
       "      <td>-2.034860e-08</td>\n",
       "      <td>0.787283</td>\n",
       "      <td>0.775708</td>\n",
       "      <td>-0.250995</td>\n",
       "      <td>0.007928</td>\n",
       "      <td>-0.164101</td>\n",
       "      <td>-0.084486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -0.097268 -0.013570 -0.065097 -0.004534 -0.128028 -0.003919  0.683378   \n",
       "1 -0.182251 -0.054384 -0.065097 -0.004534 -0.128038 -0.003921 -0.368444   \n",
       "2 -0.132213 -0.003500 -0.065097 -0.004535 -0.128036 -0.003921 -0.210076   \n",
       "3 -0.143493  0.015549 -0.065097 -0.004535 -0.128041 -0.003921 -0.210075   \n",
       "4 -0.129592 -0.091374 -0.065097 -0.004535 -0.128034 -0.003922 -0.284982   \n",
       "\n",
       "         7         8             9         10        11        12        13  \\\n",
       "0  0.075231 -0.013533  1.155041e-07  0.787282  0.775708 -0.440530 -0.178784   \n",
       "1 -0.421074 -0.013533 -2.034859e-08  0.883008 -0.635261 -0.549706  0.776129   \n",
       "2 -0.099517 -0.013533 -2.034860e-08  0.883008 -0.635262 -0.549712  0.776119   \n",
       "3 -0.099516 -0.013533 -2.034860e-08  0.883008 -0.635262 -0.549703  0.776138   \n",
       "4 -0.318154 -0.013533 -2.034860e-08  0.787283  0.775708 -0.250995  0.007928   \n",
       "\n",
       "         14        15  \n",
       "0 -0.248379 -0.224913  \n",
       "1 -0.164104 -0.084490  \n",
       "2 -0.248380 -0.224912  \n",
       "3 -0.248380 -0.224913  \n",
       "4 -0.164101 -0.084486  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the X and y into Train and Test data with a ratio of 0.2 (ie Test Data = 0.2 of Full data set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(167, 16)\n",
      "(42, 16)\n"
     ]
    }
   ],
   "source": [
    "selector = SelectKBest(f_classif, k='all')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, stratify=y, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upsample the potentialMicrobial data, since the data is highly imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>-0.337541</td>\n",
       "      <td>-0.517563</td>\n",
       "      <td>-0.065097</td>\n",
       "      <td>-0.004535</td>\n",
       "      <td>-0.128038</td>\n",
       "      <td>-0.003921</td>\n",
       "      <td>0.683377</td>\n",
       "      <td>0.075231</td>\n",
       "      <td>-0.013533</td>\n",
       "      <td>-2.034860e-08</td>\n",
       "      <td>-0.386790</td>\n",
       "      <td>-0.012677</td>\n",
       "      <td>0.621616</td>\n",
       "      <td>-0.005091</td>\n",
       "      <td>-0.164101</td>\n",
       "      <td>-0.084486</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.780240</td>\n",
       "      <td>0.013213</td>\n",
       "      <td>-0.065097</td>\n",
       "      <td>-0.004535</td>\n",
       "      <td>-0.128038</td>\n",
       "      <td>-0.003921</td>\n",
       "      <td>-0.398059</td>\n",
       "      <td>-0.604142</td>\n",
       "      <td>-0.013533</td>\n",
       "      <td>-2.034860e-08</td>\n",
       "      <td>-0.386790</td>\n",
       "      <td>-0.012677</td>\n",
       "      <td>-0.603883</td>\n",
       "      <td>-0.617703</td>\n",
       "      <td>0.788703</td>\n",
       "      <td>0.069769</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.780240</td>\n",
       "      <td>0.013213</td>\n",
       "      <td>-0.065097</td>\n",
       "      <td>-0.004535</td>\n",
       "      <td>-0.128038</td>\n",
       "      <td>-0.003921</td>\n",
       "      <td>-0.398059</td>\n",
       "      <td>-0.604142</td>\n",
       "      <td>-0.013533</td>\n",
       "      <td>-2.034860e-08</td>\n",
       "      <td>-0.386790</td>\n",
       "      <td>-0.012677</td>\n",
       "      <td>-0.603883</td>\n",
       "      <td>-0.617703</td>\n",
       "      <td>0.788703</td>\n",
       "      <td>0.069769</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.780240</td>\n",
       "      <td>0.013213</td>\n",
       "      <td>-0.065097</td>\n",
       "      <td>-0.004535</td>\n",
       "      <td>-0.128038</td>\n",
       "      <td>-0.003921</td>\n",
       "      <td>-0.398059</td>\n",
       "      <td>-0.604142</td>\n",
       "      <td>-0.013533</td>\n",
       "      <td>-2.034860e-08</td>\n",
       "      <td>-0.386790</td>\n",
       "      <td>-0.012677</td>\n",
       "      <td>-0.603883</td>\n",
       "      <td>-0.617703</td>\n",
       "      <td>0.788703</td>\n",
       "      <td>0.069769</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>-0.161871</td>\n",
       "      <td>-0.114718</td>\n",
       "      <td>-0.065097</td>\n",
       "      <td>-0.004535</td>\n",
       "      <td>-0.128038</td>\n",
       "      <td>-0.003921</td>\n",
       "      <td>0.683377</td>\n",
       "      <td>0.075231</td>\n",
       "      <td>-0.013533</td>\n",
       "      <td>-2.034860e-08</td>\n",
       "      <td>0.787283</td>\n",
       "      <td>0.775708</td>\n",
       "      <td>0.621616</td>\n",
       "      <td>-0.005091</td>\n",
       "      <td>-0.410590</td>\n",
       "      <td>0.807420</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "190 -0.337541 -0.517563 -0.065097 -0.004535 -0.128038 -0.003921  0.683377   \n",
       "73   0.780240  0.013213 -0.065097 -0.004535 -0.128038 -0.003921 -0.398059   \n",
       "68   0.780240  0.013213 -0.065097 -0.004535 -0.128038 -0.003921 -0.398059   \n",
       "89   0.780240  0.013213 -0.065097 -0.004535 -0.128038 -0.003921 -0.398059   \n",
       "163 -0.161871 -0.114718 -0.065097 -0.004535 -0.128038 -0.003921  0.683377   \n",
       "\n",
       "            7         8             9        10        11        12        13  \\\n",
       "190  0.075231 -0.013533 -2.034860e-08 -0.386790 -0.012677  0.621616 -0.005091   \n",
       "73  -0.604142 -0.013533 -2.034860e-08 -0.386790 -0.012677 -0.603883 -0.617703   \n",
       "68  -0.604142 -0.013533 -2.034860e-08 -0.386790 -0.012677 -0.603883 -0.617703   \n",
       "89  -0.604142 -0.013533 -2.034860e-08 -0.386790 -0.012677 -0.603883 -0.617703   \n",
       "163  0.075231 -0.013533 -2.034860e-08  0.787283  0.775708  0.621616 -0.005091   \n",
       "\n",
       "           14        15  tags  \n",
       "190 -0.164101 -0.084486     0  \n",
       "73   0.788703  0.069769     0  \n",
       "68   0.788703  0.069769     0  \n",
       "89   0.788703  0.069769     0  \n",
       "163 -0.410590  0.807420     0  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# concatenate our training data back together\n",
    "X = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# separate minority and majority classes\n",
    "not_potMicrobial = X[X.tags==0]\n",
    "potMicrobial = X[X.tags==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(not_potMicrobial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(potMicrobial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# upsample minority\n",
    "potMicrobial_upsampled = resample(potMicrobial,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=len(not_potMicrobial), # match number in majority class\n",
    "                          random_state=27) # reproducible results\n",
    "\n",
    "# combine majority and upsampled minority\n",
    "upsampled = pd.concat([not_potMicrobial, potMicrobial_upsampled])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After upsampling the target counts are same, and data is balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    164\n",
       "0    164\n",
       "Name: tags, dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upsampled.tags.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = upsampled.tags\n",
    "X_train = upsampled.drop('tags', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train=y_train.reshape(y_train.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(328, 16)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(328, 1)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define method to evaluate Machine Learning models with the X and y vectors created above, and check the effectiveness of each. Also store the results in array to be plotted in graph for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import time\n",
    "def benchmark(clf):\n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "    print(len(X_train))\n",
    "    \n",
    "    clf_descr = str(clf).split('(')[0]\n",
    "    print(\"model name:\"+clf_descr)\n",
    "  \n",
    "    a = datetime.now()\n",
    "    \n",
    "    if clf_descr.__contains__('tensorflow'):\n",
    "        history = clf.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            epochs=epochs,\n",
    "            callbacks=callbacks,\n",
    "            validation_data=(X_test, y_test),\n",
    "            verbose=2, \n",
    "            batch_size=batch_size)\n",
    "    else:\n",
    "        clf.fit(X_train, y_train)\n",
    "    \n",
    "    b = datetime.now()\n",
    "    c = a-b\n",
    "    train_time = c.microseconds\n",
    "    print(\"train time: %0.3fs\" % train_time)\n",
    "\n",
    "    pred = clf.predict(X_test)\n",
    "\n",
    "    pred_train = clf.predict(X_train)\n",
    " \n",
    "    if clf_descr.__contains__('tensorflow'):\n",
    "        for i in range (len(pred)):\n",
    "            if (pred[i]>=0.3):\n",
    "                pred[i]=1\n",
    "            else:\n",
    "                pred[i]=0\n",
    "        for i in range (len(pred_train)):        \n",
    "            if (pred_train[i]>=0.3):\n",
    "                pred_train[i]=1\n",
    "            else:\n",
    "                pred_train[i]=0\n",
    "    \n",
    "    f1_score = metrics.f1_score(y_test, pred, average='weighted')\n",
    "    print(\"f1_score:   %0.3f\" % f1_score )\n",
    "    \n",
    "    f1_score_train = metrics.f1_score(y_train, pred_train, average='weighted')\n",
    "    print(\"f1_score_train:   %0.3f\" % f1_score_train )\n",
    "    \n",
    "    print(\"classification report:\")\n",
    "    print(classification_report(y_test, pred))\n",
    "    \n",
    "    print(\"confusion matrix:\")\n",
    "    print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "    if hasattr(clf, 'coef_'):\n",
    "        print(\"dimensionality: %d\" % clf.coef_.shape[1])\n",
    "        print(\"density: %f\" % density(clf.coef_))\n",
    "\n",
    "    \n",
    "    return clf_descr,f1_score_train,f1_score,train_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Machine Learning Models from a List (using the reusable method defined above). Store the results (Accuracy score - train, accuracy score - test, and training time) in a List for data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "Training: \n",
      "328\n",
      "model name:Pipeline\n",
      "train time: 0.000s\n",
      "f1_score:   0.914\n",
      "f1_score_train:   0.942\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.90      0.94        41\n",
      "          1       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.95      0.88      0.91        42\n",
      "\n",
      "confusion matrix:\n",
      "[[37  4]\n",
      " [ 1  0]]\n",
      "================================================================================\n",
      "Ridge Classifier\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "328\n",
      "model name:RidgeClassifier\n",
      "train time: 0.000s\n",
      "f1_score:   0.914\n",
      "f1_score_train:   0.942\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.90      0.94        41\n",
      "          1       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.95      0.88      0.91        42\n",
      "\n",
      "confusion matrix:\n",
      "[[37  4]\n",
      " [ 1  0]]\n",
      "dimensionality: 16\n",
      "density: 1.000000\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "328\n",
      "model name:Pipeline\n",
      "train time: 984384.000s\n",
      "f1_score:   0.940\n",
      "f1_score_train:   0.960\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.95      0.96        41\n",
      "          1       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.95      0.93      0.94        42\n",
      "\n",
      "confusion matrix:\n",
      "[[39  2]\n",
      " [ 1  0]]\n",
      "================================================================================\n",
      "Perceptron\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "328\n",
      "model name:Perceptron\n",
      "train time: 0.000s\n",
      "f1_score:   0.940\n",
      "f1_score_train:   0.960\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.95      0.96        41\n",
      "          1       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.95      0.93      0.94        42\n",
      "\n",
      "confusion matrix:\n",
      "[[39  2]\n",
      " [ 1  0]]\n",
      "dimensionality: 16\n",
      "density: 1.000000\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "328\n",
      "model name:Pipeline\n",
      "train time: 0.000s\n",
      "f1_score:   0.927\n",
      "f1_score_train:   0.963\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.93      0.95        41\n",
      "          1       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.95      0.90      0.93        42\n",
      "\n",
      "confusion matrix:\n",
      "[[38  3]\n",
      " [ 1  0]]\n",
      "================================================================================\n",
      "Passive-Aggressive\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "328\n",
      "model name:PassiveAggressiveClassifier\n",
      "train time: 0.000s\n",
      "f1_score:   0.940\n",
      "f1_score_train:   0.982\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.95      0.96        41\n",
      "          1       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.95      0.93      0.94        42\n",
      "\n",
      "confusion matrix:\n",
      "[[39  2]\n",
      " [ 1  0]]\n",
      "dimensionality: 16\n",
      "density: 1.000000\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "328\n",
      "model name:Pipeline\n",
      "train time: 0.000s\n",
      "f1_score:   0.914\n",
      "f1_score_train:   0.991\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.90      0.94        41\n",
      "          1       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.95      0.88      0.91        42\n",
      "\n",
      "confusion matrix:\n",
      "[[37  4]\n",
      " [ 1  0]]\n",
      "================================================================================\n",
      "kNN\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "328\n",
      "model name:KNeighborsClassifier\n",
      "train time: 0.000s\n",
      "f1_score:   0.914\n",
      "f1_score_train:   0.991\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.90      0.94        41\n",
      "          1       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.95      0.88      0.91        42\n",
      "\n",
      "confusion matrix:\n",
      "[[37  4]\n",
      " [ 1  0]]\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "328\n",
      "model name:Pipeline\n",
      "train time: 671867.000s\n",
      "f1_score:   0.964\n",
      "f1_score_train:   1.000\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99        41\n",
      "          1       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.95      0.98      0.96        42\n",
      "\n",
      "confusion matrix:\n",
      "[[41  0]\n",
      " [ 1  0]]\n",
      "================================================================================\n",
      "Random forest\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "328\n",
      "model name:RandomForestClassifier\n",
      "train time: 703104.000s\n",
      "f1_score:   0.964\n",
      "f1_score_train:   1.000\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99        41\n",
      "          1       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.95      0.98      0.96        42\n",
      "\n",
      "confusion matrix:\n",
      "[[41  0]\n",
      " [ 1  0]]\n",
      "================================================================================\n",
      "L2 penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "328\n",
      "model name:LinearSVC\n",
      "train time: 0.000s\n",
      "f1_score:   0.927\n",
      "f1_score_train:   0.969\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.93      0.95        41\n",
      "          1       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.95      0.90      0.93        42\n",
      "\n",
      "confusion matrix:\n",
      "[[38  3]\n",
      " [ 1  0]]\n",
      "dimensionality: 16\n",
      "density: 1.000000\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "328\n",
      "model name:SGDClassifier\n",
      "train time: 0.000s\n",
      "f1_score:   0.927\n",
      "f1_score_train:   0.973\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.93      0.95        41\n",
      "          1       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.95      0.90      0.93        42\n",
      "\n",
      "confusion matrix:\n",
      "[[38  3]\n",
      " [ 1  0]]\n",
      "dimensionality: 16\n",
      "density: 1.000000\n",
      "================================================================================\n",
      "L1 penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "328\n",
      "model name:LinearSVC\n",
      "train time: 968755.000s\n",
      "f1_score:   0.927\n",
      "f1_score_train:   0.960\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.93      0.95        41\n",
      "          1       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.95      0.90      0.93        42\n",
      "\n",
      "confusion matrix:\n",
      "[[38  3]\n",
      " [ 1  0]]\n",
      "dimensionality: 16\n",
      "density: 0.750000\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "328\n",
      "model name:SGDClassifier\n",
      "train time: 0.000s\n",
      "f1_score:   0.952\n",
      "f1_score_train:   0.985\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.98      0.98        41\n",
      "          1       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.95      0.95      0.95        42\n",
      "\n",
      "confusion matrix:\n",
      "[[40  1]\n",
      " [ 1  0]]\n",
      "dimensionality: 16\n",
      "density: 0.812500\n",
      "================================================================================\n",
      "Elastic-Net penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "328\n",
      "model name:SGDClassifier\n",
      "train time: 0.000s\n",
      "f1_score:   0.927\n",
      "f1_score_train:   0.969\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.93      0.95        41\n",
      "          1       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.95      0.90      0.93        42\n",
      "\n",
      "confusion matrix:\n",
      "[[38  3]\n",
      " [ 1  0]]\n",
      "dimensionality: 16\n",
      "density: 0.875000\n",
      "================================================================================\n",
      "NearestCentroid (aka Rocchio classifier)\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "328\n",
      "model name:NearestCentroid\n",
      "train time: 0.000s\n",
      "f1_score:   0.859\n",
      "f1_score_train:   0.747\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.80      0.88        41\n",
      "          1       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.95      0.79      0.86        42\n",
      "\n",
      "confusion matrix:\n",
      "[[33  8]\n",
      " [ 1  0]]\n"
     ]
    }
   ],
   "source": [
    "# Not using MultinomialNaiveBayes, because sampled data has negative components. NaiveBayes expects frequencies in the positive\n",
    "\n",
    "results = []\n",
    "model_name = []\n",
    "\n",
    "for clf, name in (\n",
    "        (RidgeClassifier(tol=1e-2, solver=\"lsqr\"), \"Ridge Classifier\"),\n",
    "        (Perceptron(n_iter=50), \"Perceptron\"),\n",
    "        (PassiveAggressiveClassifier(n_iter=50), \"Passive-Aggressive\"),\n",
    "        (KNeighborsClassifier(n_neighbors=5), \"kNN\"),\n",
    "        (RandomForestClassifier(n_estimators=100), \"Random forest\")):\n",
    "    selector_clf = benchmark(Pipeline([('selector', selector),('classifier', clf)]))\n",
    "    print('=' * 80)\n",
    "    print(name)\n",
    "    results.append(benchmark(clf))\n",
    "    model_name.append(name)\n",
    "    #model.append(clf)\n",
    "    \n",
    "for penalty in [\"l2\", \"l1\"]:\n",
    "    print('=' * 80)\n",
    "    print(\"%s penalty\" % penalty.upper())\n",
    "    # Train Liblinear model\n",
    "    results.append(benchmark(LinearSVC(loss='l2', penalty=penalty,dual=False, tol=1e-3)))\n",
    "    model_name.append(\"LinearSVC\"+\" \"+penalty)\n",
    "\n",
    "    # Train SGD model\n",
    "    results.append(benchmark(SGDClassifier(alpha=.0001, n_iter=50,penalty=penalty)))\n",
    "    model_name.append(\"SGDClassifier\"+\" \"+penalty)\n",
    "\n",
    "\n",
    "# Train SGD with Elastic Net penalty\n",
    "print('=' * 80)\n",
    "print(\"Elastic-Net penalty\")\n",
    "results.append(benchmark(SGDClassifier(alpha=.0001, n_iter=50,penalty=\"elasticnet\")))\n",
    "model_name.append(\"SGD with Elastic Net penalty\")\n",
    "\n",
    "\n",
    "# Train NearestCentroid without threshold\n",
    "print('=' * 80)\n",
    "print(\"NearestCentroid (aka Rocchio classifier)\")\n",
    "results.append(benchmark(NearestCentroid()))\n",
    "model_name.append(\"NearestCentroid (aka Rocchio classifier)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Neural Network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mlp_model(layers, units, dropout_rate, input_shape):\n",
    "    \"\"\"Creates an instance of a multi-layer perceptron model.\n",
    "\n",
    "    # Arguments\n",
    "        layers: int, number of `Dense` layers in the model.\n",
    "        units: int, output dimension of the layers.\n",
    "        dropout_rate: float, percentage of input to drop at Dropout layers.\n",
    "        input_shape: tuple, shape of input to the model.\n",
    "\n",
    "    # Returns\n",
    "        An MLP model instance.\n",
    "    \"\"\"\n",
    "    model = models.Sequential()\n",
    "    model.add(Dropout(rate=dropout_rate, input_shape=input_shape))\n",
    "\n",
    "    for _ in range(layers-1):\n",
    "        model.add(Dense(units=units, activation='relu'))\n",
    "        model.add(Dropout(rate=dropout_rate))\n",
    "\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dropout_2 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 1,153\n",
      "Trainable params: 1,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "learning_rate=1e-3\n",
    "epochs=100\n",
    "batch_size=128\n",
    "layers=2\n",
    "units=64\n",
    "dropout_rate=0.2\n",
    "model = mlp_model(layers=layers,units=units,dropout_rate=dropout_rate,input_shape=X_train.shape[1:])\n",
    "optimizer = tf.keras.optimizers.Adam(lr=learning_rate)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['acc'])\n",
    "callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)]\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model and store results in array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Keras Dense Neural Network\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "328\n",
      "model name:<tensorflow.python.keras.engine.sequential.Sequential object at 0x000001A98901DEF0>\n",
      "Train on 328 samples, validate on 42 samples\n",
      "Epoch 1/100\n",
      "328/328 - 0s - loss: 0.6464 - acc: 0.6707 - val_loss: 0.6436 - val_acc: 0.6905\n",
      "Epoch 2/100\n",
      "328/328 - 0s - loss: 0.6420 - acc: 0.6982 - val_loss: 0.6400 - val_acc: 0.6429\n",
      "Epoch 3/100\n",
      "328/328 - 0s - loss: 0.6196 - acc: 0.7652 - val_loss: 0.6350 - val_acc: 0.6429\n",
      "Epoch 4/100\n",
      "328/328 - 0s - loss: 0.6100 - acc: 0.8018 - val_loss: 0.6312 - val_acc: 0.6190\n",
      "Epoch 5/100\n",
      "328/328 - 0s - loss: 0.5878 - acc: 0.7988 - val_loss: 0.6265 - val_acc: 0.6190\n",
      "Epoch 6/100\n",
      "328/328 - 0s - loss: 0.5766 - acc: 0.8140 - val_loss: 0.6222 - val_acc: 0.6905\n",
      "Epoch 7/100\n",
      "328/328 - 0s - loss: 0.5607 - acc: 0.8354 - val_loss: 0.6177 - val_acc: 0.6905\n",
      "Epoch 8/100\n",
      "328/328 - 0s - loss: 0.5587 - acc: 0.8232 - val_loss: 0.6130 - val_acc: 0.6905\n",
      "Epoch 9/100\n",
      "328/328 - 0s - loss: 0.5426 - acc: 0.8354 - val_loss: 0.6080 - val_acc: 0.6905\n",
      "Epoch 10/100\n",
      "328/328 - 0s - loss: 0.5326 - acc: 0.8262 - val_loss: 0.6025 - val_acc: 0.6905\n",
      "Epoch 11/100\n",
      "328/328 - 0s - loss: 0.5187 - acc: 0.8567 - val_loss: 0.5963 - val_acc: 0.6905\n",
      "Epoch 12/100\n",
      "328/328 - 0s - loss: 0.4988 - acc: 0.8598 - val_loss: 0.5913 - val_acc: 0.6905\n",
      "Epoch 13/100\n",
      "328/328 - 0s - loss: 0.5025 - acc: 0.8598 - val_loss: 0.5861 - val_acc: 0.6905\n",
      "Epoch 14/100\n",
      "328/328 - 0s - loss: 0.4798 - acc: 0.8659 - val_loss: 0.5806 - val_acc: 0.6905\n",
      "Epoch 15/100\n",
      "328/328 - 0s - loss: 0.4728 - acc: 0.8598 - val_loss: 0.5760 - val_acc: 0.6905\n",
      "Epoch 16/100\n",
      "328/328 - 0s - loss: 0.4827 - acc: 0.8506 - val_loss: 0.5709 - val_acc: 0.6905\n",
      "Epoch 17/100\n",
      "328/328 - 0s - loss: 0.4670 - acc: 0.8415 - val_loss: 0.5663 - val_acc: 0.7143\n",
      "Epoch 18/100\n",
      "328/328 - 0s - loss: 0.4393 - acc: 0.8689 - val_loss: 0.5611 - val_acc: 0.7143\n",
      "Epoch 19/100\n",
      "328/328 - 0s - loss: 0.4415 - acc: 0.8506 - val_loss: 0.5553 - val_acc: 0.7143\n",
      "Epoch 20/100\n",
      "328/328 - 0s - loss: 0.4370 - acc: 0.8598 - val_loss: 0.5493 - val_acc: 0.7381\n",
      "Epoch 21/100\n",
      "328/328 - 0s - loss: 0.4348 - acc: 0.8659 - val_loss: 0.5434 - val_acc: 0.7381\n",
      "Epoch 22/100\n",
      "328/328 - 0s - loss: 0.4272 - acc: 0.8720 - val_loss: 0.5371 - val_acc: 0.7381\n",
      "Epoch 23/100\n",
      "328/328 - 0s - loss: 0.4146 - acc: 0.8567 - val_loss: 0.5300 - val_acc: 0.7381\n",
      "Epoch 24/100\n",
      "328/328 - 0s - loss: 0.4178 - acc: 0.8720 - val_loss: 0.5224 - val_acc: 0.7381\n",
      "Epoch 25/100\n",
      "328/328 - 0s - loss: 0.4204 - acc: 0.8567 - val_loss: 0.5157 - val_acc: 0.7381\n",
      "Epoch 26/100\n",
      "328/328 - 0s - loss: 0.3990 - acc: 0.8963 - val_loss: 0.5085 - val_acc: 0.7381\n",
      "Epoch 27/100\n",
      "328/328 - 0s - loss: 0.3919 - acc: 0.8598 - val_loss: 0.5023 - val_acc: 0.7381\n",
      "Epoch 28/100\n",
      "328/328 - 0s - loss: 0.3815 - acc: 0.8628 - val_loss: 0.4953 - val_acc: 0.7381\n",
      "Epoch 29/100\n",
      "328/328 - 0s - loss: 0.3844 - acc: 0.8811 - val_loss: 0.4881 - val_acc: 0.7381\n",
      "Epoch 30/100\n",
      "328/328 - 0s - loss: 0.3834 - acc: 0.8750 - val_loss: 0.4811 - val_acc: 0.7381\n",
      "Epoch 31/100\n",
      "328/328 - 0s - loss: 0.3787 - acc: 0.8750 - val_loss: 0.4746 - val_acc: 0.7381\n",
      "Epoch 32/100\n",
      "328/328 - 0s - loss: 0.3526 - acc: 0.8994 - val_loss: 0.4678 - val_acc: 0.7381\n",
      "Epoch 33/100\n",
      "328/328 - 0s - loss: 0.3685 - acc: 0.8872 - val_loss: 0.4616 - val_acc: 0.7381\n",
      "Epoch 34/100\n",
      "328/328 - 0s - loss: 0.3681 - acc: 0.8780 - val_loss: 0.4558 - val_acc: 0.7381\n",
      "Epoch 35/100\n",
      "328/328 - 0s - loss: 0.3552 - acc: 0.8720 - val_loss: 0.4496 - val_acc: 0.7619\n",
      "Epoch 36/100\n",
      "328/328 - 0s - loss: 0.3440 - acc: 0.8963 - val_loss: 0.4443 - val_acc: 0.7619\n",
      "Epoch 37/100\n",
      "328/328 - 0s - loss: 0.3360 - acc: 0.8933 - val_loss: 0.4389 - val_acc: 0.7619\n",
      "Epoch 38/100\n",
      "328/328 - 0s - loss: 0.3305 - acc: 0.8872 - val_loss: 0.4351 - val_acc: 0.7619\n",
      "Epoch 39/100\n",
      "328/328 - 0s - loss: 0.3243 - acc: 0.8902 - val_loss: 0.4316 - val_acc: 0.7619\n",
      "Epoch 40/100\n",
      "328/328 - 0s - loss: 0.3288 - acc: 0.8994 - val_loss: 0.4285 - val_acc: 0.7619\n",
      "Epoch 41/100\n",
      "328/328 - 0s - loss: 0.3166 - acc: 0.8994 - val_loss: 0.4257 - val_acc: 0.7619\n",
      "Epoch 42/100\n",
      "328/328 - 0s - loss: 0.3153 - acc: 0.8841 - val_loss: 0.4235 - val_acc: 0.7619\n",
      "Epoch 43/100\n",
      "328/328 - 0s - loss: 0.3198 - acc: 0.8902 - val_loss: 0.4207 - val_acc: 0.7619\n",
      "Epoch 44/100\n",
      "328/328 - 0s - loss: 0.3045 - acc: 0.8933 - val_loss: 0.4178 - val_acc: 0.7619\n",
      "Epoch 45/100\n",
      "328/328 - 0s - loss: 0.3103 - acc: 0.8994 - val_loss: 0.4150 - val_acc: 0.7619\n",
      "Epoch 46/100\n",
      "328/328 - 0s - loss: 0.2966 - acc: 0.8933 - val_loss: 0.4110 - val_acc: 0.7619\n",
      "Epoch 47/100\n",
      "328/328 - 0s - loss: 0.2983 - acc: 0.8963 - val_loss: 0.4063 - val_acc: 0.7619\n",
      "Epoch 48/100\n",
      "328/328 - 0s - loss: 0.3063 - acc: 0.8689 - val_loss: 0.4004 - val_acc: 0.7619\n",
      "Epoch 49/100\n",
      "328/328 - 0s - loss: 0.3027 - acc: 0.9085 - val_loss: 0.3955 - val_acc: 0.7619\n",
      "Epoch 50/100\n",
      "328/328 - 0s - loss: 0.2857 - acc: 0.9024 - val_loss: 0.3914 - val_acc: 0.7619\n",
      "Epoch 51/100\n",
      "328/328 - 0s - loss: 0.3048 - acc: 0.8994 - val_loss: 0.3872 - val_acc: 0.7857\n",
      "Epoch 52/100\n",
      "328/328 - 0s - loss: 0.2620 - acc: 0.9055 - val_loss: 0.3839 - val_acc: 0.7857\n",
      "Epoch 53/100\n",
      "328/328 - 0s - loss: 0.2813 - acc: 0.8994 - val_loss: 0.3809 - val_acc: 0.7857\n",
      "Epoch 54/100\n",
      "328/328 - 0s - loss: 0.3033 - acc: 0.8872 - val_loss: 0.3787 - val_acc: 0.7857\n",
      "Epoch 55/100\n",
      "328/328 - 0s - loss: 0.2750 - acc: 0.8994 - val_loss: 0.3768 - val_acc: 0.7857\n",
      "Epoch 56/100\n",
      "328/328 - 0s - loss: 0.2701 - acc: 0.9024 - val_loss: 0.3753 - val_acc: 0.7857\n",
      "Epoch 57/100\n",
      "328/328 - 0s - loss: 0.2781 - acc: 0.9085 - val_loss: 0.3732 - val_acc: 0.7857\n",
      "Epoch 58/100\n",
      "328/328 - 0s - loss: 0.2876 - acc: 0.8963 - val_loss: 0.3708 - val_acc: 0.8333\n",
      "Epoch 59/100\n",
      "328/328 - 0s - loss: 0.2778 - acc: 0.8902 - val_loss: 0.3696 - val_acc: 0.8333\n",
      "Epoch 60/100\n",
      "328/328 - 0s - loss: 0.2496 - acc: 0.9146 - val_loss: 0.3698 - val_acc: 0.8333\n",
      "Epoch 61/100\n",
      "328/328 - 0s - loss: 0.2530 - acc: 0.9177 - val_loss: 0.3688 - val_acc: 0.8333\n",
      "Epoch 62/100\n",
      "328/328 - 0s - loss: 0.2534 - acc: 0.9207 - val_loss: 0.3684 - val_acc: 0.8333\n",
      "Epoch 63/100\n",
      "328/328 - 0s - loss: 0.2486 - acc: 0.9116 - val_loss: 0.3686 - val_acc: 0.8333\n",
      "Epoch 64/100\n",
      "328/328 - 0s - loss: 0.2648 - acc: 0.8963 - val_loss: 0.3671 - val_acc: 0.8333\n",
      "Epoch 65/100\n",
      "328/328 - 0s - loss: 0.2713 - acc: 0.8963 - val_loss: 0.3653 - val_acc: 0.8333\n",
      "Epoch 66/100\n",
      "328/328 - 0s - loss: 0.2581 - acc: 0.9055 - val_loss: 0.3634 - val_acc: 0.8333\n",
      "Epoch 67/100\n",
      "328/328 - 0s - loss: 0.2523 - acc: 0.9085 - val_loss: 0.3619 - val_acc: 0.8333\n",
      "Epoch 68/100\n",
      "328/328 - 0s - loss: 0.2587 - acc: 0.9024 - val_loss: 0.3609 - val_acc: 0.8333\n",
      "Epoch 69/100\n",
      "328/328 - 0s - loss: 0.2549 - acc: 0.9177 - val_loss: 0.3603 - val_acc: 0.8333\n",
      "Epoch 70/100\n",
      "328/328 - 0s - loss: 0.2372 - acc: 0.9116 - val_loss: 0.3590 - val_acc: 0.8333\n",
      "Epoch 71/100\n",
      "328/328 - 0s - loss: 0.2495 - acc: 0.9268 - val_loss: 0.3587 - val_acc: 0.8333\n",
      "Epoch 72/100\n",
      "328/328 - 0s - loss: 0.2553 - acc: 0.9146 - val_loss: 0.3585 - val_acc: 0.8333\n",
      "Epoch 73/100\n",
      "328/328 - 0s - loss: 0.2378 - acc: 0.9268 - val_loss: 0.3581 - val_acc: 0.8333\n",
      "Epoch 74/100\n",
      "328/328 - 0s - loss: 0.2465 - acc: 0.9146 - val_loss: 0.3575 - val_acc: 0.8333\n",
      "Epoch 75/100\n",
      "328/328 - 0s - loss: 0.2459 - acc: 0.8933 - val_loss: 0.3571 - val_acc: 0.8333\n",
      "Epoch 76/100\n",
      "328/328 - 0s - loss: 0.2518 - acc: 0.8994 - val_loss: 0.3562 - val_acc: 0.8333\n",
      "Epoch 77/100\n",
      "328/328 - 0s - loss: 0.2247 - acc: 0.9177 - val_loss: 0.3552 - val_acc: 0.8333\n",
      "Epoch 78/100\n",
      "328/328 - 0s - loss: 0.2458 - acc: 0.9055 - val_loss: 0.3553 - val_acc: 0.8333\n",
      "Epoch 79/100\n",
      "328/328 - 0s - loss: 0.2274 - acc: 0.9329 - val_loss: 0.3552 - val_acc: 0.8333\n",
      "Epoch 80/100\n",
      "328/328 - 0s - loss: 0.2249 - acc: 0.9268 - val_loss: 0.3545 - val_acc: 0.8333\n",
      "Epoch 81/100\n",
      "328/328 - 0s - loss: 0.2267 - acc: 0.9329 - val_loss: 0.3528 - val_acc: 0.8333\n",
      "Epoch 82/100\n",
      "328/328 - 0s - loss: 0.2393 - acc: 0.9024 - val_loss: 0.3512 - val_acc: 0.8333\n",
      "Epoch 83/100\n",
      "328/328 - 0s - loss: 0.2487 - acc: 0.9055 - val_loss: 0.3497 - val_acc: 0.8333\n",
      "Epoch 84/100\n",
      "328/328 - 0s - loss: 0.2331 - acc: 0.9146 - val_loss: 0.3483 - val_acc: 0.8333\n",
      "Epoch 85/100\n",
      "328/328 - 0s - loss: 0.2237 - acc: 0.9360 - val_loss: 0.3463 - val_acc: 0.8333\n",
      "Epoch 86/100\n",
      "328/328 - 0s - loss: 0.2450 - acc: 0.9024 - val_loss: 0.3447 - val_acc: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/100\n",
      "328/328 - 0s - loss: 0.2210 - acc: 0.9421 - val_loss: 0.3430 - val_acc: 0.8333\n",
      "Epoch 88/100\n",
      "328/328 - 0s - loss: 0.2394 - acc: 0.9146 - val_loss: 0.3419 - val_acc: 0.8333\n",
      "Epoch 89/100\n",
      "328/328 - 0s - loss: 0.2161 - acc: 0.9421 - val_loss: 0.3424 - val_acc: 0.8333\n",
      "Epoch 90/100\n",
      "328/328 - 0s - loss: 0.2214 - acc: 0.9238 - val_loss: 0.3410 - val_acc: 0.8333\n",
      "Epoch 91/100\n",
      "328/328 - 0s - loss: 0.2139 - acc: 0.9482 - val_loss: 0.3404 - val_acc: 0.8333\n",
      "Epoch 92/100\n",
      "328/328 - 0s - loss: 0.2212 - acc: 0.9177 - val_loss: 0.3389 - val_acc: 0.8333\n",
      "Epoch 93/100\n",
      "328/328 - 0s - loss: 0.2070 - acc: 0.9329 - val_loss: 0.3383 - val_acc: 0.8333\n",
      "Epoch 94/100\n",
      "328/328 - 0s - loss: 0.2133 - acc: 0.9299 - val_loss: 0.3381 - val_acc: 0.8333\n",
      "Epoch 95/100\n",
      "328/328 - 0s - loss: 0.2205 - acc: 0.9207 - val_loss: 0.3357 - val_acc: 0.8333\n",
      "Epoch 96/100\n",
      "328/328 - 0s - loss: 0.2148 - acc: 0.9299 - val_loss: 0.3350 - val_acc: 0.8333\n",
      "Epoch 97/100\n",
      "328/328 - 0s - loss: 0.2164 - acc: 0.9116 - val_loss: 0.3360 - val_acc: 0.8333\n",
      "Epoch 98/100\n",
      "328/328 - 0s - loss: 0.1990 - acc: 0.9329 - val_loss: 0.3382 - val_acc: 0.8333\n",
      "Epoch 99/100\n",
      "328/328 - 0s - loss: 0.2232 - acc: 0.9207 - val_loss: 0.3388 - val_acc: 0.8333\n",
      "train time: 93699.000s\n",
      "f1_score:   0.844\n",
      "f1_score_train:   0.911\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.78      0.86        41\n",
      "          1       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.95      0.76      0.84        42\n",
      "\n",
      "confusion matrix:\n",
      "[[32  9]\n",
      " [ 1  0]]\n"
     ]
    }
   ],
   "source": [
    "print('=' * 80)\n",
    "print(\"Keras Dense Neural Network\")\n",
    "results.append(benchmark(model))\n",
    "model_name.append(\"Keras Dense Neural Network\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the results from multiple Machine Learning Models (accuracy - train, accuracy - test, training time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuMAAAI1CAYAAAB8GvSWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n45IkSVInhnFJkiSpk/8AIxredPDbjrAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a9890151d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make some plots\n",
    "indices = np.arange(len(results))\n",
    "\n",
    "results = [[x[i] for x in results] for i in range(4)]\n",
    "\n",
    "clf_names, f1_score_train, f1_score_test, training_time = results\n",
    "\n",
    "training_time = np.array(training_time) / np.max(training_time)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title(\"Score\")\n",
    "plt.barh(indices, f1_score_train, .2, label=\"f1_score_train\", color='r')\n",
    "plt.barh(indices+0.3, f1_score_test, .2, label=\"f1_score_test\", color='b')\n",
    "plt.barh(indices + .6, training_time, .2, label=\"training time\", color='g')\n",
    "plt.yticks(())\n",
    "plt.legend(loc='best')\n",
    "plt.subplots_adjust(left=.25)\n",
    "plt.subplots_adjust(top=.95)\n",
    "plt.subplots_adjust(bottom=.05)\n",
    "\n",
    "for i, c in zip(indices, model_name):\n",
    "    plt.text(-.3, i, c)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print the best model and accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9644291451520366\n",
      "Random forest\n"
     ]
    }
   ],
   "source": [
    "\n",
    "index=np.argmax(f1_score_test)\n",
    "f1score = f1_score_test[index]\n",
    "print(f1score)\n",
    "print(model_name[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result is F1-score of \"Yes\" is 96.4%, but the No instances are not predicted at all, as can be seen in the classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
