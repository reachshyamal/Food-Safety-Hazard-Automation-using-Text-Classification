{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-5c51bc138875>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSTOPWORDS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mImageColorGenerator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSnowballStemmer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mLancasterStemmer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mPorterStemmer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWordNetLemmatizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWordNetLemmatizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "### import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import os \n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from nltk.stem import SnowballStemmer,LancasterStemmer,PorterStemmer, WordNetLemmatizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk import pos_tag\n",
    "from collections import Counter \n",
    "import re\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\574977\\\\PycharmProjects\\\\pepsico\\\\fsha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1=pd.read_csv('pesico.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Allergen_text</th>\n",
       "      <th>Label_text</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Tag_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.xlsx</td>\n",
       "      <td>['Allergens in seasonings:\\nCQ69 Vegetable Ble...</td>\n",
       "      <td>[\"Star Hyper Cheese\\nCheese flavoured maize sn...</td>\n",
       "      <td>['Yes']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.xlsx</td>\n",
       "      <td>['Allergens in seasonings:\\nCQ69 Vegetable Ble...</td>\n",
       "      <td>[\"Star Hyper Cheese\\nCheese flavoured maize sn...</td>\n",
       "      <td>['Yes']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3.xlsx</td>\n",
       "      <td>['Allergens in seasonings:\\nCQ69 Vegetable Ble...</td>\n",
       "      <td>[\"Star Hyper Cheese\\nCheese flavoured maize sn...</td>\n",
       "      <td>['Yes']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4.xlsx</td>\n",
       "      <td>['Allergens in seasonings:\\nCQ69 Vegetable Ble...</td>\n",
       "      <td>[\"Star Hyper Cheese\\nCheese flavoured maize sn...</td>\n",
       "      <td>['No']</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>46565 FSHA 5.4.1Star Project G3 v2 _ FS input2...</td>\n",
       "      <td>['Allergens in seasonings:\\nCQ69 Vegetable Ble...</td>\n",
       "      <td>[\"Star Hyper Cheese\\nCheese flavoured maize sn...</td>\n",
       "      <td>['No']</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           Filename  \\\n",
       "0           0                                             1.xlsx   \n",
       "1           1                                             2.xlsx   \n",
       "2           2                                             3.xlsx   \n",
       "3           3                                             4.xlsx   \n",
       "4           4  46565 FSHA 5.4.1Star Project G3 v2 _ FS input2...   \n",
       "\n",
       "                                       Allergen_text  \\\n",
       "0  ['Allergens in seasonings:\\nCQ69 Vegetable Ble...   \n",
       "1  ['Allergens in seasonings:\\nCQ69 Vegetable Ble...   \n",
       "2  ['Allergens in seasonings:\\nCQ69 Vegetable Ble...   \n",
       "3  ['Allergens in seasonings:\\nCQ69 Vegetable Ble...   \n",
       "4  ['Allergens in seasonings:\\nCQ69 Vegetable Ble...   \n",
       "\n",
       "                                          Label_text      Tag  Tag_key  \n",
       "0  [\"Star Hyper Cheese\\nCheese flavoured maize sn...  ['Yes']        1  \n",
       "1  [\"Star Hyper Cheese\\nCheese flavoured maize sn...  ['Yes']        1  \n",
       "2  [\"Star Hyper Cheese\\nCheese flavoured maize sn...  ['Yes']        1  \n",
       "3  [\"Star Hyper Cheese\\nCheese flavoured maize sn...   ['No']        0  \n",
       "4  [\"Star Hyper Cheese\\nCheese flavoured maize sn...   ['No']        0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\574977\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([\"['allergens','seasonings','vegetable','blend','mccormick','milk','lactose','cheese','symrise','milk','glucose','','product','may','contain','peanut','nexisting','allergens','manufacturing','plant','celery','cereals','containing','gluten','wheat','barley','oats','milk','mustard','peanuts','soya','nexisting','allergens','production','line','celery','cereals','containing','gluten','wheat','barley','milk','mustard','peanuts','soya']\",\n",
       "       \"['allergens','seasonings','vegetable','blend','mccormick','milk','lactose','butter','symrise','milk','lactose','','product','may','contain','peanut','nexisting','allergens','manufacturing','plant','celery','cereals','containing','gluten','wheat','barley','oats','milk','mustard','peanuts','soya','nexisting','allergens','production','line','celery','cereals','containing','gluten','wheat','barley','milk','mustard','peanuts','soya']\",\n",
       "       \"['allergens','seasonings','vegetable','blend','mccormick','milk','lactose','cheese','symrise','milk','lactose','','product','may','contain','peanut','nexisting','allergens','manufacturing','plant','celery','cereals','containing','gluten','wheat','barley','urad','milk','mustard','peanuts','soya','nexisting','allergens','production','line','celery','cereals','containing','gluten','wheat','barley','milk','mustard','peanuts','soya']\",\n",
       "       \"['allergens','seasonings','vegetable','blend','mccormick','milk','lactose','cheese','symrise','milk','lactose','','product','may','contain','peanut','nexisting','allergens','manufacturing','plant','celery','cereals','containing','gluten','wheat','barley','oats','milk','mustard','peanuts','soya','nexisting','allergens','production','line','celery','cereals','containing','gluten','wheat','barley','milk','sunflower','peanuts','soya']\",\n",
       "       \"['allergens','seasonings','vegetable','blend','mccormick','milk','lactose','cheese','symrise','milk','lactose','','product','may','contain','peanut','nexisting','allergens','manufacturing','plant','celery','cereals','containing','gluten','wheat','barley','oats','milk','mustard','peanuts','soya','nexisting','allergens','production','line','celery','cereals','containing','gluten','wheat','barley','milk','mustard','peanuts','soya']\",\n",
       "       \"['allergens','seasonings','vegetable','blend','mccormick','milk','lactose','cheese','symrise','milk','lactose','','product','may','contain','peanut','nexisting','allergens','manufacturing','plant','celery','cereals','containing','gluten','wheat','barley','oats','milk','mustard','peanuts','soya','nexisting','allergens','production','line','celery','cereals','containing','gluten','wheat','barley','milk','mustard','groundnut','soya']\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#text processing step\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stop= set(STOPWORDS)\n",
    "df1['aller_key']=df1['Allergen_text'].str.lower().str.split()\n",
    "df1['aller_key']=df1['aller_key'].apply(lambda x: [item for item in x if item not in stop])\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "df1['aller_key']=df1['aller_key'].apply(lambda x: tokenizer.tokenize(str(x)))\n",
    "df1['aller_key']=df1['aller_key'].apply(lambda x: [w for w in x if len(w)>2])\n",
    "df1['aller_key']=df1['aller_key'].apply(lambda x: re.sub(\"nthe\",\"\",str(x)))\n",
    "df1['aller_key']=df1['aller_key'].apply(lambda x: re.sub('\\S*\\d\\S*',\"\",x).strip())\n",
    "df1['aller_key']=df1['aller_key'].apply(lambda x: re.sub(' ',\"\",str(x)).strip())\n",
    "#df1['aller_key']=df1['aller_key'].apply(lambda x: x.collocations())\n",
    "df1['aller_key'].values.flatten()\n",
    "# remove punctuation from each word\n",
    "#aller_key = [re_punc.sub( '' , w) for w in aller_key]\n",
    "# filter out stop words\n",
    "#stop_words = set(stopwords.words( 'english' ))\n",
    "#aller_key= [w for w in aller_key if not w in stop_words]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['allergens',\n",
       " 'barley',\n",
       " 'blend',\n",
       " 'butter',\n",
       " 'celery',\n",
       " 'cereals',\n",
       " 'cheese',\n",
       " 'contain',\n",
       " 'containing',\n",
       " 'glucose',\n",
       " 'gluten',\n",
       " 'groundnut',\n",
       " 'lactose',\n",
       " 'line',\n",
       " 'manufacturing',\n",
       " 'may',\n",
       " 'mccormick',\n",
       " 'milk',\n",
       " 'mustard',\n",
       " 'nexisting',\n",
       " 'oats',\n",
       " 'peanut',\n",
       " 'peanuts',\n",
       " 'plant',\n",
       " 'product',\n",
       " 'production',\n",
       " 'seasonings',\n",
       " 'soya',\n",
       " 'sunflower',\n",
       " 'symrise',\n",
       " 'urad',\n",
       " 'vegetable',\n",
       " 'wheat']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the tf-idf feature matrix\n",
    "tfidf = CountVectorizer()\n",
    "feature_matrix = tfidf.fit_transform(df1['aller_key'])\n",
    "#feature_matrix = tfidf.fit(data)\n",
    "# Show tf-idf feature matrix\n",
    "feature_matrix.toarray()\n",
    "tfidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>allergens</th>\n",
       "      <th>barley</th>\n",
       "      <th>blend</th>\n",
       "      <th>butter</th>\n",
       "      <th>celery</th>\n",
       "      <th>cereals</th>\n",
       "      <th>cheese</th>\n",
       "      <th>contain</th>\n",
       "      <th>containing</th>\n",
       "      <th>glucose</th>\n",
       "      <th>...</th>\n",
       "      <th>production</th>\n",
       "      <th>seasonings</th>\n",
       "      <th>soya</th>\n",
       "      <th>sunflower</th>\n",
       "      <th>symrise</th>\n",
       "      <th>urad</th>\n",
       "      <th>vegetable</th>\n",
       "      <th>wheat</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Tag_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.xlsx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.xlsx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.xlsx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4.xlsx</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>46565 FSHA 5.4.1Star Project G3 v2 _ FS input2...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   allergens  barley  blend  butter  celery  cereals  cheese  contain  \\\n",
       "0          3       2      1       0       2        2       1        1   \n",
       "1          3       2      1       1       2        2       0        1   \n",
       "2          3       2      1       0       2        2       1        1   \n",
       "3          3       2      1       0       2        2       1        1   \n",
       "4          3       2      1       0       2        2       1        1   \n",
       "\n",
       "   containing  glucose   ...     production  seasonings  soya  sunflower  \\\n",
       "0           2        1   ...              1           1     2          0   \n",
       "1           2        0   ...              1           1     2          0   \n",
       "2           2        0   ...              1           1     2          0   \n",
       "3           2        0   ...              1           1     2          1   \n",
       "4           2        0   ...              1           1     2          0   \n",
       "\n",
       "   symrise  urad  vegetable  wheat  \\\n",
       "0        1     0          1      2   \n",
       "1        1     0          1      2   \n",
       "2        1     1          1      2   \n",
       "3        1     0          1      2   \n",
       "4        1     0          1      2   \n",
       "\n",
       "                                            Filename  Tag_key  \n",
       "0                                             1.xlsx        1  \n",
       "1                                             2.xlsx        1  \n",
       "2                                             3.xlsx        1  \n",
       "3                                             4.xlsx        0  \n",
       "4  46565 FSHA 5.4.1Star Project G3 v2 _ FS input2...        0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=pd.DataFrame(feature_matrix.toarray(), columns=tfidf.get_feature_names())\n",
    "df2['Filename']=df1['Filename']\n",
    "df2['Tag_key']=df1['Tag_key']\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
