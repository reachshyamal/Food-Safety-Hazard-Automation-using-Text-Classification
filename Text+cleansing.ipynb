{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#os.chdir('C:\\\\Users\\\\725191\\\\Desktop\\\\PepsiCo FSHA data\\\\to be combined')\n",
    "import nltk\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "#file_content = open(\"Allergen data.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\103467\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "import string\n",
    "exclude = set(string.punctuation) \n",
    "wpt = nltk.WordPunctTokenizer()\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "#newStopWords = ['lb','j','df','jdf']\n",
    "#stop_words.extend(newStopWords)\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "\n",
    "def normalize_document(doc):\n",
    "    # lower case and remove special characters\\whitespaces\n",
    "   # doc = re.sub(r'[^a-zA-Z0-9\\s]', '', doc, re.I)\n",
    "   # doc = doc.lower()\n",
    "   # doc = doc.strip()\n",
    "    # tokenize document\n",
    "    tokens = doc.split()\n",
    "    # remove punctuation from each word\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "    #wpt.tokenize(doc)\n",
    "    # convert to lower case\n",
    "    lower_tokens = [w.lower() for w in tokens]\n",
    "    #remove spaces\n",
    "    stripped = [w.strip() for w in lower_tokens]\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    words = [word for word in stripped if word.isalpha()]\n",
    "    # filter stopwords out of document\n",
    "    filtered_tokens = [token for token in words if token not in stop_words]\n",
    "    #apply Stemming\n",
    "    #stemmed = [porter.stem(word) for word in filtered_tokens]\n",
    "    # re-create document from filtered tokens\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "    return doc\n",
    "\n",
    "normalize_corpus = np.vectorize(normalize_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "norm_corpus = normalize_corpus(file_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array('allergens seasonings vegetable blend mccormick milk lactose cheese symrise milk lactose product may contain peanut existing allergens manufacturing plant celery cereals containing gluten wheat barley oats milk mustard existing allergens production line celery cereals containing gluten wheat barley milk mustard allergens seasonings vegetable blend mccormick milk lactose cheese symrise milk lactose product may contain peanut existing allergens manufacturing plant celery cereals containing gluten wheat barley oats milk mustard peanuts existing allergens production line celery cereals containing gluten wheat barley milk mustard peanuts allergens seasonings vegetable blend mccormick milk fruit cheese symrise milk fruit product may contain peanut existing allergens manufacturing plant celery cereals containing gluten wheat barley oats milk mustard existing allergens production line celery cereals containing gluten wheat barley milk mustard allergens seasonings vegetable blend mccormick milk cheese symrise milk product may contain peanut existing allergens manufacturing plant celery cereals containing gluten wheat barley oats milk mustard existing allergens production line celery cereals containing gluten wheat barley milk mustard allergens seasonings vegetable blend mccormick milk fruit juice cheese symrise milk fruit juice product may contain peanut existing allergens manufacturing plant celery cereals containing gluten wheat barley oats milk mustard pineapple existing allergens production line celery cereals containing gluten wheat barley milk mustard pineapple allergens seasonings vegetable blend mccormick milk fruit juice cheese symrise milk fruit juice product may contain peanut existing allergens manufacturing plant celery cereals containing gluten wheat barley oats milk mustard existing allergens production line celery cereals containing gluten wheat barley milk mustard',\n",
       "      dtype='<U1903')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "#newStopWords = ['lb','j','df','jdf']\n",
    "#stop_words.extend(newStopWords)\n",
    "wpt = nltk.WordPunctTokenizer()\n",
    "\n",
    "def normalize_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    # convert to lower case\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    # remove punctuation from each word\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    stripped = [w.translate(table) for w in tokens]\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    words = [word for word in stripped if word.isalpha()]\n",
    "    # filter out stop words\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    #print(words[:100])\n",
    "    doc = ' '.join(words)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_text = normalize_text(str(norm_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'allergens seasonings vegetable blend mccormick milk lactose cheese symrise milk lactose product may contain peanut existing allergens manufacturing plant celery cereals containing gluten wheat barley oats milk mustard existing allergens production line celery cereals containing gluten wheat barley milk mustard allergens seasonings vegetable blend mccormick milk lactose cheese symrise milk lactose product may contain peanut existing allergens manufacturing plant celery cereals containing gluten wheat barley oats milk mustard peanuts existing allergens production line celery cereals containing gluten wheat barley milk mustard peanuts allergens seasonings vegetable blend mccormick milk fruit cheese symrise milk fruit product may contain peanut existing allergens manufacturing plant celery cereals containing gluten wheat barley oats milk mustard existing allergens production line celery cereals containing gluten wheat barley milk mustard allergens seasonings vegetable blend mccormick milk cheese symrise milk product may contain peanut existing allergens manufacturing plant celery cereals containing gluten wheat barley oats milk mustard existing allergens production line celery cereals containing gluten wheat barley milk mustard allergens seasonings vegetable blend mccormick milk fruit juice cheese symrise milk fruit juice product may contain peanut existing allergens manufacturing plant celery cereals containing gluten wheat barley oats milk mustard pineapple existing allergens production line celery cereals containing gluten wheat barley milk mustard pineapple allergens seasonings vegetable blend mccormick milk fruit juice cheese symrise milk fruit juice product may contain peanut existing allergens manufacturing plant celery cereals containing gluten wheat barley oats milk mustard existing allergens production line celery cereals containing gluten wheat barley milk mustard'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Pepsico\\pos\\#46565 FSHA 5.4.1Star Project G3 v2 + FS input2_1_yes.xlsx.txt\n",
      "D:\\Pepsico\\pos\\#46565 FSHA 5.4.1Star Project G3 v2 + FS input2_2_yes.xlsx.txt\n",
      "D:\\Pepsico\\pos\\#46565 FSHA 5.4.1Star Project G3 v2 + FS input2_3_yes.xlsx.txt\n",
      "D:\\Pepsico\\neg\\#46565 FSHA 5.4.1Star Project G3 v2 + FS input2_1_no.xlsx.txt\n",
      "D:\\Pepsico\\neg\\#46565 FSHA 5.4.1Star Project G3 v2 + FS input2_2_no.xlsx.txt\n",
      "D:\\Pepsico\\neg\\#46565 FSHA 5.4.1Star Project G3 v2 + FS input2_3_no.xlsx.txt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Allergens in seasonings:\\n\\nCQ69 Vegetable Bl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Allergens in seasonings:\\n\\nCQ69 Vegetable Bl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Allergens in seasonings:\\n\\nCQ69 Vegetable Bl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Allergens in seasonings:\\n\\nCQ69 Vegetable Bl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Allergens in seasonings:\\n\\nCQ69 Vegetable Bl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  target\n",
       "0  \"Allergens in seasonings:\\n\\nCQ69 Vegetable Bl...       0\n",
       "1  \"Allergens in seasonings:\\n\\nCQ69 Vegetable Bl...       1\n",
       "2  \"Allergens in seasonings:\\n\\nCQ69 Vegetable Bl...       0\n",
       "3  \"Allergens in seasonings:\\n\\nCQ69 Vegetable Bl...       1\n",
       "4  \"Allergens in seasonings:\\n\\nCQ69 Vegetable Bl...       0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "# Load all files from a directory in a DataFrame.\n",
    "def load_directory_data(directory):\n",
    "    data = {}\n",
    "    data[\"sentence\"] = []\n",
    "    for file_path in os.listdir(directory):\n",
    "        print(os.path.join(directory, file_path))\n",
    "        #print(file_path)\n",
    "        with open(os.path.join(directory, file_path),encoding=\"utf-8\") as f:\n",
    "            data[\"sentence\"].append(f.read())\n",
    "    return pd.DataFrame.from_dict(data)\n",
    "\n",
    "# Merge positive and negative examples, add a polarity column and shuffle.\n",
    "def load_dataset(directory):\n",
    "    pos_df = load_directory_data(os.path.join(directory, \"pos\"))\n",
    "    neg_df = load_directory_data(os.path.join(directory, \"neg\"))\n",
    "    pos_df[\"target\"] = 1\n",
    "    neg_df[\"target\"] = 0\n",
    "    return pd.concat([pos_df, neg_df]).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "train_df = load_dataset(\"D:\\Pepsico\")\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Allergens in seasonings:\\n\\nCQ69 Vegetable Blend, McCormick - milk, lactose\\n\\n2763030 Cheese, Symrise - milk, lactose\\n\\n\\n\\nThe product may contain peanut.\\n\\nExisting allergens in manufacturing plant: celery, cereals containing gluten (wheat, barley, oats), milk, mustard\\n\\nExisting allergens on production line: celery, cereals containing gluten (wheat, barley), milk, mustard\" 0\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_text = train_df['sentence'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Allergens in seasonings:\\n\\nCQ69 Vegetable Blend, McCormick - milk fruit juice\\n\\n2763030 Cheese, Symrise - milk fruit juice\\n\\n\\n\\nThe product may contain peanut.\\n\\nExisting allergens in manufacturing plant: celery, cereals containing gluten (wheat, barley, oats), milk, mustard pineapple\\n\\nExisting allergens on production line: celery, cereals containing gluten (wheat, barley), milk, mustard pineapple\" 0\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "norm_clean_text = normalize_corpus(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'allergens seasonings vegetable blend mccormick milk lactose cheese symrise milk lactose product may contain peanut existing allergens manufacturing plant celery cereals containing gluten wheat barley oats milk mustard peanuts existing allergens production line celery cereals containing gluten wheat barley milk mustard peanuts'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_clean_text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels = train_df[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    0\n",
       "3    1\n",
       "4    0\n",
       "5    1\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "# Vectorization parameters\n",
    "\n",
    "# Range (inclusive) of n-gram sizes for tokenizing text.\n",
    "NGRAM_RANGE = (1, 2)\n",
    "\n",
    "# Limit on the number of features. We use the top 20K features.\n",
    "TOP_K = 20000\n",
    "\n",
    "# Whether text should be split into word or character n-grams.\n",
    "# One of 'word', 'char'.\n",
    "TOKEN_MODE = 'word'\n",
    "\n",
    "# Minimum document/corpus frequency below which a token will be discarded.\n",
    "MIN_DOCUMENT_FREQUENCY = 2\n",
    "\n",
    "# Limit on the length of text sequences. Sequences longer than this\n",
    "# will be truncated.\n",
    "MAX_SEQUENCE_LENGTH = 500\n",
    "\n",
    "\n",
    "def ngram_vectorize(train_texts, train_labels, val_texts):\n",
    "    \"\"\"Vectorizes texts as ngram vectors.\n",
    "\n",
    "    1 text = 1 tf-idf vector the length of vocabulary of uni-grams + bi-grams.\n",
    "\n",
    "    # Arguments\n",
    "        train_texts: list, training text strings.\n",
    "        train_labels: np.ndarray, training labels.\n",
    "        val_texts: list, validation text strings.\n",
    "\n",
    "    # Returns\n",
    "        x_train, x_val: vectorized training and validation texts\n",
    "    \"\"\"\n",
    "    # Create keyword arguments to pass to the 'tf-idf' vectorizer.\n",
    "    kwargs = {\n",
    "            'ngram_range': NGRAM_RANGE,  # Use 1-grams + 2-grams.\n",
    "            'dtype': 'int32',\n",
    "            'strip_accents': 'unicode',\n",
    "            'decode_error': 'replace',\n",
    "            'analyzer': TOKEN_MODE,  # Split text into word tokens.\n",
    "            'min_df': MIN_DOCUMENT_FREQUENCY,\n",
    "    }\n",
    "    vectorizer = TfidfVectorizer(**kwargs)\n",
    "\n",
    "    # Learn vocabulary from training texts and vectorize training texts.\n",
    "    x_train = vectorizer.fit_transform(train_texts)\n",
    "\n",
    "    # Vectorize validation texts.\n",
    "    x_val = vectorizer.transform(val_texts)\n",
    "\n",
    "    # Select top 'k' of the vectorized features.\n",
    "    selector = SelectKBest(f_classif, k=min(TOP_K, x_train.shape[1]))\n",
    "    selector.fit(x_train, train_labels)\n",
    "    x_train = selector.transform(x_train)\n",
    "    x_val = selector.transform(x_val)\n",
    "\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_val = x_val.astype('float32')\n",
    "    return x_train, x_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\103467\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "C:\\Users\\103467\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "# Vectorize texts.\n",
    "x_train, x_test = ngram_vectorize(norm_clean_text, train_labels, [\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 63)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t0.24026059\n",
      "  (0, 1)\t0.08008686\n",
      "  (0, 2)\t0.08008686\n",
      "  (0, 3)\t0.08008686\n",
      "  (0, 4)\t0.16017371\n",
      "  (0, 5)\t0.08008686\n",
      "  (0, 6)\t0.08008686\n",
      "  (0, 7)\t0.08008686\n",
      "  (0, 8)\t0.08008686\n",
      "  (0, 9)\t0.16017371\n",
      "  (0, 10)\t0.16017371\n",
      "  (0, 11)\t0.16017371\n",
      "  (0, 12)\t0.16017371\n",
      "  (0, 13)\t0.08008686\n",
      "  (0, 14)\t0.08008686\n",
      "  (0, 15)\t0.08008686\n",
      "  (0, 16)\t0.08008686\n",
      "  (0, 17)\t0.16017371\n",
      "  (0, 18)\t0.16017371\n",
      "  (0, 19)\t0.16017371\n",
      "  (0, 20)\t0.16017371\n",
      "  (0, 23)\t0.16017371\n",
      "  (0, 24)\t0.16017371\n",
      "  (0, 28)\t0.29588857\n",
      "  (0, 29)\t0.14794429\n",
      "  :\t:\n",
      "  (0, 37)\t0.08008686\n",
      "  (0, 38)\t0.08008686\n",
      "  (0, 39)\t0.32034743\n",
      "  (0, 41)\t0.29588857\n",
      "  (0, 42)\t0.16017371\n",
      "  (0, 43)\t0.16017371\n",
      "  (0, 44)\t0.10703386\n",
      "  (0, 45)\t0.08008686\n",
      "  (0, 46)\t0.08008686\n",
      "  (0, 47)\t0.08008686\n",
      "  (0, 48)\t0.08008686\n",
      "  (0, 49)\t0.08008686\n",
      "  (0, 50)\t0.08008686\n",
      "  (0, 51)\t0.08008686\n",
      "  (0, 52)\t0.08008686\n",
      "  (0, 53)\t0.08008686\n",
      "  (0, 54)\t0.08008686\n",
      "  (0, 55)\t0.08008686\n",
      "  (0, 56)\t0.08008686\n",
      "  (0, 57)\t0.08008686\n",
      "  (0, 58)\t0.08008686\n",
      "  (0, 59)\t0.08008686\n",
      "  (0, 60)\t0.08008686\n",
      "  (0, 61)\t0.16017371\n",
      "  (0, 62)\t0.16017371\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Use CountVectorizer\n",
    "\n",
    "#Display Freq plot of n-grams\n",
    "\n",
    "#Display length(no of words) distribution of samples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
