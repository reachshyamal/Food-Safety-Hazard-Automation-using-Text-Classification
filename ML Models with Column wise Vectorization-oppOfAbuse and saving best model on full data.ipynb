{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook reads text data from data extract created from FSHA Forms and runs predictive Models to predict the value 'Are there any opp of Abuse?' , based on the Input Data\n",
    "# It does vectorization of each Column and concatenates these Vectors to create a final Feature Vector and fits the best ML Model from benchmarking study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import all necessary modules\n",
    "from __future__ import print_function\n",
    "import logging\n",
    "from optparse import OptionParser\n",
    "import sys\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import nltk\n",
    "import string\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import re\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from scipy import signal\n",
    "import random\n",
    "import string\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_selection import f_classif\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.svm import SVC \n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn import linear_model\n",
    "from sklearn.utils.extmath import density\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File name and other important parameters like ngram_range set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#These parameters will be input from command line\n",
    "ngram_range_inp=(1,2)\n",
    "filename = \"C:/Pepsico/Base LCS Files Extract_28 Aug 2019_207Files.xlsm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename1 = \"C:/Pepsico/MLextracts_abuseByConsumer 08 26.xlsm\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define reusable modular method for Text Normalization (removal of stopwords, changing to lower case, removal of punctuation etc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "\n",
    "tokenizer = ToktokTokenizer()\n",
    "stopword_list = nltk.corpus.stopwords.words('english')\n",
    "stopword_list.remove('no')\n",
    "stopword_list.remove('not')\n",
    "def strip_html_tags(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    stripped_text = soup.get_text()\n",
    "    return stripped_text\n",
    "def remove_accented_chars(text):\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return text\n",
    "\n",
    "def remove_special_characters(text):\n",
    "    text = re.sub('[^a-zA-z0-9\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "def remove_stopwords(text, is_lower_case=False):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    if is_lower_case:\n",
    "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    else:\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text\n",
    "def normalize_corpus(corpus, html_stripping=True, contraction_expansion=True,\n",
    "                     accented_char_removal=True, text_lower_case=True, \n",
    "                     text_lemmatization=True, special_char_removal=True, \n",
    "                     stopword_removal=True):\n",
    "    \n",
    "    normalized_corpus = []\n",
    "    # normalize each document in the corpus\n",
    "    #corpus = str(corpus)\n",
    "    for doc in corpus:\n",
    "        # strip HTML\n",
    "        if html_stripping:\n",
    "            doc = strip_html_tags(doc)\n",
    "        # remove accented characters\n",
    "        if accented_char_removal:\n",
    "            doc = remove_accented_chars(doc)\n",
    "\n",
    "        # lowercase the text    \n",
    "        if text_lower_case:\n",
    "            doc = doc.lower()\n",
    "        # remove extra newlines\n",
    "        doc = re.sub(r'[\\r|\\n|\\r\\n]+', ' ',doc)\n",
    "        # insert spaces between special characters to isolate them    \n",
    "        special_char_pattern = re.compile(r'([{.(-)!}])')\n",
    "        doc = special_char_pattern.sub(\" \\\\1 \", doc)\n",
    "        # remove special characters    \n",
    "        if special_char_removal:\n",
    "            doc = remove_special_characters(doc)  \n",
    "        # remove extra whitespace\n",
    "        doc = re.sub(' +', ' ', doc)\n",
    "        # remove stopwords\n",
    "        if stopword_removal:\n",
    "            doc = remove_stopwords(doc, is_lower_case=text_lower_case)\n",
    "            \n",
    "        normalized_corpus.append(doc)\n",
    "        \n",
    "    return normalized_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the data extract file (tabular format with Input data(X) and target(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fsha_data = pd.read_excel(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fsha_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fsha_data = fsha_data[(fsha_data['abuseByConsumer']=='No')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fsha_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fsha_data_yes = pd.read_excel(filename1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fsha_data_yes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fsha_data = pd.concat([fsha_data,fsha_data_yes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fsha_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     204\n",
       "Yes     23\n",
       "Name: abuseByConsumer, dtype: int64"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fsha_data.abuseByConsumer.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File Name</th>\n",
       "      <th>projName</th>\n",
       "      <th>accolNumber</th>\n",
       "      <th>PDA_projName</th>\n",
       "      <th>projType</th>\n",
       "      <th>projDesc</th>\n",
       "      <th>formulaNumber</th>\n",
       "      <th>owner</th>\n",
       "      <th>sector</th>\n",
       "      <th>center</th>\n",
       "      <th>...</th>\n",
       "      <th>prodModifications</th>\n",
       "      <th>newIngredient</th>\n",
       "      <th>approvedPackage</th>\n",
       "      <th>potentialMicrobial</th>\n",
       "      <th>crossContactAllergens</th>\n",
       "      <th>chokeHazard</th>\n",
       "      <th>operationalAllergen</th>\n",
       "      <th>abuseByConsumer</th>\n",
       "      <th>cookstepByConsumer</th>\n",
       "      <th>allergensLabeledIMAF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FSHA 46694 Lays Ridge.xlsm</td>\n",
       "      <td>Lays Ridge launch</td>\n",
       "      <td>46694</td>\n",
       "      <td>Lay's Wavy Spring Onion, Lay's Wavy Sour Cream,</td>\n",
       "      <td>Category Reframe</td>\n",
       "      <td>Significant launch of new subline within exist...</td>\n",
       "      <td>P02806, PP03084 (PF03211)</td>\n",
       "      <td>Artur Zyśk, +48723990114</td>\n",
       "      <td>ESSA</td>\n",
       "      <td>Warsaw, Poland</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Milk, Lactose : Milk, Lactose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FSHA 5.4.1 - Doritos Sweet Chilli Pepper Na Re...</td>\n",
       "      <td>Sodium reduction Doritos Sweet Chilli Pepper I...</td>\n",
       "      <td>39660</td>\n",
       "      <td>Doritos Sweet Chilli Pepper</td>\n",
       "      <td>Refresh</td>\n",
       "      <td>Sodium reduction project to conform to Legisla...</td>\n",
       "      <td>999010432 Doritos Sweet Chilli Pepper</td>\n",
       "      <td>Sherwin Tlhoaele / Gabisile Buthelezi</td>\n",
       "      <td>ESSA</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Not Applicable : Not Applicable : Soya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FSHA 5.4.1 - Doritos Sweet Chilli Pepper Na Re...</td>\n",
       "      <td>Sodium reduction Doritos Sweet Chilli Pepper P...</td>\n",
       "      <td>39660</td>\n",
       "      <td>Doritos Sweet Chilli Pepper</td>\n",
       "      <td>Refresh</td>\n",
       "      <td>Sodium reduction project to conform to Legisla...</td>\n",
       "      <td>999010432 Doritos Sweet Chilli Pepper</td>\n",
       "      <td>Sherwin Tlhoaele / Gabisile Buthelezi</td>\n",
       "      <td>ESSA</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Not Applicable : Not Applicable : Soya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FSHA 5.4.1 - Lay's BBQ Gate 3 Prospecton 5.04....</td>\n",
       "      <td>Lay's Barbecue Flavoured Potato Chips</td>\n",
       "      <td>50169</td>\n",
       "      <td>Lay's Barbecue Flavoured Potato Chips</td>\n",
       "      <td>Refresh</td>\n",
       "      <td>New flavour for the Lay's range - Lay's Barbecue</td>\n",
       "      <td>not provided</td>\n",
       "      <td>Xolelwa Nzuzo</td>\n",
       "      <td>ESSA</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Not Applicable : Not Applicable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FSHA 5.4.1 - Simba Cheese &amp; Onion NA Reduction...</td>\n",
       "      <td>Simba Cheese &amp; Onion Sodium Reduction Isando</td>\n",
       "      <td>39660</td>\n",
       "      <td>Simba Cheese &amp; Onion</td>\n",
       "      <td>Renovation</td>\n",
       "      <td>Sodium Reduction Project to conform to Legisla...</td>\n",
       "      <td>Simba Potato Chips (ZBR for different flavoure...</td>\n",
       "      <td>Lizel Laubscher</td>\n",
       "      <td>ESSA</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Not Applicable : Not Applicable : Dairy (Cows ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           File Name  \\\n",
       "0                         FSHA 46694 Lays Ridge.xlsm   \n",
       "1  FSHA 5.4.1 - Doritos Sweet Chilli Pepper Na Re...   \n",
       "2  FSHA 5.4.1 - Doritos Sweet Chilli Pepper Na Re...   \n",
       "3  FSHA 5.4.1 - Lay's BBQ Gate 3 Prospecton 5.04....   \n",
       "4  FSHA 5.4.1 - Simba Cheese & Onion NA Reduction...   \n",
       "\n",
       "                                            projName accolNumber  \\\n",
       "0                                  Lays Ridge launch       46694   \n",
       "1  Sodium reduction Doritos Sweet Chilli Pepper I...       39660   \n",
       "2  Sodium reduction Doritos Sweet Chilli Pepper P...       39660   \n",
       "3              Lay's Barbecue Flavoured Potato Chips       50169   \n",
       "4       Simba Cheese & Onion Sodium Reduction Isando       39660   \n",
       "\n",
       "                                       PDA_projName          projType  \\\n",
       "0  Lay's Wavy Spring Onion, Lay's Wavy Sour Cream,   Category Reframe   \n",
       "1                       Doritos Sweet Chilli Pepper          Refresh    \n",
       "2                       Doritos Sweet Chilli Pepper          Refresh    \n",
       "3             Lay's Barbecue Flavoured Potato Chips           Refresh   \n",
       "4                              Simba Cheese & Onion        Renovation   \n",
       "\n",
       "                                            projDesc  \\\n",
       "0  Significant launch of new subline within exist...   \n",
       "1  Sodium reduction project to conform to Legisla...   \n",
       "2  Sodium reduction project to conform to Legisla...   \n",
       "3   New flavour for the Lay's range - Lay's Barbecue   \n",
       "4  Sodium Reduction Project to conform to Legisla...   \n",
       "\n",
       "                                       formulaNumber  \\\n",
       "0                         P02806, PP03084 (PF03211)    \n",
       "1              999010432 Doritos Sweet Chilli Pepper   \n",
       "2              999010432 Doritos Sweet Chilli Pepper   \n",
       "3                                       not provided   \n",
       "4  Simba Potato Chips (ZBR for different flavoure...   \n",
       "\n",
       "                                    owner sector          center  \\\n",
       "0                Artur Zyśk, +48723990114   ESSA  Warsaw, Poland   \n",
       "1  Sherwin Tlhoaele / Gabisile Buthelezi    ESSA    South Africa   \n",
       "2  Sherwin Tlhoaele / Gabisile Buthelezi    ESSA    South Africa   \n",
       "3                           Xolelwa Nzuzo   ESSA    South Africa   \n",
       "4                         Lizel Laubscher   ESSA    South Africa   \n",
       "\n",
       "                         ...                         prodModifications  \\\n",
       "0                        ...                                        No   \n",
       "1                        ...                                        No   \n",
       "2                        ...                                        No   \n",
       "3                        ...                                        No   \n",
       "4                        ...                                        No   \n",
       "\n",
       "  newIngredient approvedPackage potentialMicrobial crossContactAllergens  \\\n",
       "0           Yes              No                 No                   Yes   \n",
       "1            No              No                 No                    No   \n",
       "2            No              No                 No                    No   \n",
       "3           Yes              No                 No                   Yes   \n",
       "4            No              No                 No                   Yes   \n",
       "\n",
       "  chokeHazard operationalAllergen abuseByConsumer cookstepByConsumer  \\\n",
       "0          No                 Yes              No                 No   \n",
       "1          No                 Yes              No                 No   \n",
       "2          No                 Yes              No                 No   \n",
       "3          No                 Yes              No                 No   \n",
       "4          No                 Yes              No                 No   \n",
       "\n",
       "                                allergensLabeledIMAF  \n",
       "0                      Milk, Lactose : Milk, Lactose  \n",
       "1             Not Applicable : Not Applicable : Soya  \n",
       "2             Not Applicable : Not Applicable : Soya  \n",
       "3                    Not Applicable : Not Applicable  \n",
       "4  Not Applicable : Not Applicable : Dairy (Cows ...  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fsha_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Based on Analysis select the Features (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#selecting set of columns as Features\n",
    "fsha_data.fillna('NA', inplace=True)\n",
    "features_df=fsha_data[['PDA_projName', 'projDesc','formulaNumber','CPD-ProdName-Desc','packMaterial','prodStorageDist','shelfLife',\n",
    "    'TCG','cookedOrHeated', 'specificStorage','labelingInstructions','mishandled','targetMarket','approvedPackage']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_str(x):\n",
    "   \n",
    "    x=str(x)\n",
    "    x=x.lower()\n",
    "    return (x)\n",
    "\n",
    "features_df['PDA_projName']=features_df['PDA_projName'].apply(lambda x:conv_str(x))  \n",
    "features_df['projDesc']=features_df['projDesc'].apply(lambda x:conv_str(x))\n",
    "features_df['formulaNumber']=features_df['formulaNumber'].apply(lambda x:conv_str(x)) \n",
    "features_df['packMaterial']=features_df['packMaterial'].apply(lambda x:conv_str(x))  \n",
    "features_df['CPD-ProdName-Desc']=features_df['CPD-ProdName-Desc'].apply(lambda x:conv_str(x))  \n",
    "features_df['prodStorageDist']=features_df['prodStorageDist'].apply(lambda x:conv_str(x)) \n",
    "features_df['shelfLife']=features_df['shelfLife'].apply(lambda x:conv_str(x))  \n",
    "features_df['TCG']=features_df['TCG'].apply(lambda x:conv_str(x)) \n",
    "features_df['cookedOrHeated']=features_df['cookedOrHeated'].apply(lambda x:conv_str(x)) \n",
    "features_df['specificStorage']=features_df['specificStorage'].apply(lambda x:conv_str(x)) \n",
    "features_df['labelingInstructions']=features_df['labelingInstructions'].apply(lambda x:conv_str(x)) \n",
    "features_df['mishandled']=features_df['mishandled'].apply(lambda x:conv_str(x))  \n",
    "features_df['targetMarket']=features_df['targetMarket'].apply(lambda x:conv_str(x)) \n",
    "features_df['approvedPackage']=features_df['approvedPackage'].apply(lambda x:conv_str(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define reusable code to Vectorize Text columns (ex:targetMarket) using TF-IDF Vectorizer, after doing Text data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vectorization of text data using TF-IDF Vectorizer\n",
    "\n",
    "# Whether text should be split into word or character n-grams.\n",
    "# One of 'word', 'char'.\n",
    "TOKEN_MODE = 'word'\n",
    "\n",
    "# Minimum document/corpus frequency below which a token will be discarded.\n",
    "MIN_DOCUMENT_FREQUENCY = 2\n",
    "\n",
    "# Limit on the length of text sequences. Sequences longer than this\n",
    "# will be truncated.\n",
    "MAX_SEQUENCE_LENGTH = 500\n",
    "ngram_range = n_gram_range\n",
    "n_gram_range = (1,2)\n",
    "kwargs = {\n",
    "            'ngram_range': ngram_range,  # Use 1-grams + 2-grams.\n",
    "            'dtype': 'int32',\n",
    "            'strip_accents': 'unicode',\n",
    "            'decode_error': 'replace',\n",
    "            'analyzer': TOKEN_MODE,  # Split text into word tokens.\n",
    "            'min_df': MIN_DOCUMENT_FREQUENCY,\n",
    "    }\n",
    "vectorizer = TfidfVectorizer(**kwargs)\n",
    "\n",
    "def ngram_vectorize(train_texts, train_labels,ngram_range):\n",
    "    \"\"\"Vectorizes texts as ngram vectors.\n",
    "\n",
    "    1 text = 1 tf-idf vector the length of vocabulary of uni-grams + bi-grams.\n",
    "\n",
    "    # Arguments\n",
    "        train_texts: list, training text strings.\n",
    "        train_labels: np.ndarray, training labels.\n",
    "        val_texts: list, validation text strings.\n",
    "\n",
    "    # Returns\n",
    "        x_train, x_val: vectorized training and validation texts\n",
    "    \"\"\"\n",
    "    # Create keyword arguments to pass to the 'tf-idf' vectorizer.\n",
    "    \n",
    "\n",
    "    # Learn vocabulary from training texts and vectorize training texts.\n",
    "    x_train = vectorizer.fit_transform(train_texts)\n",
    "\n",
    "    x_train = x_train.astype('float32')\n",
    "    return x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize each column , by cleaning the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df['PDA_projName']=normalize_corpus(train_df['PDA_projName'])\n",
    "train_df['projDesc']=normalize_corpus(train_df['projDesc'])\n",
    "train_df['formulaNumber']=normalize_corpus(train_df['formulaNumber'])\n",
    "train_df['packMaterial']=normalize_corpus(train_df['packMaterial'])  \n",
    "train_df['CPD-ProdName-Desc']=normalize_corpus(train_df['CPD-ProdName-Desc'])\n",
    "train_df['prodStorageDist']=normalize_corpus(train_df['prodStorageDist'])\n",
    "train_df['shelfLife']=normalize_corpus(train_df['shelfLife'])\n",
    "train_df['TCG']=normalize_corpus(train_df['TCG'])\n",
    "train_df['cookedOrHeated']=normalize_corpus(train_df['cookedOrHeated'])\n",
    "train_df['specificStorage']=normalize_corpus(train_df['specificStorage'])\n",
    "train_df['labelingInstructions']=normalize_corpus(train_df['labelingInstructions']) \n",
    "train_df['mishandled']=normalize_corpus(train_df['mishandled']) \n",
    "train_df['targetMarket']=normalize_corpus(train_df['targetMarket'])\n",
    "train_df['approvedPackage']=normalize_corpus(train_df['approvedPackage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                       18 1 week\n",
       "1    code date 16 weeks export code date 24 weeks\n",
       "2    code date 16 weeks export code date 24 weeks\n",
       "3       16 weeks sa market 26 weeks export market\n",
       "4       16 weeks sa market 26 weeks export market\n",
       "Name: shelfLife, dtype: object"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check normalized text\n",
    "train_df['shelfLife'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binarize the target (1/0 for Yes/No)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statistics \n",
    "\n",
    "def impute_target(fsha_data,targetName):\n",
    "    train_y=[]\n",
    "    for i in range (len(fsha_data)):\n",
    "        if fsha_data[targetName].values[i]=='Yes':\n",
    "            train_y.append(1)\n",
    "        elif fsha_data[targetName].values[i]=='No':\n",
    "            train_y.append(0)\n",
    "        else:\n",
    "            train_y.append(-1)\n",
    "               \n",
    "    mode_y = statistics.mode(train_y)\n",
    "\n",
    "    for i in range (len(fsha_data)):\n",
    "        if train_y[i]==-1:\n",
    "            train_y[i] = mode_y\n",
    "            \n",
    "    return train_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target (Yes/No choice) in PDAF are converted to binary values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_y_abuse = impute_target(fsha_data,\"abuseByConsumer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df['target']=train_y_abuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    204\n",
       "1     23\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = train_df['target']\n",
    "train_df = train_df.drop('target',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform n-gram vectorization and PCA on text data, columnwise (2 components per column) and concatenate the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_gram_range = (1,2)\n",
    "n_components = 2\n",
    "whiten = False\n",
    "random_state = 42\n",
    "svd_solver=\"full\"\n",
    "pca = PCA(n_components=n_components,svd_solver=svd_solver,whiten=whiten, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "def preprocess_text(train_df,y):    \n",
    "    train_labels = y\n",
    "    x_ngram_projName=ngram_vectorize(train_df['PDA_projName'], train_labels,n_gram_range).toarray()\n",
    "    x_ngram_projDesc=ngram_vectorize(train_df['projDesc'], train_labels,n_gram_range).toarray()\n",
    "    x_ngram_formula=ngram_vectorize(train_df['formulaNumber'], train_labels,n_gram_range).toarray()\n",
    "    x_ngram_packMaterial=ngram_vectorize(train_df['packMaterial'], train_labels,n_gram_range).toarray() \n",
    "    x_ngram_CPD_ProdName_Desc=ngram_vectorize(train_df['CPD-ProdName-Desc'], train_labels,n_gram_range).toarray()\n",
    "    x_ngram_prodStorageDist=ngram_vectorize(train_df['prodStorageDist'], train_labels,n_gram_range).toarray()\n",
    "    x_ngram_shelfLife=ngram_vectorize(train_df['shelfLife'], train_labels,n_gram_range).toarray()\n",
    "    x_ngram_TCG=ngram_vectorize(train_df['TCG'], train_labels,n_gram_range).toarray() \n",
    "    x_ngram_cookedOrHeated=ngram_vectorize(train_df['cookedOrHeated'], train_labels,n_gram_range).toarray() \n",
    "    x_ngram_specificStorage=ngram_vectorize(train_df['specificStorage'], train_labels,n_gram_range).toarray() \n",
    "    x_ngram_labelingInstructions=ngram_vectorize(train_df['labelingInstructions'], train_labels,n_gram_range).toarray()\n",
    "    x_ngram_mishandled=ngram_vectorize(train_df['mishandled'], train_labels,n_gram_range).toarray() \n",
    "    x_ngram_targetMarket=ngram_vectorize(train_df['targetMarket'], train_labels,n_gram_range).toarray()\n",
    "    x_ngram_approvedPackage=ngram_vectorize(train_df['approvedPackage'], train_labels,n_gram_range).toarray()\n",
    "    train_df = train_df.drop(['PDA_projName','projDesc','formulaNumber','packMaterial','CPD-ProdName-Desc','prodStorageDist','shelfLife','TCG','cookedOrHeated','specificStorage','labelingInstructions','mishandled','targetMarket','approvedPackage'],axis=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    x_ngram_projName = scaler.fit_transform(x_ngram_projName)\n",
    "    x_ngram_projDesc = scaler.fit_transform(x_ngram_projDesc)\n",
    "    x_ngram_formula = scaler.fit_transform(x_ngram_formula)\n",
    "    x_ngram_packMaterial = scaler.fit_transform(x_ngram_packMaterial)\n",
    "    x_ngram_CPD_ProdName_Desc = scaler.fit_transform(x_ngram_CPD_ProdName_Desc)\n",
    "    x_ngram_prodStorageDist = scaler.fit_transform(x_ngram_prodStorageDist)\n",
    "    x_ngram_shelfLife = scaler.fit_transform(x_ngram_shelfLife)\n",
    "    x_ngram_TCG = scaler.fit_transform(x_ngram_TCG)\n",
    "    x_ngram_cookedOrHeated = scaler.fit_transform(x_ngram_cookedOrHeated)\n",
    "    x_ngram_specificStorage = scaler.fit_transform(x_ngram_specificStorage)\n",
    "    x_ngram_labelingInstructions = scaler.fit_transform(x_ngram_labelingInstructions)\n",
    "    x_ngram_mishandled = scaler.fit_transform(x_ngram_mishandled)\n",
    "    x_ngram_targetMarket = scaler.fit_transform(x_ngram_targetMarket)\n",
    "    x_ngram_approvedPackage = scaler.fit_transform(x_ngram_approvedPackage)\n",
    "    \n",
    "    x_pca_projName = pca.fit_transform(x_ngram_projName)\n",
    "    x_pca_projDesc = pca.fit_transform(x_ngram_projDesc)\n",
    "    x_pca_formula = pca.fit_transform(x_ngram_formula)\n",
    "    x_pca_packMaterial = pca.fit_transform(x_ngram_packMaterial)\n",
    "    x_pca_CPD_ProdName_Desc = pca.fit_transform(x_ngram_CPD_ProdName_Desc)\n",
    "    x_pca_prodStorageDist = pca.fit_transform(x_ngram_prodStorageDist)\n",
    "    x_pca_shelfLife = pca.fit_transform(x_ngram_shelfLife)\n",
    "    x_pca_TCG = pca.fit_transform(x_ngram_TCG)\n",
    "    x_pca_cookedOrHeated = pca.fit_transform(x_ngram_cookedOrHeated)\n",
    "    x_pca_specificStorage = pca.fit_transform(x_ngram_specificStorage)\n",
    "    x_pca_labelingInstructions = pca.fit_transform(x_ngram_labelingInstructions)\n",
    "    x_pca_mishandled = pca.fit_transform(x_ngram_mishandled)\n",
    "    x_pca_targetMarket = pca.fit_transform(x_ngram_targetMarket)\n",
    "    x_pca_approvedPackage = pca.fit_transform(x_ngram_approvedPackage)\n",
    "\n",
    "    x_train = np.concatenate((x_pca_projName,x_pca_projDesc,x_pca_formula,x_pca_packMaterial,x_pca_CPD_ProdName_Desc,\n",
    "                              x_pca_prodStorageDist,x_pca_shelfLife,x_pca_TCG,x_pca_cookedOrHeated,x_pca_specificStorage,x_pca_labelingInstructions,x_pca_mishandled,x_pca_targetMarket,x_pca_approvedPackage),axis=1)\n",
    "    print(x_train.shape)\n",
    "    return x_train  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(227, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['vectorizer_oppabuse.pkl']"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "X_features = preprocess_text(train_df,y)\n",
    "joblib.dump(scaler, \"scaler_oppabuse.pkl\")\n",
    "joblib.dump(pca, \"pca_oppabuse.pkl\")\n",
    "joblib.dump(vectorizer,\"vectorizer_oppabuse.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(227,)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y, test_size=.2, random_state=42,stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(181, 28)\n",
      "(46, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train)\n",
    "y_train = pd.DataFrame(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_train.columns = ['PCA_allergens_1','PCA_allergens_2','PCA_allergens_3','PCA_allergens_4','PCA_allergens_5','PCA_allergens_6','PCA_allergens_M_1','PCA_allergens_M_2','PCA_allergens_M_3','PCA_allergens_M_4','PCA_allergens_M_5','PCA_allergens_M_6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(181, 28)\n",
      "(181, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.213613</td>\n",
       "      <td>-0.406524</td>\n",
       "      <td>-1.628742</td>\n",
       "      <td>-0.831830</td>\n",
       "      <td>-0.519215</td>\n",
       "      <td>-0.347381</td>\n",
       "      <td>-0.413723</td>\n",
       "      <td>-0.438325</td>\n",
       "      <td>-0.752045</td>\n",
       "      <td>-0.870288</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.680027</td>\n",
       "      <td>-0.965795</td>\n",
       "      <td>-0.666259</td>\n",
       "      <td>-0.492769</td>\n",
       "      <td>0.054003</td>\n",
       "      <td>-1.758757</td>\n",
       "      <td>-1.087704</td>\n",
       "      <td>-0.150070</td>\n",
       "      <td>-0.233021</td>\n",
       "      <td>6.885145e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.452320</td>\n",
       "      <td>-0.443179</td>\n",
       "      <td>-1.439855</td>\n",
       "      <td>-0.578417</td>\n",
       "      <td>-0.519215</td>\n",
       "      <td>-0.347381</td>\n",
       "      <td>-0.413723</td>\n",
       "      <td>-0.438325</td>\n",
       "      <td>-0.705390</td>\n",
       "      <td>-0.888516</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.079985</td>\n",
       "      <td>-4.107902</td>\n",
       "      <td>-0.670338</td>\n",
       "      <td>-0.497468</td>\n",
       "      <td>0.064585</td>\n",
       "      <td>-1.576816</td>\n",
       "      <td>-0.995784</td>\n",
       "      <td>-0.125885</td>\n",
       "      <td>-0.233021</td>\n",
       "      <td>6.885145e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4.123102</td>\n",
       "      <td>43.843384</td>\n",
       "      <td>-1.668024</td>\n",
       "      <td>-1.059773</td>\n",
       "      <td>62.993397</td>\n",
       "      <td>0.936517</td>\n",
       "      <td>-0.425953</td>\n",
       "      <td>-0.447513</td>\n",
       "      <td>-1.079254</td>\n",
       "      <td>-1.833803</td>\n",
       "      <td>...</td>\n",
       "      <td>0.202513</td>\n",
       "      <td>-1.270825</td>\n",
       "      <td>-0.666259</td>\n",
       "      <td>-0.492769</td>\n",
       "      <td>0.054003</td>\n",
       "      <td>-1.758757</td>\n",
       "      <td>8.736084</td>\n",
       "      <td>-3.996828</td>\n",
       "      <td>-0.233021</td>\n",
       "      <td>6.885145e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45.237499</td>\n",
       "      <td>3.393736</td>\n",
       "      <td>4.218925</td>\n",
       "      <td>94.691284</td>\n",
       "      <td>-0.504280</td>\n",
       "      <td>-0.333946</td>\n",
       "      <td>-0.425953</td>\n",
       "      <td>-0.447513</td>\n",
       "      <td>-0.784086</td>\n",
       "      <td>-0.938204</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.680027</td>\n",
       "      <td>-0.965795</td>\n",
       "      <td>-0.666259</td>\n",
       "      <td>-0.492769</td>\n",
       "      <td>0.054003</td>\n",
       "      <td>-1.758757</td>\n",
       "      <td>-1.464820</td>\n",
       "      <td>-0.863988</td>\n",
       "      <td>-0.233021</td>\n",
       "      <td>6.885145e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.305454</td>\n",
       "      <td>-0.275335</td>\n",
       "      <td>-1.348129</td>\n",
       "      <td>-0.523758</td>\n",
       "      <td>-0.464532</td>\n",
       "      <td>-0.299139</td>\n",
       "      <td>-0.425953</td>\n",
       "      <td>-0.447513</td>\n",
       "      <td>-0.703264</td>\n",
       "      <td>0.088893</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.378168</td>\n",
       "      <td>-0.810218</td>\n",
       "      <td>-0.803340</td>\n",
       "      <td>-0.685610</td>\n",
       "      <td>-1.775446</td>\n",
       "      <td>10.869046</td>\n",
       "      <td>17.116545</td>\n",
       "      <td>-2.110739</td>\n",
       "      <td>-0.233021</td>\n",
       "      <td>6.885145e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0          1         2          3          4         5         6   \\\n",
       "0  -0.213613  -0.406524 -1.628742  -0.831830  -0.519215 -0.347381 -0.413723   \n",
       "1  -0.452320  -0.443179 -1.439855  -0.578417  -0.519215 -0.347381 -0.413723   \n",
       "2  -4.123102  43.843384 -1.668024  -1.059773  62.993397  0.936517 -0.425953   \n",
       "3  45.237499   3.393736  4.218925  94.691284  -0.504280 -0.333946 -0.425953   \n",
       "4  -0.305454  -0.275335 -1.348129  -0.523758  -0.464532 -0.299139 -0.425953   \n",
       "\n",
       "         7         8         9       ...             18        19        20  \\\n",
       "0 -0.438325 -0.752045 -0.870288      ...      -0.680027 -0.965795 -0.666259   \n",
       "1 -0.438325 -0.705390 -0.888516      ...      -1.079985 -4.107902 -0.670338   \n",
       "2 -0.447513 -1.079254 -1.833803      ...       0.202513 -1.270825 -0.666259   \n",
       "3 -0.447513 -0.784086 -0.938204      ...      -0.680027 -0.965795 -0.666259   \n",
       "4 -0.447513 -0.703264  0.088893      ...      -0.378168 -0.810218 -0.803340   \n",
       "\n",
       "         21        22         23         24        25        26            27  \n",
       "0 -0.492769  0.054003  -1.758757  -1.087704 -0.150070 -0.233021  6.885145e-08  \n",
       "1 -0.497468  0.064585  -1.576816  -0.995784 -0.125885 -0.233021  6.885145e-08  \n",
       "2 -0.492769  0.054003  -1.758757   8.736084 -3.996828 -0.233021  6.885145e-08  \n",
       "3 -0.492769  0.054003  -1.758757  -1.464820 -0.863988 -0.233021  6.885145e-08  \n",
       "4 -0.685610 -1.775446  10.869046  17.116545 -2.110739 -0.233021  6.885145e-08  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upsample the oppAbuse=Y data, since the data is highly imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# concatenate our training data back together\n",
    "X = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "# separate minority and majority classes\n",
    "not_abuse = X[X.target==0]\n",
    "abuse = X[X.target==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "print(len(not_abuse))\n",
    "print(len(abuse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# upsample minority\n",
    "abuse_upsampled = resample(abuse,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=len(not_abuse), # match number in majority class\n",
    "                          random_state=27) # reproducible results\n",
    "\n",
    "# combine majority and upsampled minority\n",
    "upsampled = pd.concat([abuse_upsampled, not_abuse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    163\n",
       "0    163\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upsampled.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = upsampled.target\n",
    "X_train = upsampled.drop('target', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(326, 28)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the LinearSVC since the benchmarking study shows this model giving best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score:   0.889\n",
      "f1_score_train:   0.972\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99        41\n",
      "          1       1.00      0.80      0.89         5\n",
      "\n",
      "avg / total       0.98      0.98      0.98        46\n",
      "\n",
      "confusion matrix:\n",
      "[[41  0]\n",
      " [ 1  4]]\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import time\n",
    "selector = SelectKBest(f_classif, k='all')\n",
    "selector_clf = Pipeline([('selector', selector),('classifier', LinearSVC(loss='l2', penalty='l2',dual=False, tol=1e-3))])\n",
    "selector_clf.fit(X_train, y_train)\n",
    "pred = selector_clf.predict(X_test)\n",
    "pred_train = selector_clf.predict(X_train)\n",
    "\n",
    "f1_score = metrics.f1_score(y_test, pred)\n",
    "print(\"f1_score:   %0.3f\" % f1_score )\n",
    "    \n",
    "f1_score_train = metrics.f1_score(y_train, pred_train)\n",
    "print(\"f1_score_train:   %0.3f\" % f1_score_train )\n",
    "    \n",
    "print(\"classification report:\")\n",
    "print(classification_report(y_test, pred))\n",
    "    \n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, pred))\n",
    "y_pred = pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let us plot the Confusion Matrix for the opportunity of Abuse prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATkAAAEYCAYAAAAnEYFiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x163696d3438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    #classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        #print(\"Normalized confusion matrix\")\n",
    "   # else:\n",
    "        #print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "class_names=['No','Yes']\n",
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(y_test, y_pred, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "#plot_confusion_matrix(y_test, y_pred, classes=class_names, normalize=True,\n",
    "#                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let us plot the ROC-AUC for the boolean opportunity of Abuse prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16365a89be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "true_labels = y_test\n",
    "scores = y_pred\n",
    "\n",
    "# compute fpr, tpr, thresholds and roc_auc\n",
    "fpr, tpr, thresholds = roc_curve(true_labels, scores)\n",
    "roc_auc = auc(fpr, tpr) # compute area under the curve\n",
    " \n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows the Area under ROC Curve is a healthy 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let us do K-fold CV on the data and verify the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "cv_results = cross_validate(selector_clf.fit(X_features, y), X_features, y,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98 0.85 0.89 0.93 1.  ]\n"
     ]
    }
   ],
   "source": [
    "print(cv_results['test_score'].round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_features = pd.DataFrame(X_features)\n",
    "y = pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_features.reset_index(drop=True, inplace=True)\n",
    "y.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# concatenate our training data back together\n",
    "X = pd.concat([X_features, y], axis=1)\n",
    "\n",
    "# separate minority and majority classes\n",
    "not_abuse = X[X.target==0]\n",
    "abuse = X[X.target==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "print(len(not_abuse))\n",
    "print(len(abuse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# upsample minority\n",
    "abuse_upsampled = resample(abuse,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=len(not_abuse), # match number in majority class\n",
    "                          random_state=27) # reproducible results\n",
    "\n",
    "# combine majority and upsampled minority\n",
    "upsampled = pd.concat([abuse_upsampled, not_abuse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    204\n",
       "0    204\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upsampled.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = upsampled.target\n",
    "X_train = upsampled.drop('target', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(408, 28)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>-1.608035</td>\n",
       "      <td>-2.254374</td>\n",
       "      <td>-1.587290</td>\n",
       "      <td>-0.688586</td>\n",
       "      <td>-1.803438</td>\n",
       "      <td>-14.379501</td>\n",
       "      <td>-0.804433</td>\n",
       "      <td>1.492519</td>\n",
       "      <td>-0.675917</td>\n",
       "      <td>-0.763602</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.067463</td>\n",
       "      <td>-3.342502</td>\n",
       "      <td>-0.646704</td>\n",
       "      <td>-0.470675</td>\n",
       "      <td>0.054003</td>\n",
       "      <td>-1.758757</td>\n",
       "      <td>-1.087704</td>\n",
       "      <td>-0.150070</td>\n",
       "      <td>-0.233021</td>\n",
       "      <td>6.885145e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>-0.593128</td>\n",
       "      <td>-0.584451</td>\n",
       "      <td>-1.568635</td>\n",
       "      <td>-0.883263</td>\n",
       "      <td>1.044781</td>\n",
       "      <td>-0.328200</td>\n",
       "      <td>-2.468253</td>\n",
       "      <td>47.978802</td>\n",
       "      <td>0.121547</td>\n",
       "      <td>-0.782165</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.983296</td>\n",
       "      <td>-2.623570</td>\n",
       "      <td>-0.666259</td>\n",
       "      <td>-0.492769</td>\n",
       "      <td>0.075470</td>\n",
       "      <td>-1.909450</td>\n",
       "      <td>-1.087704</td>\n",
       "      <td>-0.150070</td>\n",
       "      <td>-0.233021</td>\n",
       "      <td>6.885145e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>-0.571220</td>\n",
       "      <td>-0.556690</td>\n",
       "      <td>-1.567366</td>\n",
       "      <td>-0.862292</td>\n",
       "      <td>0.125961</td>\n",
       "      <td>-0.340758</td>\n",
       "      <td>-2.468253</td>\n",
       "      <td>47.978802</td>\n",
       "      <td>0.551821</td>\n",
       "      <td>-0.550835</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.983296</td>\n",
       "      <td>-2.623570</td>\n",
       "      <td>-0.666259</td>\n",
       "      <td>-0.492769</td>\n",
       "      <td>0.075470</td>\n",
       "      <td>-1.909450</td>\n",
       "      <td>-1.087704</td>\n",
       "      <td>-0.150070</td>\n",
       "      <td>-0.233021</td>\n",
       "      <td>6.885145e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>-0.271066</td>\n",
       "      <td>-0.240726</td>\n",
       "      <td>-1.629000</td>\n",
       "      <td>-0.983016</td>\n",
       "      <td>-0.464532</td>\n",
       "      <td>-0.299139</td>\n",
       "      <td>-0.425953</td>\n",
       "      <td>-0.447513</td>\n",
       "      <td>-0.889818</td>\n",
       "      <td>-1.331099</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.601626</td>\n",
       "      <td>-1.858336</td>\n",
       "      <td>-0.666259</td>\n",
       "      <td>-0.492769</td>\n",
       "      <td>0.054003</td>\n",
       "      <td>-1.758757</td>\n",
       "      <td>-0.453086</td>\n",
       "      <td>-0.597902</td>\n",
       "      <td>-0.233021</td>\n",
       "      <td>6.885145e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>-4.123102</td>\n",
       "      <td>43.843384</td>\n",
       "      <td>-1.668024</td>\n",
       "      <td>-1.059773</td>\n",
       "      <td>62.993397</td>\n",
       "      <td>0.936517</td>\n",
       "      <td>-0.425953</td>\n",
       "      <td>-0.447513</td>\n",
       "      <td>-1.079254</td>\n",
       "      <td>-1.833803</td>\n",
       "      <td>...</td>\n",
       "      <td>0.202513</td>\n",
       "      <td>-1.270825</td>\n",
       "      <td>-0.666259</td>\n",
       "      <td>-0.492769</td>\n",
       "      <td>0.054003</td>\n",
       "      <td>-1.758757</td>\n",
       "      <td>8.736084</td>\n",
       "      <td>-3.996828</td>\n",
       "      <td>-0.233021</td>\n",
       "      <td>6.885145e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1         2         3          4          5         6   \\\n",
       "223 -1.608035  -2.254374 -1.587290 -0.688586  -1.803438 -14.379501 -0.804433   \n",
       "212 -0.593128  -0.584451 -1.568635 -0.883263   1.044781  -0.328200 -2.468253   \n",
       "220 -0.571220  -0.556690 -1.567366 -0.862292   0.125961  -0.340758 -2.468253   \n",
       "209 -0.271066  -0.240726 -1.629000 -0.983016  -0.464532  -0.299139 -0.425953   \n",
       "217 -4.123102  43.843384 -1.668024 -1.059773  62.993397   0.936517 -0.425953   \n",
       "\n",
       "            7         8         9       ...             18        19  \\\n",
       "223   1.492519 -0.675917 -0.763602      ...      -1.067463 -3.342502   \n",
       "212  47.978802  0.121547 -0.782165      ...      -0.983296 -2.623570   \n",
       "220  47.978802  0.551821 -0.550835      ...      -0.983296 -2.623570   \n",
       "209  -0.447513 -0.889818 -1.331099      ...      -0.601626 -1.858336   \n",
       "217  -0.447513 -1.079254 -1.833803      ...       0.202513 -1.270825   \n",
       "\n",
       "           20        21        22        23        24        25        26  \\\n",
       "223 -0.646704 -0.470675  0.054003 -1.758757 -1.087704 -0.150070 -0.233021   \n",
       "212 -0.666259 -0.492769  0.075470 -1.909450 -1.087704 -0.150070 -0.233021   \n",
       "220 -0.666259 -0.492769  0.075470 -1.909450 -1.087704 -0.150070 -0.233021   \n",
       "209 -0.666259 -0.492769  0.054003 -1.758757 -0.453086 -0.597902 -0.233021   \n",
       "217 -0.666259 -0.492769  0.054003 -1.758757  8.736084 -3.996828 -0.233021   \n",
       "\n",
       "               27  \n",
       "223  6.885145e-08  \n",
       "212  6.885145e-08  \n",
       "220  6.885145e-08  \n",
       "209  6.885145e-08  \n",
       "217  6.885145e-08  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score_train:   1.000\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        41\n",
      "          1       1.00      1.00      1.00         5\n",
      "\n",
      "avg / total       1.00      1.00      1.00        46\n",
      "\n",
      "confusion matrix:\n",
      "[[41  0]\n",
      " [ 0  5]]\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time\n",
    "selector = SelectKBest(f_classif, k='all')\n",
    "selector_clf = Pipeline([('selector', selector),('classifier', RandomForestClassifier(n_estimators=100))])\n",
    "selector_clf.fit(X_train, y_train)\n",
    "pred_train = selector_clf.predict(X_train)\n",
    "y_pred = selector_clf.predict(X_test)\n",
    "\n",
    "    \n",
    "f1_score_train = metrics.f1_score(y_train, pred_train)\n",
    "print(\"f1_score_train:   %0.3f\" % f1_score_train )\n",
    "    \n",
    "print(\"classification report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "    \n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "#We define custom functions to return count of TP,TN,FP,FN for each fold\n",
    "def tn(y_train, pred_train): return confusion_matrix(y_train, pred_train)[0, 0]\n",
    "def fp(y_train, pred_train): return confusion_matrix(y_train, pred_train)[0, 1]\n",
    "def fn(y_train, pred_train): return confusion_matrix(y_train, pred_train)[1, 0]\n",
    "def tp(y_train, pred_train): return confusion_matrix(y_train, pred_train)[1, 1]\n",
    "\n",
    "scoring = {'tp': make_scorer(tp), 'tn': make_scorer(tn),'fp': make_scorer(fp), 'fn': make_scorer(fn)}\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "\n",
    "selector = SelectKBest(f_classif, k='all')\n",
    "selector_clf = Pipeline([('selector', selector),('classifier', RandomForestClassifier(n_estimators=100))])\n",
    "#selector_clf.fit(X_train, y_train)\n",
    "cv_results = cross_validate(selector_clf.fit(X_train, y_train), X_train, y_train,scoring=scoring, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of True Positives\n",
      "[47 43 37 32 38]\n",
      "Count of True Negatives\n",
      "[35 38 45 49 44]\n",
      "Count of False Negatives\n",
      "[0 0 0 0 0]\n",
      "Count of False Positives\n",
      "[0 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Count of True Positives\")\n",
    "print(cv_results['test_tp']) \n",
    "print(\"Count of True Negatives\")\n",
    "print(cv_results['test_tn']) \n",
    "# Getting the test set false negative scores\n",
    "print(\"Count of False Negatives\")\n",
    "print(cv_results['test_fn']) \n",
    "print(\"Count of False Positives\")\n",
    "print(cv_results['test_fp']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "cv_results = cross_validate(selector_clf.fit(X_train, y_train), X_train, y_train,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.   0.99 1.   1.   1.  ]\n"
     ]
    }
   ],
   "source": [
    "print(cv_results['test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model for predictions on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Pepsico/finalized_model_oppAbuse.sav']"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "filename = 'C:/Pepsico/finalized_model_oppAbuse.sav'\n",
    "joblib.dump(selector_clf,filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Loading instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = train_df[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(train_df): \n",
    "    scaler_load = joblib.load(\"scaler_oppabuse.pkl\")\n",
    "    pca_load = joblib.load(\"pca_oppabuse.pkl\")\n",
    "    vectorizer_load = joblib.load(\"vectorizer_oppabuse.pkl\")\n",
    "    \n",
    "    x_ngram_projName=vectorizer_load.transform(train_df['PDA_projName']).toarray()\n",
    "    x_ngram_projDesc=vectorizer_load.transform(train_df['projDesc']).toarray()\n",
    "    x_ngram_formula=vectorizer_load.transform(train_df['formulaNumber']).toarray()\n",
    "    x_ngram_packMaterial=vectorizer_load.transform(train_df['packMaterial']).toarray() \n",
    "    x_ngram_CPD_ProdName_Desc=vectorizer_load.transform(train_df['CPD-ProdName-Desc']).toarray()\n",
    "    x_ngram_prodStorageDist=vectorizer_load.transform(train_df['prodStorageDist']).toarray()\n",
    "    x_ngram_shelfLife=vectorizer_load.transform(train_df['shelfLife']).toarray()\n",
    "    x_ngram_TCG=vectorizer_load.transform(train_df['TCG']).toarray() \n",
    "    x_ngram_cookedOrHeated=vectorizer_load.transform(train_df['cookedOrHeated']).toarray() \n",
    "    x_ngram_specificStorage=vectorizer_load.transform(train_df['specificStorage']).toarray() \n",
    "    x_ngram_labelingInstructions=vectorizer_load.transform(train_df['labelingInstructions']).toarray()\n",
    "    x_ngram_mishandled=vectorizer_load.transform(train_df['mishandled']).toarray() \n",
    "    x_ngram_targetMarket=vectorizer_load.transform(train_df['targetMarket']).toarray()\n",
    "    x_ngram_approvedPackage=vectorizer_load.transform(train_df['approvedPackage']).toarray()\n",
    "    train_df = train_df.drop(['PDA_projName','projDesc','formulaNumber','packMaterial','CPD-ProdName-Desc','prodStorageDist','shelfLife','TCG','cookedOrHeated','specificStorage','labelingInstructions','mishandled','targetMarket','approvedPackage'],axis=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    x_ngram_projName =  scaler_load.transform(x_ngram_projName)\n",
    "    x_ngram_projDesc =  scaler_load.transform(x_ngram_projDesc)\n",
    "    x_ngram_formula =  scaler_load.transform(x_ngram_formula)\n",
    "    x_ngram_packMaterial =  scaler_load.transform(x_ngram_packMaterial)\n",
    "    x_ngram_CPD_ProdName_Desc =  scaler_load.transform(x_ngram_CPD_ProdName_Desc)\n",
    "    x_ngram_prodStorageDist =  scaler_load.transform(x_ngram_prodStorageDist)\n",
    "    x_ngram_shelfLife =  scaler_load.transform(x_ngram_shelfLife)\n",
    "    x_ngram_TCG =  scaler_load.transform(x_ngram_TCG)\n",
    "    x_ngram_cookedOrHeated =  scaler_load.transform(x_ngram_cookedOrHeated)\n",
    "    x_ngram_specificStorage =  scaler_load.transform(x_ngram_specificStorage)\n",
    "    x_ngram_labelingInstructions =  scaler_load.transform(x_ngram_labelingInstructions)\n",
    "    x_ngram_mishandled =  scaler_load.transform(x_ngram_mishandled)\n",
    "    x_ngram_targetMarket =  scaler_load.transform(x_ngram_targetMarket)\n",
    "    x_ngram_approvedPackage =  scaler_load.transform(x_ngram_approvedPackage)\n",
    "    \n",
    "   # x_pca_projName = pca_load.transform(x_ngram_projName)\n",
    "    x_pca_projDesc = pca_load.transform(x_ngram_projDesc)\n",
    "    x_pca_formula = pca_load.transform(x_ngram_formula)\n",
    "    x_pca_packMaterial = pca_load.transform(x_ngram_packMaterial)\n",
    "    x_pca_CPD_ProdName_Desc = pca_load.transform(x_ngram_CPD_ProdName_Desc)\n",
    "    x_pca_prodStorageDist = pca_load.transform(x_ngram_prodStorageDist)\n",
    "    x_pca_shelfLife = pca_load.transform(x_ngram_shelfLife)\n",
    "    x_pca_TCG = pca_load.transform(x_ngram_TCG)\n",
    "    x_pca_cookedOrHeated = pca_load.transform(x_ngram_cookedOrHeated)\n",
    "    x_pca_specificStorage = pca_load.transform(x_ngram_specificStorage)\n",
    "    x_pca_labelingInstructions = pca_load.transform(x_ngram_labelingInstructions)\n",
    "    x_pca_mishandled = pca_load.transform(x_ngram_mishandled)\n",
    "    x_pca_targetMarket = pca_load.transform(x_ngram_targetMarket)\n",
    "    x_pca_approvedPackage = pca_load.transform(x_ngram_approvedPackage)\n",
    "\n",
    "    x_train = np.concatenate((x_pca_projDesc,x_pca_formula,x_pca_packMaterial,x_pca_CPD_ProdName_Desc,\n",
    "                              x_pca_prodStorageDist,x_pca_shelfLife,x_pca_TCG,x_pca_cookedOrHeated,x_pca_specificStorage,x_pca_labelingInstructions,x_pca_mishandled,x_pca_targetMarket,x_pca_approvedPackage),axis=1)\n",
    "    print(x_train.shape)\n",
    "    return x_train  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 26)\n"
     ]
    }
   ],
   "source": [
    "X_features=preprocess_text(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_load = joblib.load(\"pca_oppabuse.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_cache',\n",
       " '_abc_negative_cache',\n",
       " '_abc_negative_cache_version',\n",
       " '_abc_registry',\n",
       " '_fit',\n",
       " '_fit_full',\n",
       " '_fit_truncated',\n",
       " '_get_param_names',\n",
       " 'components_',\n",
       " 'copy',\n",
       " 'explained_variance_',\n",
       " 'explained_variance_ratio_',\n",
       " 'fit',\n",
       " 'fit_transform',\n",
       " 'get_covariance',\n",
       " 'get_params',\n",
       " 'get_precision',\n",
       " 'inverse_transform',\n",
       " 'iterated_power',\n",
       " 'mean_',\n",
       " 'n_components',\n",
       " 'n_components_',\n",
       " 'n_features_',\n",
       " 'n_samples_',\n",
       " 'noise_variance_',\n",
       " 'random_state',\n",
       " 'score',\n",
       " 'score_samples',\n",
       " 'set_params',\n",
       " 'singular_values_',\n",
       " 'svd_solver',\n",
       " 'tol',\n",
       " 'transform',\n",
       " 'whiten']"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(pca_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_load.n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
