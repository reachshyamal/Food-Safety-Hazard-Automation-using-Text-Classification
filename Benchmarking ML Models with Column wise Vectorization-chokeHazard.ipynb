{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook reads text data from data extract created from FSHA Forms and runs predictive Models to predict the value 'Are there any consumer suitability or choke hazard concerns?' , based on the Input Data\n",
    "# It does vectorization of each Column and concatenates these Vectors to create a final Feature Vector and fits multiple ML Models, including Deep Learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "#import all necessary modules\n",
    "from __future__ import print_function\n",
    "import logging\n",
    "from optparse import OptionParser\n",
    "import sys\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import nltk\n",
    "import string\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import re\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from scipy import signal\n",
    "import random\n",
    "import string\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_selection import f_classif\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.svm import SVC \n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB,BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.utils.extmath import density\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import models\n",
    "from tensorflow.python.keras import initializers\n",
    "from tensorflow.python.keras import regularizers\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.layers import Dropout\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19.0\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File name and other important parameters like ngram_range set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#These parameters will be input from command line\n",
    "ngram_range_inp=(1,2)\n",
    "filename = \"C:/Pepsico/FSHA RPA - 25 July 2019 - 209Files.xlsm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename1 = \"C:/Pepsico/choke hazards_08 26.xlsm\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define reusable modular method for Text Normalization (removal of stopwords, changing to lower case, removal of punctuation etc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exclude = set(string.punctuation) \n",
    "wpt = nltk.WordPunctTokenizer()\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "newStopWords = ['from','dtype','object']\n",
    "stop_words.extend(newStopWords)\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "porter = PorterStemmer()\n",
    "\n",
    "def normalize_document(doc):\n",
    "    # tokenize document\n",
    "    tokens = doc.split()\n",
    "    # remove punctuation from each word\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "    # convert to lower case\n",
    "    lower_tokens = [w.lower() for w in tokens]\n",
    "    #remove spaces\n",
    "    stripped = [w.strip() for w in lower_tokens]\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    words = [word for word in stripped if word.isalpha()]\n",
    "    # filter stopwords out of document\n",
    "    filtered_tokens = [token for token in words if token not in stop_words]\n",
    "    # re-create document from filtered tokens\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "    return doc\n",
    "\n",
    "#normalize_corpus = np.vectorize(normalize_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "\n",
    "tokenizer = ToktokTokenizer()\n",
    "stopword_list = nltk.corpus.stopwords.words('english')\n",
    "stopword_list.remove('no')\n",
    "stopword_list.remove('not')\n",
    "def strip_html_tags(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    stripped_text = soup.get_text()\n",
    "    return stripped_text\n",
    "def remove_accented_chars(text):\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return text\n",
    "\n",
    "def remove_special_characters(text):\n",
    "    text = re.sub('[^a-zA-z0-9\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "def remove_stopwords(text, is_lower_case=False):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    if is_lower_case:\n",
    "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    else:\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text\n",
    "def normalize_corpus(corpus, html_stripping=True, contraction_expansion=True,\n",
    "                     accented_char_removal=True, text_lower_case=True, \n",
    "                     text_lemmatization=True, special_char_removal=True, \n",
    "                     stopword_removal=True):\n",
    "    \n",
    "    normalized_corpus = []\n",
    "    # normalize each document in the corpus\n",
    "    #corpus = str(corpus)\n",
    "    for doc in corpus:\n",
    "        # strip HTML\n",
    "        if html_stripping:\n",
    "            doc = strip_html_tags(doc)\n",
    "        # remove accented characters\n",
    "        if accented_char_removal:\n",
    "            doc = remove_accented_chars(doc)\n",
    "\n",
    "        # lowercase the text    \n",
    "        if text_lower_case:\n",
    "            doc = doc.lower()\n",
    "        # remove extra newlines\n",
    "        doc = re.sub(r'[\\r|\\n|\\r\\n]+', ' ',doc)\n",
    "        # insert spaces between special characters to isolate them    \n",
    "        special_char_pattern = re.compile(r'([{.(-)!}])')\n",
    "        doc = special_char_pattern.sub(\" \\\\1 \", doc)\n",
    "        # remove special characters    \n",
    "        if special_char_removal:\n",
    "            doc = remove_special_characters(doc)  \n",
    "        # remove extra whitespace\n",
    "        doc = re.sub(' +', ' ', doc)\n",
    "        # remove stopwords\n",
    "        if stopword_removal:\n",
    "            doc = remove_stopwords(doc, is_lower_case=text_lower_case)\n",
    "            \n",
    "        normalized_corpus.append(doc)\n",
    "        \n",
    "    return normalized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_doc(corpus):\n",
    "    normalized_corpus = []\n",
    "    # normalize each document in the corpus\n",
    "    #corpus = str(corpus)\n",
    "    for doc in corpus:\n",
    "\t# split into tokens by white space\n",
    "        doc=str(doc)\n",
    "        doc = doc.replace('\\n',' ')\n",
    "        tokens = doc.split()\n",
    "        # prepare regex for char filtering\n",
    "        re_punc = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "        # remove punctuation from each word\n",
    "        tokens = [re_punc.sub('', w) for w in tokens]\n",
    "        # remove remaining tokens that are not alphabetic\n",
    "        tokens = [word for word in tokens if word.isalpha()]\n",
    "        # filter out stop words\n",
    "        tokens = [w for w in tokens if not w in stop_words]\n",
    "        # filter out short tokens\n",
    "        tokens = [word for word in tokens if len(word) > 1]\n",
    "        # remove nn from each word\n",
    "        tokens = [re.sub('nn',' ',word) for word in tokens]\n",
    "        tokens = ' '.join(tokens)\n",
    "        normalized_corpus.append(tokens)\n",
    "    return normalized_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the data extract file (tabular format with Input data(X) and target(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsha_data = pd.read_excel(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fsha_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fsha_data = fsha_data[(fsha_data['chokeHazard']=='No')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fsha_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fsha_data_yes = pd.read_excel(filename1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fsha_data_yes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fsha_data = pd.concat([fsha_data,fsha_data_yes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "229"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fsha_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CPD-ProdName</th>\n",
       "      <th>CPD-ProdName-Desc</th>\n",
       "      <th>Current TSG Stage</th>\n",
       "      <th>FSAssessors</th>\n",
       "      <th>FSDate</th>\n",
       "      <th>File Name</th>\n",
       "      <th>PDA_projName</th>\n",
       "      <th>PlantTrial</th>\n",
       "      <th>TCG</th>\n",
       "      <th>Table1_Row1_Celery</th>\n",
       "      <th>...</th>\n",
       "      <th>prodModifications</th>\n",
       "      <th>prodStorageDist</th>\n",
       "      <th>projDesc</th>\n",
       "      <th>projName</th>\n",
       "      <th>projType</th>\n",
       "      <th>sector</th>\n",
       "      <th>shelfLife</th>\n",
       "      <th>specificStorage</th>\n",
       "      <th>targetMarket</th>\n",
       "      <th>waterActivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1SKU Star Puffs Onion\\n2 SKU Star Puffs Cheese...</td>\n",
       "      <td>Extruded and baked corn base product, flavoure...</td>\n",
       "      <td>G3</td>\n",
       "      <td>Helen Booden</td>\n",
       "      <td>21/11/2017</td>\n",
       "      <td>#46565 FSHA 5.4.1Star Project G3 v2 + FS input...</td>\n",
       "      <td>1SKU Star Puffs Onion\\n2 SKU Star Puffs Cheese...</td>\n",
       "      <td>Tomaszow plant, trial conducted on 02/11/2017</td>\n",
       "      <td>Families and Adults, value conscious consumers</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Store in a dry, cool and away from sun place.</td>\n",
       "      <td>Star Puffs Cheese &amp; STar Hyper Cheese\\nSeasoni...</td>\n",
       "      <td>S-T3-Star-• POL Star Puff (Chrupki) quality –POL</td>\n",
       "      <td>Brand Refresh</td>\n",
       "      <td>ESSA</td>\n",
       "      <td>26 weeks</td>\n",
       "      <td>No</td>\n",
       "      <td>People with allergies to milk, lactose, peanuts.</td>\n",
       "      <td>low moisture food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hrusteam</td>\n",
       "      <td>Crispy Bread</td>\n",
       "      <td>Gate 3, 4</td>\n",
       "      <td>Fedor Kholodov</td>\n",
       "      <td>2019-06-14 00:00:00</td>\n",
       "      <td>#53697 FSHA HT Baguette 4 Cheese UA 2.07.19.xlsm</td>\n",
       "      <td>Hrusteam Baguette</td>\n",
       "      <td>Nikolaev</td>\n",
       "      <td>Adults</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Keep at temperature 25 °C, &lt;75% humidity</td>\n",
       "      <td>Launch new seasoning 4 Cheese NL-502-352-9 on ...</td>\n",
       "      <td>HT Baguette Four Cheese Flavor</td>\n",
       "      <td>Refresh</td>\n",
       "      <td>ESSA</td>\n",
       "      <td>140 days</td>\n",
       "      <td>Keep at temperature 25 °C, &lt;75% humidity</td>\n",
       "      <td>No</td>\n",
       "      <td>low water activity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lay's Red Caviar</td>\n",
       "      <td>Potato chips</td>\n",
       "      <td>Development + Scale-up</td>\n",
       "      <td>Helen Booden</td>\n",
       "      <td>2019-06-27 00:00:00</td>\n",
       "      <td>#57686 FSHA 5.4.1 Red Caviar  Azov.xlsm</td>\n",
       "      <td>Lay's Red Caviar</td>\n",
       "      <td>Azov, Russia</td>\n",
       "      <td>18-45 y.o. males 50%/females 50%</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>air temperature is not higher than 25 ˚С and r...</td>\n",
       "      <td>Idea is to launch I&amp;O flavour under New Year p...</td>\n",
       "      <td>Lay's Caviar IO 2019 RUS Asov</td>\n",
       "      <td>Refresh</td>\n",
       "      <td>ESSA</td>\n",
       "      <td>20+1 week</td>\n",
       "      <td>store the product for no more than 24 hours at...</td>\n",
       "      <td>people with allergy to ingredients in the prod...</td>\n",
       "      <td>Low water activity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lay's Red Caviar</td>\n",
       "      <td>Potato chips</td>\n",
       "      <td>Development + Scale-up</td>\n",
       "      <td>Helen Booden</td>\n",
       "      <td>2019-06-27 00:00:00</td>\n",
       "      <td>#57686 FSHA 5.4.1 Red Caviar Kashira.xlsm</td>\n",
       "      <td>Lay's Red Caviar</td>\n",
       "      <td>Kashira, Russia</td>\n",
       "      <td>18-45 y.o. males 50%/females 50%</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>air temperature is not higher than 25 ˚С and r...</td>\n",
       "      <td>Idea is to launch I&amp;O flavour under New Year p...</td>\n",
       "      <td>Lay's Caviar IO 2019 RUS Kashira</td>\n",
       "      <td>Refresh</td>\n",
       "      <td>ESSA</td>\n",
       "      <td>20+1 week</td>\n",
       "      <td>store the product for no more than 24 hours at...</td>\n",
       "      <td>people with allergy to ingredients in the prod...</td>\n",
       "      <td>Low water activity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cheetos Palomitos</td>\n",
       "      <td>Extruded product with \"popcorn\" shape with cre...</td>\n",
       "      <td>G3 4 Combined</td>\n",
       "      <td>Helen Booden</td>\n",
       "      <td>2018-11-28 00:00:00</td>\n",
       "      <td>53354-FSHA-In Process 13.12.18.xlsm</td>\n",
       "      <td>Cheetos Palomito</td>\n",
       "      <td>Burgos, Spain</td>\n",
       "      <td>Kids and families</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Product to be sold in Iberia, storage in ambie...</td>\n",
       "      <td>Re Launch of Cheetos Palomitos, Soft Extruded ...</td>\n",
       "      <td>Soft and Mild Iberia 2019</td>\n",
       "      <td>Re Launch</td>\n",
       "      <td>ESSA</td>\n",
       "      <td>Flavour/color loss powered by clear film windo...</td>\n",
       "      <td>Ensure the bag is closed and consumed after 2 ...</td>\n",
       "      <td>Kids from  4-10</td>\n",
       "      <td>Low water activity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        CPD-ProdName  \\\n",
       "0  1SKU Star Puffs Onion\\n2 SKU Star Puffs Cheese...   \n",
       "1                                           Hrusteam   \n",
       "2                                   Lay's Red Caviar   \n",
       "3                                   Lay's Red Caviar   \n",
       "4                                  Cheetos Palomitos   \n",
       "\n",
       "                                   CPD-ProdName-Desc       Current TSG Stage  \\\n",
       "0  Extruded and baked corn base product, flavoure...                      G3   \n",
       "1                                       Crispy Bread               Gate 3, 4   \n",
       "2                                       Potato chips  Development + Scale-up   \n",
       "3                                       Potato chips  Development + Scale-up   \n",
       "4  Extruded product with \"popcorn\" shape with cre...           G3 4 Combined   \n",
       "\n",
       "      FSAssessors               FSDate  \\\n",
       "0    Helen Booden           21/11/2017   \n",
       "1  Fedor Kholodov  2019-06-14 00:00:00   \n",
       "2  Helen Booden    2019-06-27 00:00:00   \n",
       "3  Helen Booden    2019-06-27 00:00:00   \n",
       "4    Helen Booden  2018-11-28 00:00:00   \n",
       "\n",
       "                                           File Name  \\\n",
       "0  #46565 FSHA 5.4.1Star Project G3 v2 + FS input...   \n",
       "1   #53697 FSHA HT Baguette 4 Cheese UA 2.07.19.xlsm   \n",
       "2            #57686 FSHA 5.4.1 Red Caviar  Azov.xlsm   \n",
       "3          #57686 FSHA 5.4.1 Red Caviar Kashira.xlsm   \n",
       "4                53354-FSHA-In Process 13.12.18.xlsm   \n",
       "\n",
       "                                        PDA_projName  \\\n",
       "0  1SKU Star Puffs Onion\\n2 SKU Star Puffs Cheese...   \n",
       "1                                  Hrusteam Baguette   \n",
       "2                                  Lay's Red Caviar    \n",
       "3                                  Lay's Red Caviar    \n",
       "4                                   Cheetos Palomito   \n",
       "\n",
       "                                      PlantTrial  \\\n",
       "0  Tomaszow plant, trial conducted on 02/11/2017   \n",
       "1                                       Nikolaev   \n",
       "2                                   Azov, Russia   \n",
       "3                               Kashira, Russia    \n",
       "4                                  Burgos, Spain   \n",
       "\n",
       "                                              TCG Table1_Row1_Celery  \\\n",
       "0  Families and Adults, value conscious consumers                  0   \n",
       "1                                          Adults                  0   \n",
       "2                18-45 y.o. males 50%/females 50%                  0   \n",
       "3                18-45 y.o. males 50%/females 50%                  0   \n",
       "4                               Kids and families                  0   \n",
       "\n",
       "          ...         prodModifications  \\\n",
       "0         ...                        No   \n",
       "1         ...                        No   \n",
       "2         ...                        No   \n",
       "3         ...                        No   \n",
       "4         ...                        No   \n",
       "\n",
       "                                     prodStorageDist  \\\n",
       "0      Store in a dry, cool and away from sun place.   \n",
       "1           Keep at temperature 25 °C, <75% humidity   \n",
       "2  air temperature is not higher than 25 ˚С and r...   \n",
       "3  air temperature is not higher than 25 ˚С and r...   \n",
       "4  Product to be sold in Iberia, storage in ambie...   \n",
       "\n",
       "                                            projDesc  \\\n",
       "0  Star Puffs Cheese & STar Hyper Cheese\\nSeasoni...   \n",
       "1  Launch new seasoning 4 Cheese NL-502-352-9 on ...   \n",
       "2  Idea is to launch I&O flavour under New Year p...   \n",
       "3  Idea is to launch I&O flavour under New Year p...   \n",
       "4  Re Launch of Cheetos Palomitos, Soft Extruded ...   \n",
       "\n",
       "                                            projName       projType sector  \\\n",
       "0  S-T3-Star-• POL Star Puff (Chrupki) quality –POL   Brand Refresh   ESSA   \n",
       "1                     HT Baguette Four Cheese Flavor        Refresh   ESSA   \n",
       "2                      Lay's Caviar IO 2019 RUS Asov        Refresh   ESSA   \n",
       "3                   Lay's Caviar IO 2019 RUS Kashira        Refresh   ESSA   \n",
       "4                          Soft and Mild Iberia 2019      Re Launch   ESSA   \n",
       "\n",
       "                                           shelfLife  \\\n",
       "0                                           26 weeks   \n",
       "1                                           140 days   \n",
       "2                                          20+1 week   \n",
       "3                                          20+1 week   \n",
       "4  Flavour/color loss powered by clear film windo...   \n",
       "\n",
       "                                     specificStorage  \\\n",
       "0                                                 No   \n",
       "1           Keep at temperature 25 °C, <75% humidity   \n",
       "2  store the product for no more than 24 hours at...   \n",
       "3  store the product for no more than 24 hours at...   \n",
       "4  Ensure the bag is closed and consumed after 2 ...   \n",
       "\n",
       "                                        targetMarket       waterActivity  \n",
       "0   People with allergies to milk, lactose, peanuts.   low moisture food  \n",
       "1                                                 No  low water activity  \n",
       "2  people with allergy to ingredients in the prod...  Low water activity  \n",
       "3  people with allergy to ingredients in the prod...  Low water activity  \n",
       "4                                    Kids from  4-10  Low water activity  \n",
       "\n",
       "[5 rows x 138 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fsha_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Based on Analysis select the Features (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#selecting set of columns as Features\n",
    "fsha_data.fillna('NA', inplace=True)\n",
    "features_df=fsha_data[['projDesc','PDA_projName','packMaterial', 'CPD-ProdName','CPD-ProdName-Desc','TCG', 'labelingInstructions',\n",
    "        'mishandled', 'targetMarket']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_str(x):\n",
    "   \n",
    "    x=str(x)\n",
    "    x=x.lower()\n",
    "    return (x)\n",
    "\n",
    "features_df['projDesc']=features_df['projDesc'].apply(lambda x:conv_str(x))  \n",
    "features_df['PDA_projName']=features_df['PDA_projName'].apply(lambda x:conv_str(x))\n",
    "features_df['packMaterial']=features_df['packMaterial'].apply(lambda x:conv_str(x))  \n",
    "features_df['CPD-ProdName']=features_df['CPD-ProdName'].apply(lambda x:conv_str(x))  \n",
    "features_df['CPD-ProdName-Desc']=features_df['CPD-ProdName-Desc'].apply(lambda x:conv_str(x))  \n",
    "features_df['TCG']=features_df['TCG'].apply(lambda x:conv_str(x)) \n",
    "features_df['labelingInstructions']=features_df['labelingInstructions'].apply(lambda x:conv_str(x)) \n",
    "features_df['mishandled']=features_df['mishandled'].apply(lambda x:conv_str(x))  \n",
    "features_df['targetMarket']=features_df['targetMarket'].apply(lambda x:conv_str(x)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replace missing values in features with NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define reusable code to Vectorize Text column (ex: Allergens) using TF-IDF Vectorizer, after doing Text data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vectorization of text data using TF-IDF Vectorizer\n",
    "\n",
    "# Range (inclusive) of n-gram sizes for tokenizing text.\n",
    "#NGRAM_RANGE \n",
    "\n",
    "# Limit on the number of features. We use the top 20K features.\n",
    "#TOP_K = 20000\n",
    "\n",
    "# Whether text should be split into word or character n-grams.\n",
    "# One of 'word', 'char'.\n",
    "TOKEN_MODE = 'word'\n",
    "\n",
    "# Minimum document/corpus frequency below which a token will be discarded.\n",
    "MIN_DOCUMENT_FREQUENCY = 2\n",
    "\n",
    "# Limit on the length of text sequences. Sequences longer than this\n",
    "# will be truncated.\n",
    "MAX_SEQUENCE_LENGTH = 500\n",
    "\n",
    "\n",
    "def ngram_vectorize(train_texts, train_labels,ngram_range):\n",
    "    \"\"\"Vectorizes texts as ngram vectors.\n",
    "\n",
    "    1 text = 1 tf-idf vector the length of vocabulary of uni-grams + bi-grams.\n",
    "\n",
    "    # Arguments\n",
    "        train_texts: list, training text strings.\n",
    "        train_labels: np.ndarray, training labels.\n",
    "        val_texts: list, validation text strings.\n",
    "\n",
    "    # Returns\n",
    "        x_train, x_val: vectorized training and validation texts\n",
    "    \"\"\"\n",
    "    # Create keyword arguments to pass to the 'tf-idf' vectorizer.\n",
    "    kwargs = {\n",
    "            'ngram_range': ngram_range,  # Use 1-grams + 2-grams.\n",
    "            'dtype': 'int32',\n",
    "            'strip_accents': 'unicode',\n",
    "            'decode_error': 'replace',\n",
    "            'analyzer': TOKEN_MODE,  # Split text into word tokens.\n",
    "            'min_df': MIN_DOCUMENT_FREQUENCY,\n",
    "    }\n",
    "    vectorizer = TfidfVectorizer(**kwargs)\n",
    "\n",
    "    # Learn vocabulary from training texts and vectorize training texts.\n",
    "    x_train = vectorizer.fit_transform(train_texts)\n",
    "\n",
    "    x_train = x_train.astype('float32')\n",
    "    return x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['projDesc', 'PDA_projName', 'packMaterial', 'CPD-ProdName',\n",
       "       'CPD-ProdName-Desc', 'TCG', 'labelingInstructions', 'mishandled',\n",
       "       'targetMarket'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize each column , by cleaning the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df['projDesc']=normalize_corpus(train_df['projDesc'])\n",
    "train_df['PDA_projName']=normalize_corpus(train_df['PDA_projName'])\n",
    "train_df['packMaterial']=normalize_corpus(train_df['packMaterial'])  \n",
    "train_df['CPD-ProdName']=normalize_corpus(train_df['CPD-ProdName'])  \n",
    "train_df['CPD-ProdName-Desc']=normalize_corpus(train_df['CPD-ProdName-Desc'])\n",
    "train_df['TCG']=normalize_corpus(train_df['TCG']) \n",
    "train_df['labelingInstructions']=normalize_corpus(train_df['labelingInstructions']) \n",
    "train_df['mishandled']=normalize_corpus(train_df['mishandled']) \n",
    "train_df['targetMarket']=normalize_corpus(train_df['targetMarket'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['projDesc', 'PDA_projName', 'packMaterial', 'CPD-ProdName',\n",
       "       'CPD-ProdName-Desc', 'TCG', 'labelingInstructions', 'mishandled',\n",
       "       'targetMarket'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binarize the target (1/0 for Yes/No)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statistics \n",
    "\n",
    "def impute_target(fsha_data,targetName):\n",
    "    train_y=[]\n",
    "    for i in range (len(fsha_data)):\n",
    "        if fsha_data[targetName].values[i]=='Yes':\n",
    "            train_y.append(1)\n",
    "        elif fsha_data[targetName].values[i]=='No':\n",
    "            train_y.append(0)\n",
    "        else:\n",
    "            train_y.append(-1)\n",
    "               \n",
    "    mode_y = statistics.mode(train_y)\n",
    "\n",
    "    for i in range (len(fsha_data)):\n",
    "        if train_y[i]==-1:\n",
    "            train_y[i] = mode_y\n",
    "            \n",
    "    return train_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target (Yes/No choice) in PDAF are converted to binary values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_y_chokehazard = impute_target(fsha_data,\"chokeHazard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df['target']=train_y_chokehazard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    204\n",
       "1     25\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = train_df['target']\n",
    "train_df = train_df.drop('target',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform n-gram vectorization and PCA on text data, columnwise, and concatenate with categorical one-hot encoded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_text(train_df,y):    \n",
    "    train_labels = y\n",
    "    x_ngram_projDesc=ngram_vectorize(train_df['projDesc'], train_labels,n_gram_range).toarray()\n",
    "    x_ngram_PDA_projName=ngram_vectorize(train_df['PDA_projName'], train_labels,n_gram_range).toarray()\n",
    "    x_ngram_packMaterial=ngram_vectorize(train_df['packMaterial'], train_labels,n_gram_range).toarray() \n",
    "    x_ngram_CPD_ProdName=ngram_vectorize(train_df['CPD-ProdName'], train_labels,n_gram_range).toarray() \n",
    "    x_ngram_CPD_ProdName_Desc=ngram_vectorize(train_df['CPD-ProdName-Desc'], train_labels,n_gram_range).toarray()\n",
    "    x_ngram_TCG=ngram_vectorize(train_df['TCG'], train_labels,n_gram_range).toarray() \n",
    "    x_ngram_labelingInstructions=ngram_vectorize(train_df['labelingInstructions'], train_labels,n_gram_range).toarray()\n",
    "    x_ngram_mishandled=ngram_vectorize(train_df['mishandled'], train_labels,n_gram_range).toarray() \n",
    "    x_ngram_targetMarket=ngram_vectorize(train_df['targetMarket'], train_labels,n_gram_range).toarray()\n",
    "    train_df = train_df.drop(['projDesc','PDA_projName','packMaterial','CPD-ProdName','TCG','labelingInstructions','mishandled','targetMarket'],axis=1)\n",
    "    pca = PCA(n_components=n_components,svd_solver=svd_solver,whiten=whiten, random_state=42)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    x_ngram_projDesc = scaler.fit_transform(x_ngram_projDesc)\n",
    "    x_ngram_PDA_projName = scaler.fit_transform(x_ngram_PDA_projName)\n",
    "    x_ngram_packMaterial = scaler.fit_transform(x_ngram_packMaterial)\n",
    "    x_ngram_CPD_ProdName = scaler.fit_transform(x_ngram_CPD_ProdName)\n",
    "    x_ngram_CPD_ProdName_Desc = scaler.fit_transform(x_ngram_CPD_ProdName_Desc)\n",
    "    x_ngram_TCG = scaler.fit_transform(x_ngram_TCG)\n",
    "    x_ngram_labelingInstructions = scaler.fit_transform(x_ngram_labelingInstructions)\n",
    "    x_ngram_mishandled = pca.fit_transform(x_ngram_mishandled)\n",
    "    x_ngram_targetMarket = scaler.fit_transform(x_ngram_targetMarket)\n",
    "    \n",
    "    x_pca_projDesc = pca.fit_transform(x_ngram_projDesc)\n",
    "    x_pca_PDA_projName = pca.fit_transform(x_ngram_PDA_projName)\n",
    "    x_pca_packMaterial = pca.fit_transform(x_ngram_packMaterial)\n",
    "    x_pca_CPD_ProdName = pca.fit_transform(x_ngram_CPD_ProdName)\n",
    "    x_pca_CPD_ProdName_Desc = pca.fit_transform(x_ngram_CPD_ProdName_Desc)\n",
    "    x_pca_TCG = pca.fit_transform(x_ngram_TCG)\n",
    "    x_pca_labelingInstructions = pca.fit_transform(x_ngram_labelingInstructions)\n",
    "    x_pca_mishandled = pca.fit_transform(x_ngram_mishandled)\n",
    "    x_pca_targetMarket = pca.fit_transform(x_ngram_targetMarket)\n",
    "\n",
    "    x_train = np.concatenate((x_pca_projDesc,x_pca_PDA_projName,x_pca_packMaterial,x_pca_CPD_ProdName,x_pca_CPD_ProdName_Desc,x_pca_TCG,x_pca_labelingInstructions,x_pca_mishandled,x_pca_targetMarket),axis=1)\n",
    "    print(x_train.shape)\n",
    "    return x_train  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(229, 27)\n"
     ]
    }
   ],
   "source": [
    "n_gram_range = (1,2)\n",
    "n_components = 3\n",
    "whiten = False\n",
    "random_state = 42\n",
    "svd_solver=\"full\"\n",
    "X_features = preprocess_text(train_df,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(229,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y, test_size=.2, random_state=42,stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(183, 27)\n",
      "(46, 27)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train)\n",
    "y_train = pd.DataFrame(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(183, 1)\n",
      "(46,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_train.columns = ['PCA_allergens_1','PCA_allergens_2','PCA_allergens_3','PCA_allergens_4','PCA_allergens_5','PCA_allergens_6','PCA_allergens_M_1','PCA_allergens_M_2','PCA_allergens_M_3','PCA_allergens_M_4','PCA_allergens_M_5','PCA_allergens_M_6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.506329</td>\n",
       "      <td>-8.853518</td>\n",
       "      <td>9.399597</td>\n",
       "      <td>-0.772311</td>\n",
       "      <td>0.077167</td>\n",
       "      <td>-0.898672</td>\n",
       "      <td>-1.880895</td>\n",
       "      <td>5.182326</td>\n",
       "      <td>-0.167279</td>\n",
       "      <td>-0.443091</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.186849</td>\n",
       "      <td>-0.819833</td>\n",
       "      <td>-0.664658</td>\n",
       "      <td>-0.067670</td>\n",
       "      <td>0.688105</td>\n",
       "      <td>-0.505032</td>\n",
       "      <td>-0.118800</td>\n",
       "      <td>-1.300389</td>\n",
       "      <td>-0.288930</td>\n",
       "      <td>-1.291586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.492383</td>\n",
       "      <td>0.743671</td>\n",
       "      <td>-1.390057</td>\n",
       "      <td>-0.577119</td>\n",
       "      <td>-0.140470</td>\n",
       "      <td>-0.356033</td>\n",
       "      <td>-0.581103</td>\n",
       "      <td>-1.194342</td>\n",
       "      <td>-0.907903</td>\n",
       "      <td>-0.045027</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.833394</td>\n",
       "      <td>-0.674255</td>\n",
       "      <td>-0.492840</td>\n",
       "      <td>-0.482959</td>\n",
       "      <td>-0.511923</td>\n",
       "      <td>-0.051763</td>\n",
       "      <td>-0.037197</td>\n",
       "      <td>-1.013797</td>\n",
       "      <td>-0.182434</td>\n",
       "      <td>-0.776942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.076171</td>\n",
       "      <td>0.476095</td>\n",
       "      <td>-1.496893</td>\n",
       "      <td>-0.613497</td>\n",
       "      <td>-0.020490</td>\n",
       "      <td>-0.978051</td>\n",
       "      <td>-0.955439</td>\n",
       "      <td>1.337357</td>\n",
       "      <td>0.297091</td>\n",
       "      <td>-0.774588</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.354721</td>\n",
       "      <td>-0.674257</td>\n",
       "      <td>-0.492840</td>\n",
       "      <td>-0.482958</td>\n",
       "      <td>-0.511923</td>\n",
       "      <td>-0.051763</td>\n",
       "      <td>-0.037197</td>\n",
       "      <td>3.682249</td>\n",
       "      <td>18.138680</td>\n",
       "      <td>4.667863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.249207</td>\n",
       "      <td>3.474395</td>\n",
       "      <td>-8.984358</td>\n",
       "      <td>-0.376746</td>\n",
       "      <td>-0.109328</td>\n",
       "      <td>-0.973648</td>\n",
       "      <td>-0.517155</td>\n",
       "      <td>-0.874483</td>\n",
       "      <td>1.731065</td>\n",
       "      <td>-1.035889</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.643512</td>\n",
       "      <td>-0.790392</td>\n",
       "      <td>-0.618335</td>\n",
       "      <td>-0.867813</td>\n",
       "      <td>-0.511923</td>\n",
       "      <td>-0.051763</td>\n",
       "      <td>-0.037197</td>\n",
       "      <td>-1.013795</td>\n",
       "      <td>-0.182430</td>\n",
       "      <td>-0.776940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.982773</td>\n",
       "      <td>-0.731722</td>\n",
       "      <td>-0.233618</td>\n",
       "      <td>-1.028028</td>\n",
       "      <td>-0.039941</td>\n",
       "      <td>-3.289472</td>\n",
       "      <td>-0.523920</td>\n",
       "      <td>-0.893254</td>\n",
       "      <td>2.222820</td>\n",
       "      <td>-5.145839</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.850290</td>\n",
       "      <td>-0.682604</td>\n",
       "      <td>-0.501331</td>\n",
       "      <td>-0.501755</td>\n",
       "      <td>0.498033</td>\n",
       "      <td>0.866910</td>\n",
       "      <td>-0.387149</td>\n",
       "      <td>-0.931106</td>\n",
       "      <td>-0.156761</td>\n",
       "      <td>-0.656388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -2.506329 -8.853518  9.399597 -0.772311  0.077167 -0.898672 -1.880895   \n",
       "1 -0.492383  0.743671 -1.390057 -0.577119 -0.140470 -0.356033 -0.581103   \n",
       "2  0.076171  0.476095 -1.496893 -0.613497 -0.020490 -0.978051 -0.955439   \n",
       "3 -1.249207  3.474395 -8.984358 -0.376746 -0.109328 -0.973648 -0.517155   \n",
       "4 -0.982773 -0.731722 -0.233618 -1.028028 -0.039941 -3.289472 -0.523920   \n",
       "\n",
       "         7         8         9     ...           17        18        19  \\\n",
       "0  5.182326 -0.167279 -0.443091    ...    -1.186849 -0.819833 -0.664658   \n",
       "1 -1.194342 -0.907903 -0.045027    ...    -0.833394 -0.674255 -0.492840   \n",
       "2  1.337357  0.297091 -0.774588    ...    -5.354721 -0.674257 -0.492840   \n",
       "3 -0.874483  1.731065 -1.035889    ...    -0.643512 -0.790392 -0.618335   \n",
       "4 -0.893254  2.222820 -5.145839    ...    -0.850290 -0.682604 -0.501331   \n",
       "\n",
       "         20        21        22        23        24         25        26  \n",
       "0 -0.067670  0.688105 -0.505032 -0.118800 -1.300389  -0.288930 -1.291586  \n",
       "1 -0.482959 -0.511923 -0.051763 -0.037197 -1.013797  -0.182434 -0.776942  \n",
       "2 -0.482958 -0.511923 -0.051763 -0.037197  3.682249  18.138680  4.667863  \n",
       "3 -0.867813 -0.511923 -0.051763 -0.037197 -1.013795  -0.182430 -0.776940  \n",
       "4 -0.501755  0.498033  0.866910 -0.387149 -0.931106  -0.156761 -0.656388  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(183, 27)\n",
      "(183, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upsample the chokeHazard data, since the data is highly imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# concatenate our training data back together\n",
    "X = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "# separate minority and majority classes\n",
    "not_choke = X[X.target==0]\n",
    "choke = X[X.target==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(not_choke))\n",
    "print(len(choke))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# upsample minority\n",
    "choke_upsampled = resample(choke,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=len(not_choke), # match number in majority class\n",
    "                          random_state=27) # reproducible results\n",
    "\n",
    "# combine majority and upsampled minority\n",
    "upsampled = pd.concat([choke_upsampled, not_choke])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    163\n",
       "0    163\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upsampled.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = upsampled.target\n",
    "X_train = upsampled.drop('target', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(326, 27)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define method to evaluate Machine Learning models with the X and y vectors created above, and check the effectiveness of each. Also store the results in array to be plotted in graph for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import time\n",
    "def benchmark(clf):\n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "    print(len(X_train))\n",
    "    \n",
    "    clf_descr = str(clf).split('(')[0]\n",
    "    print(\"model name:\"+clf_descr)\n",
    "  \n",
    "    a = datetime.now()\n",
    "    \n",
    "    if clf_descr.__contains__('tensorflow'):\n",
    "        history = clf.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            epochs=epochs,\n",
    "            callbacks=callbacks,\n",
    "            validation_data=(X_test, y_test),\n",
    "            verbose=2, \n",
    "            batch_size=batch_size)\n",
    "    else:\n",
    "        clf.fit(X_train, y_train)\n",
    "    \n",
    "    b = datetime.now()\n",
    "    c = a-b\n",
    "    train_time = c.microseconds\n",
    "    print(\"train time: %0.3fs\" % train_time)\n",
    "\n",
    "    pred = clf.predict(X_test)\n",
    "\n",
    "    pred_train = clf.predict(X_train)\n",
    " \n",
    "    if clf_descr.__contains__('tensorflow'):\n",
    "        for i in range (len(pred)):\n",
    "            if (pred[i]>=0.3):\n",
    "                pred[i]=1\n",
    "            else:\n",
    "                pred[i]=0\n",
    "        for i in range (len(pred_train)):        \n",
    "            if (pred_train[i]>=0.3):\n",
    "                pred_train[i]=1\n",
    "            else:\n",
    "                pred_train[i]=0\n",
    "    \n",
    "    f1_score = metrics.f1_score(y_test, pred)\n",
    "    print(\"f1_score:   %0.3f\" % f1_score )\n",
    "    \n",
    "    f1_score_train = metrics.f1_score(y_train, pred_train)\n",
    "    print(\"f1_score_train:   %0.3f\" % f1_score_train )\n",
    "    \n",
    "    print(\"classification report:\")\n",
    "    print(classification_report(y_test, pred))\n",
    "    \n",
    "    print(\"confusion matrix:\")\n",
    "    print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "    if hasattr(clf, 'coef_'):\n",
    "        print(\"dimensionality: %d\" % clf.coef_.shape[1])\n",
    "        print(\"density: %f\" % density(clf.coef_))\n",
    "\n",
    "    \n",
    "    return clf_descr,f1_score_train,f1_score,train_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>-1.242172</td>\n",
       "      <td>3.792236</td>\n",
       "      <td>-5.078493</td>\n",
       "      <td>-0.389853</td>\n",
       "      <td>0.131318</td>\n",
       "      <td>-1.089417</td>\n",
       "      <td>-0.581103</td>\n",
       "      <td>-1.194342</td>\n",
       "      <td>-0.907903</td>\n",
       "      <td>-1.758093</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.638756</td>\n",
       "      <td>-0.511806</td>\n",
       "      <td>-0.110708</td>\n",
       "      <td>32.134876</td>\n",
       "      <td>-0.511923</td>\n",
       "      <td>-0.051763</td>\n",
       "      <td>-0.037197</td>\n",
       "      <td>-1.013795</td>\n",
       "      <td>-0.182430</td>\n",
       "      <td>-0.776940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>-1.902015</td>\n",
       "      <td>47.553791</td>\n",
       "      <td>32.448292</td>\n",
       "      <td>-0.408145</td>\n",
       "      <td>-0.039019</td>\n",
       "      <td>-0.842341</td>\n",
       "      <td>-0.581103</td>\n",
       "      <td>-1.194342</td>\n",
       "      <td>-0.907903</td>\n",
       "      <td>-1.046373</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.417060</td>\n",
       "      <td>-0.682604</td>\n",
       "      <td>-0.501331</td>\n",
       "      <td>-0.501755</td>\n",
       "      <td>0.353809</td>\n",
       "      <td>0.289212</td>\n",
       "      <td>0.258957</td>\n",
       "      <td>-2.096767</td>\n",
       "      <td>-5.078238</td>\n",
       "      <td>17.058996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>-0.198973</td>\n",
       "      <td>2.254661</td>\n",
       "      <td>-3.531561</td>\n",
       "      <td>0.969510</td>\n",
       "      <td>-1.673032</td>\n",
       "      <td>-0.787432</td>\n",
       "      <td>-0.581103</td>\n",
       "      <td>-1.194342</td>\n",
       "      <td>-0.907903</td>\n",
       "      <td>-1.767947</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.949459</td>\n",
       "      <td>-0.682604</td>\n",
       "      <td>-0.501331</td>\n",
       "      <td>-0.501755</td>\n",
       "      <td>-0.511923</td>\n",
       "      <td>-0.051763</td>\n",
       "      <td>-0.037197</td>\n",
       "      <td>8.250135</td>\n",
       "      <td>-1.065094</td>\n",
       "      <td>0.024022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>-0.958635</td>\n",
       "      <td>6.474957</td>\n",
       "      <td>3.097427</td>\n",
       "      <td>-0.393431</td>\n",
       "      <td>-0.090166</td>\n",
       "      <td>-0.892454</td>\n",
       "      <td>-0.581103</td>\n",
       "      <td>-1.194342</td>\n",
       "      <td>-0.907903</td>\n",
       "      <td>-0.825640</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.417060</td>\n",
       "      <td>-0.519530</td>\n",
       "      <td>-0.490489</td>\n",
       "      <td>-0.458934</td>\n",
       "      <td>0.353809</td>\n",
       "      <td>0.289212</td>\n",
       "      <td>0.258957</td>\n",
       "      <td>-2.096767</td>\n",
       "      <td>-5.078238</td>\n",
       "      <td>17.058996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>-0.197694</td>\n",
       "      <td>-0.279491</td>\n",
       "      <td>-0.807181</td>\n",
       "      <td>-0.364738</td>\n",
       "      <td>-0.028272</td>\n",
       "      <td>-0.722509</td>\n",
       "      <td>-0.581103</td>\n",
       "      <td>-1.194342</td>\n",
       "      <td>-0.907903</td>\n",
       "      <td>-0.685282</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.688346</td>\n",
       "      <td>-0.682604</td>\n",
       "      <td>-0.501331</td>\n",
       "      <td>-0.501755</td>\n",
       "      <td>0.498033</td>\n",
       "      <td>0.866910</td>\n",
       "      <td>-0.387149</td>\n",
       "      <td>-0.931106</td>\n",
       "      <td>-0.156761</td>\n",
       "      <td>-0.656388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1          2         3         4         5         6   \\\n",
       "177 -1.242172   3.792236  -5.078493 -0.389853  0.131318 -1.089417 -0.581103   \n",
       "71  -1.902015  47.553791  32.448292 -0.408145 -0.039019 -0.842341 -0.581103   \n",
       "153 -0.198973   2.254661  -3.531561  0.969510 -1.673032 -0.787432 -0.581103   \n",
       "62  -0.958635   6.474957   3.097427 -0.393431 -0.090166 -0.892454 -0.581103   \n",
       "144 -0.197694  -0.279491  -0.807181 -0.364738 -0.028272 -0.722509 -0.581103   \n",
       "\n",
       "           7         8         9     ...            17        18        19  \\\n",
       "177 -1.194342 -0.907903 -1.758093    ...     -0.638756 -0.511806 -0.110708   \n",
       "71  -1.194342 -0.907903 -1.046373    ...     -1.417060 -0.682604 -0.501331   \n",
       "153 -1.194342 -0.907903 -1.767947    ...     -0.949459 -0.682604 -0.501331   \n",
       "62  -1.194342 -0.907903 -0.825640    ...     -1.417060 -0.519530 -0.490489   \n",
       "144 -1.194342 -0.907903 -0.685282    ...     -0.688346 -0.682604 -0.501331   \n",
       "\n",
       "            20        21        22        23        24        25         26  \n",
       "177  32.134876 -0.511923 -0.051763 -0.037197 -1.013795 -0.182430  -0.776940  \n",
       "71   -0.501755  0.353809  0.289212  0.258957 -2.096767 -5.078238  17.058996  \n",
       "153  -0.501755 -0.511923 -0.051763 -0.037197  8.250135 -1.065094   0.024022  \n",
       "62   -0.458934  0.353809  0.289212  0.258957 -2.096767 -5.078238  17.058996  \n",
       "144  -0.501755  0.498033  0.866910 -0.387149 -0.931106 -0.156761  -0.656388  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Machine Learning Models from a List (using the reusable method defined above). Store the results (Accuracy score - train, accuracy score - test, and training time) in a List for data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "Training: \n",
      "326\n",
      "model name:Pipeline\n",
      "train time: 982236.000s\n",
      "f1_score:   0.556\n",
      "f1_score_train:   0.768\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89        41\n",
      "          1       0.38      1.00      0.56         5\n",
      "\n",
      "avg / total       0.93      0.83      0.86        46\n",
      "\n",
      "confusion matrix:\n",
      "[[33  8]\n",
      " [ 0  5]]\n",
      "================================================================================\n",
      "Ridge Classifier\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "326\n",
      "model name:RidgeClassifier\n",
      "train time: 990499.000s\n",
      "f1_score:   0.556\n",
      "f1_score_train:   0.768\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89        41\n",
      "          1       0.38      1.00      0.56         5\n",
      "\n",
      "avg / total       0.93      0.83      0.86        46\n",
      "\n",
      "confusion matrix:\n",
      "[[33  8]\n",
      " [ 0  5]]\n",
      "dimensionality: 27\n",
      "density: 1.000000\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "326\n",
      "model name:Pipeline\n",
      "train time: 991494.000s\n",
      "f1_score:   0.500\n",
      "f1_score_train:   0.967\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.90      0.92        41\n",
      "          1       0.43      0.60      0.50         5\n",
      "\n",
      "avg / total       0.89      0.87      0.88        46\n",
      "\n",
      "confusion matrix:\n",
      "[[37  4]\n",
      " [ 2  3]]\n",
      "================================================================================\n",
      "Perceptron\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "326\n",
      "model name:Perceptron\n",
      "train time: 997998.000s\n",
      "f1_score:   0.500\n",
      "f1_score_train:   0.967\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.90      0.92        41\n",
      "          1       0.43      0.60      0.50         5\n",
      "\n",
      "avg / total       0.89      0.87      0.88        46\n",
      "\n",
      "confusion matrix:\n",
      "[[37  4]\n",
      " [ 2  3]]\n",
      "dimensionality: 27\n",
      "density: 1.000000\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "326\n",
      "model name:Pipeline\n",
      "train time: 993000.000s\n",
      "f1_score:   0.600\n",
      "f1_score_train:   0.951\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.95      0.95        41\n",
      "          1       0.60      0.60      0.60         5\n",
      "\n",
      "avg / total       0.91      0.91      0.91        46\n",
      "\n",
      "confusion matrix:\n",
      "[[39  2]\n",
      " [ 2  3]]\n",
      "================================================================================\n",
      "Passive-Aggressive\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "326\n",
      "model name:PassiveAggressiveClassifier\n",
      "train time: 995491.000s\n",
      "f1_score:   0.600\n",
      "f1_score_train:   0.985\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.95      0.95        41\n",
      "          1       0.60      0.60      0.60         5\n",
      "\n",
      "avg / total       0.91      0.91      0.91        46\n",
      "\n",
      "confusion matrix:\n",
      "[[39  2]\n",
      " [ 2  3]]\n",
      "dimensionality: 27\n",
      "density: 1.000000\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "326\n",
      "model name:Pipeline\n",
      "train time: 992199.000s\n",
      "f1_score:   0.833\n",
      "f1_score_train:   0.956\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.95      0.97        41\n",
      "          1       0.71      1.00      0.83         5\n",
      "\n",
      "avg / total       0.97      0.96      0.96        46\n",
      "\n",
      "confusion matrix:\n",
      "[[39  2]\n",
      " [ 0  5]]\n",
      "================================================================================\n",
      "kNN\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "326\n",
      "model name:KNeighborsClassifier\n",
      "train time: 998025.000s\n",
      "f1_score:   0.833\n",
      "f1_score_train:   0.956\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.95      0.97        41\n",
      "          1       0.71      1.00      0.83         5\n",
      "\n",
      "avg / total       0.97      0.96      0.96        46\n",
      "\n",
      "confusion matrix:\n",
      "[[39  2]\n",
      " [ 0  5]]\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "326\n",
      "model name:Pipeline\n",
      "train time: 650996.000s\n",
      "f1_score:   0.889\n",
      "f1_score_train:   1.000\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99        41\n",
      "          1       1.00      0.80      0.89         5\n",
      "\n",
      "avg / total       0.98      0.98      0.98        46\n",
      "\n",
      "confusion matrix:\n",
      "[[41  0]\n",
      " [ 1  4]]\n",
      "================================================================================\n",
      "Random forest\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "326\n",
      "model name:RandomForestClassifier\n",
      "train time: 649058.000s\n",
      "f1_score:   1.000\n",
      "f1_score_train:   1.000\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        41\n",
      "          1       1.00      1.00      1.00         5\n",
      "\n",
      "avg / total       1.00      1.00      1.00        46\n",
      "\n",
      "confusion matrix:\n",
      "[[41  0]\n",
      " [ 0  5]]\n",
      "================================================================================\n",
      "L2 penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "326\n",
      "model name:LinearSVC\n",
      "train time: 919850.000s\n",
      "f1_score:   0.750\n",
      "f1_score_train:   0.991\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.98        41\n",
      "          1       1.00      0.60      0.75         5\n",
      "\n",
      "avg / total       0.96      0.96      0.95        46\n",
      "\n",
      "confusion matrix:\n",
      "[[41  0]\n",
      " [ 2  3]]\n",
      "dimensionality: 27\n",
      "density: 1.000000\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "326\n",
      "model name:SGDClassifier\n",
      "train time: 998001.000s\n",
      "f1_score:   0.545\n",
      "f1_score_train:   0.919\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.93      0.94        41\n",
      "          1       0.50      0.60      0.55         5\n",
      "\n",
      "avg / total       0.90      0.89      0.90        46\n",
      "\n",
      "confusion matrix:\n",
      "[[38  3]\n",
      " [ 2  3]]\n",
      "dimensionality: 27\n",
      "density: 1.000000\n",
      "================================================================================\n",
      "L1 penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "326\n",
      "model name:LinearSVC\n",
      "train time: 921866.000s\n",
      "f1_score:   0.800\n",
      "f1_score_train:   0.994\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.98      0.98        41\n",
      "          1       0.80      0.80      0.80         5\n",
      "\n",
      "avg / total       0.96      0.96      0.96        46\n",
      "\n",
      "confusion matrix:\n",
      "[[40  1]\n",
      " [ 1  4]]\n",
      "dimensionality: 27\n",
      "density: 0.888889\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "326\n",
      "model name:SGDClassifier\n",
      "train time: 0.000s\n",
      "f1_score:   0.600\n",
      "f1_score_train:   0.991\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.95      0.95        41\n",
      "          1       0.60      0.60      0.60         5\n",
      "\n",
      "avg / total       0.91      0.91      0.91        46\n",
      "\n",
      "confusion matrix:\n",
      "[[39  2]\n",
      " [ 2  3]]\n",
      "dimensionality: 27\n",
      "density: 1.000000\n",
      "================================================================================\n",
      "Elastic-Net penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "326\n",
      "model name:SGDClassifier\n",
      "train time: 984340.000s\n",
      "f1_score:   0.571\n",
      "f1_score_train:   0.905\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.88      0.92        41\n",
      "          1       0.44      0.80      0.57         5\n",
      "\n",
      "avg / total       0.92      0.87      0.88        46\n",
      "\n",
      "confusion matrix:\n",
      "[[36  5]\n",
      " [ 1  4]]\n",
      "dimensionality: 27\n",
      "density: 0.962963\n",
      "================================================================================\n",
      "NearestCentroid (aka Rocchio classifier)\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "326\n",
      "model name:NearestCentroid\n",
      "train time: 0.000s\n",
      "f1_score:   0.333\n",
      "f1_score_train:   0.601\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95        41\n",
      "          1       1.00      0.20      0.33         5\n",
      "\n",
      "avg / total       0.92      0.91      0.89        46\n",
      "\n",
      "confusion matrix:\n",
      "[[41  0]\n",
      " [ 4  1]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "selector = SelectKBest(f_classif, k='all')\n",
    "results = []\n",
    "model_name = []\n",
    "\n",
    "for clf, name in (\n",
    "        (RidgeClassifier(tol=1e-2, solver=\"lsqr\"), \"Ridge Classifier\"),\n",
    "        (Perceptron(n_iter=50), \"Perceptron\"),\n",
    "        (PassiveAggressiveClassifier(n_iter=50), \"Passive-Aggressive\"),\n",
    "        (KNeighborsClassifier(n_neighbors=5), \"kNN\"),\n",
    "        (RandomForestClassifier(n_estimators=100), \"Random forest\")):\n",
    "    selector_clf = benchmark(Pipeline([('selector', selector),('classifier', clf)]))\n",
    "    print('=' * 80)\n",
    "    print(name)\n",
    "    results.append(benchmark(clf))\n",
    "    model_name.append(name)\n",
    "    #model.append(clf)\n",
    "    \n",
    "for penalty in [\"l2\", \"l1\"]:\n",
    "    print('=' * 80)\n",
    "    print(\"%s penalty\" % penalty.upper())\n",
    "    # Train Liblinear model\n",
    "    results.append(benchmark(LinearSVC(loss='l2', penalty=penalty,dual=False, tol=1e-3)))\n",
    "    model_name.append(\"LinearSVC\"+\" \"+penalty)\n",
    "\n",
    "    # Train SGD model\n",
    "    results.append(benchmark(SGDClassifier(alpha=.0001, n_iter=50,penalty=penalty)))\n",
    "    model_name.append(\"SGDClassifier\"+\" \"+penalty)\n",
    "\n",
    "\n",
    "# Train SGD with Elastic Net penalty\n",
    "print('=' * 80)\n",
    "print(\"Elastic-Net penalty\")\n",
    "results.append(benchmark(SGDClassifier(alpha=.0001, n_iter=50,penalty=\"elasticnet\")))\n",
    "model_name.append(\"SGD with Elastic Net penalty\")\n",
    "\n",
    "\n",
    "# Train NearestCentroid without threshold\n",
    "print('=' * 80)\n",
    "print(\"NearestCentroid (aka Rocchio classifier)\")\n",
    "results.append(benchmark(NearestCentroid()))\n",
    "model_name.append(\"NearestCentroid (aka Rocchio classifier)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Neural Network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mlp_model(layers, units, dropout_rate, input_shape):\n",
    "    \"\"\"Creates an instance of a multi-layer perceptron model.\n",
    "\n",
    "    # Arguments\n",
    "        layers: int, number of `Dense` layers in the model.\n",
    "        units: int, output dimension of the layers.\n",
    "        dropout_rate: float, percentage of input to drop at Dropout layers.\n",
    "        input_shape: tuple, shape of input to the model.\n",
    "\n",
    "    # Returns\n",
    "        An MLP model instance.\n",
    "    \"\"\"\n",
    "    model = models.Sequential()\n",
    "    model.add(Dropout(rate=dropout_rate, input_shape=input_shape))\n",
    "\n",
    "    for _ in range(layers-1):\n",
    "        model.add(Dense(units=units, activation='relu'))\n",
    "        model.add(Dropout(rate=dropout_rate))\n",
    "\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0828 06:00:56.787626 11088 deprecation.py:506] From C:\\Users\\09263248\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0828 06:00:57.025050 11088 deprecation.py:323] From C:\\Users\\09263248\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dropout (Dropout)            (None, 27)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                1792      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 1,857\n",
      "Trainable params: 1,857\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "learning_rate=1e-3\n",
    "epochs=100\n",
    "batch_size=128\n",
    "layers=2\n",
    "units=64\n",
    "dropout_rate=0.2\n",
    "model = mlp_model(layers=layers,units=units,dropout_rate=dropout_rate,input_shape=X_train.shape[1:])\n",
    "optimizer = tf.keras.optimizers.Adam(lr=learning_rate)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['acc'])\n",
    "callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)]\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model and store results in array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Keras Dense Neural Network\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "326\n",
      "model name:<tensorflow.python.keras.engine.sequential.Sequential object at 0x000001A8401A99B0>\n",
      "Train on 326 samples, validate on 46 samples\n",
      "Epoch 1/100\n",
      "326/326 - 0s - loss: 1.4179 - acc: 0.5245 - val_loss: 1.8084 - val_acc: 0.3478\n",
      "Epoch 2/100\n",
      "326/326 - 0s - loss: 1.1811 - acc: 0.5644 - val_loss: 1.6191 - val_acc: 0.3478\n",
      "Epoch 3/100\n",
      "326/326 - 0s - loss: 0.9673 - acc: 0.6135 - val_loss: 1.4402 - val_acc: 0.3696\n",
      "Epoch 4/100\n",
      "326/326 - 0s - loss: 0.9842 - acc: 0.6012 - val_loss: 1.2700 - val_acc: 0.4130\n",
      "Epoch 5/100\n",
      "326/326 - 0s - loss: 0.9281 - acc: 0.6288 - val_loss: 1.1182 - val_acc: 0.5000\n",
      "Epoch 6/100\n",
      "326/326 - 0s - loss: 0.7991 - acc: 0.6319 - val_loss: 0.9876 - val_acc: 0.5435\n",
      "Epoch 7/100\n",
      "326/326 - 0s - loss: 0.7095 - acc: 0.6503 - val_loss: 0.8745 - val_acc: 0.6304\n",
      "Epoch 8/100\n",
      "326/326 - 0s - loss: 0.6639 - acc: 0.6748 - val_loss: 0.7776 - val_acc: 0.6522\n",
      "Epoch 9/100\n",
      "326/326 - 0s - loss: 0.5825 - acc: 0.7055 - val_loss: 0.6995 - val_acc: 0.8261\n",
      "Epoch 10/100\n",
      "326/326 - 0s - loss: 0.7081 - acc: 0.7209 - val_loss: 0.6345 - val_acc: 0.8478\n",
      "Epoch 11/100\n",
      "326/326 - 0s - loss: 0.5450 - acc: 0.7546 - val_loss: 0.5728 - val_acc: 0.9130\n",
      "Epoch 12/100\n",
      "326/326 - 0s - loss: 0.5060 - acc: 0.7577 - val_loss: 0.5178 - val_acc: 0.9348\n",
      "Epoch 13/100\n",
      "326/326 - 0s - loss: 0.4792 - acc: 0.8006 - val_loss: 0.4681 - val_acc: 0.9348\n",
      "Epoch 14/100\n",
      "326/326 - 0s - loss: 0.5308 - acc: 0.7485 - val_loss: 0.4235 - val_acc: 0.9348\n",
      "Epoch 15/100\n",
      "326/326 - 0s - loss: 0.3913 - acc: 0.8098 - val_loss: 0.3937 - val_acc: 0.9565\n",
      "Epoch 16/100\n",
      "326/326 - 0s - loss: 0.4244 - acc: 0.7791 - val_loss: 0.3732 - val_acc: 0.9565\n",
      "Epoch 17/100\n",
      "326/326 - 0s - loss: 0.4533 - acc: 0.7822 - val_loss: 0.3549 - val_acc: 0.9565\n",
      "Epoch 18/100\n",
      "326/326 - 0s - loss: 0.5034 - acc: 0.7607 - val_loss: 0.3387 - val_acc: 0.9565\n",
      "Epoch 19/100\n",
      "326/326 - 0s - loss: 0.3635 - acc: 0.8221 - val_loss: 0.3263 - val_acc: 0.9565\n",
      "Epoch 20/100\n",
      "326/326 - 0s - loss: 0.3779 - acc: 0.8129 - val_loss: 0.3138 - val_acc: 0.9565\n",
      "Epoch 21/100\n",
      "326/326 - 0s - loss: 0.4171 - acc: 0.7914 - val_loss: 0.3020 - val_acc: 0.9565\n",
      "Epoch 22/100\n",
      "326/326 - 0s - loss: 0.3938 - acc: 0.8221 - val_loss: 0.2931 - val_acc: 0.9565\n",
      "Epoch 23/100\n",
      "326/326 - 0s - loss: 0.3779 - acc: 0.8098 - val_loss: 0.2843 - val_acc: 0.9565\n",
      "Epoch 24/100\n",
      "326/326 - 0s - loss: 0.3439 - acc: 0.8252 - val_loss: 0.2753 - val_acc: 0.9565\n",
      "Epoch 25/100\n",
      "326/326 - 0s - loss: 0.3112 - acc: 0.8558 - val_loss: 0.2674 - val_acc: 0.9565\n",
      "Epoch 26/100\n",
      "326/326 - 0s - loss: 0.3223 - acc: 0.8405 - val_loss: 0.2613 - val_acc: 0.9565\n",
      "Epoch 27/100\n",
      "326/326 - 0s - loss: 0.3675 - acc: 0.8221 - val_loss: 0.2548 - val_acc: 0.9565\n",
      "Epoch 28/100\n",
      "326/326 - 0s - loss: 0.3406 - acc: 0.8313 - val_loss: 0.2491 - val_acc: 0.9565\n",
      "Epoch 29/100\n",
      "326/326 - 0s - loss: 0.3245 - acc: 0.8405 - val_loss: 0.2445 - val_acc: 0.9565\n",
      "Epoch 30/100\n",
      "326/326 - 0s - loss: 0.3719 - acc: 0.8282 - val_loss: 0.2372 - val_acc: 0.9565\n",
      "Epoch 31/100\n",
      "326/326 - 0s - loss: 0.3225 - acc: 0.8681 - val_loss: 0.2317 - val_acc: 0.9565\n",
      "Epoch 32/100\n",
      "326/326 - 0s - loss: 0.3041 - acc: 0.8589 - val_loss: 0.2265 - val_acc: 0.9565\n",
      "Epoch 33/100\n",
      "326/326 - 0s - loss: 0.3042 - acc: 0.8773 - val_loss: 0.2215 - val_acc: 0.9565\n",
      "Epoch 34/100\n",
      "326/326 - 0s - loss: 0.3059 - acc: 0.8558 - val_loss: 0.2165 - val_acc: 0.9565\n",
      "Epoch 35/100\n",
      "326/326 - 0s - loss: 0.3020 - acc: 0.8865 - val_loss: 0.2129 - val_acc: 0.9565\n",
      "Epoch 36/100\n",
      "326/326 - 0s - loss: 0.3220 - acc: 0.8528 - val_loss: 0.2095 - val_acc: 0.9565\n",
      "Epoch 37/100\n",
      "326/326 - 0s - loss: 0.3289 - acc: 0.8528 - val_loss: 0.2055 - val_acc: 0.9783\n",
      "Epoch 38/100\n",
      "326/326 - 0s - loss: 0.3084 - acc: 0.8620 - val_loss: 0.2012 - val_acc: 0.9783\n",
      "Epoch 39/100\n",
      "326/326 - 0s - loss: 0.2843 - acc: 0.8742 - val_loss: 0.1978 - val_acc: 1.0000\n",
      "Epoch 40/100\n",
      "326/326 - 0s - loss: 0.2739 - acc: 0.8896 - val_loss: 0.1930 - val_acc: 1.0000\n",
      "Epoch 41/100\n",
      "326/326 - 0s - loss: 0.3192 - acc: 0.8466 - val_loss: 0.1902 - val_acc: 1.0000\n",
      "Epoch 42/100\n",
      "326/326 - 0s - loss: 0.2808 - acc: 0.8650 - val_loss: 0.1871 - val_acc: 1.0000\n",
      "Epoch 43/100\n",
      "326/326 - 0s - loss: 0.3061 - acc: 0.8528 - val_loss: 0.1840 - val_acc: 1.0000\n",
      "Epoch 44/100\n",
      "326/326 - 0s - loss: 0.2745 - acc: 0.8681 - val_loss: 0.1808 - val_acc: 1.0000\n",
      "Epoch 45/100\n",
      "326/326 - 0s - loss: 0.2959 - acc: 0.8773 - val_loss: 0.1779 - val_acc: 1.0000\n",
      "Epoch 46/100\n",
      "326/326 - 0s - loss: 0.3514 - acc: 0.8374 - val_loss: 0.1750 - val_acc: 1.0000\n",
      "Epoch 47/100\n",
      "326/326 - 0s - loss: 0.2673 - acc: 0.8804 - val_loss: 0.1722 - val_acc: 1.0000\n",
      "Epoch 48/100\n",
      "326/326 - 0s - loss: 0.2900 - acc: 0.8558 - val_loss: 0.1696 - val_acc: 1.0000\n",
      "Epoch 49/100\n",
      "326/326 - 0s - loss: 0.2564 - acc: 0.8589 - val_loss: 0.1662 - val_acc: 1.0000\n",
      "Epoch 50/100\n",
      "326/326 - 0s - loss: 0.2898 - acc: 0.8374 - val_loss: 0.1625 - val_acc: 1.0000\n",
      "Epoch 51/100\n",
      "326/326 - 0s - loss: 0.2814 - acc: 0.8804 - val_loss: 0.1589 - val_acc: 1.0000\n",
      "Epoch 52/100\n",
      "326/326 - 0s - loss: 0.2725 - acc: 0.8742 - val_loss: 0.1567 - val_acc: 1.0000\n",
      "Epoch 53/100\n",
      "326/326 - 0s - loss: 0.2614 - acc: 0.8804 - val_loss: 0.1550 - val_acc: 1.0000\n",
      "Epoch 54/100\n",
      "326/326 - 0s - loss: 0.2390 - acc: 0.9110 - val_loss: 0.1534 - val_acc: 1.0000\n",
      "Epoch 55/100\n",
      "326/326 - 0s - loss: 0.2788 - acc: 0.8773 - val_loss: 0.1512 - val_acc: 1.0000\n",
      "Epoch 56/100\n",
      "326/326 - 0s - loss: 0.3059 - acc: 0.8528 - val_loss: 0.1488 - val_acc: 1.0000\n",
      "Epoch 57/100\n",
      "326/326 - 0s - loss: 0.2688 - acc: 0.8896 - val_loss: 0.1466 - val_acc: 1.0000\n",
      "Epoch 58/100\n",
      "326/326 - 0s - loss: 0.2500 - acc: 0.8742 - val_loss: 0.1450 - val_acc: 1.0000\n",
      "Epoch 59/100\n",
      "326/326 - 0s - loss: 0.2801 - acc: 0.8712 - val_loss: 0.1426 - val_acc: 1.0000\n",
      "Epoch 60/100\n",
      "326/326 - 0s - loss: 0.2491 - acc: 0.8865 - val_loss: 0.1408 - val_acc: 1.0000\n",
      "Epoch 61/100\n",
      "326/326 - 0s - loss: 0.2841 - acc: 0.8620 - val_loss: 0.1402 - val_acc: 1.0000\n",
      "Epoch 62/100\n",
      "326/326 - 0s - loss: 0.2671 - acc: 0.8620 - val_loss: 0.1392 - val_acc: 1.0000\n",
      "Epoch 63/100\n",
      "326/326 - 0s - loss: 0.2742 - acc: 0.8650 - val_loss: 0.1377 - val_acc: 1.0000\n",
      "Epoch 64/100\n",
      "326/326 - 0s - loss: 0.2657 - acc: 0.8957 - val_loss: 0.1364 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      "326/326 - 0s - loss: 0.2464 - acc: 0.8773 - val_loss: 0.1349 - val_acc: 1.0000\n",
      "Epoch 66/100\n",
      "326/326 - 0s - loss: 0.2946 - acc: 0.8742 - val_loss: 0.1333 - val_acc: 1.0000\n",
      "Epoch 67/100\n",
      "326/326 - 0s - loss: 0.2526 - acc: 0.8865 - val_loss: 0.1330 - val_acc: 1.0000\n",
      "Epoch 68/100\n",
      "326/326 - 0s - loss: 0.2384 - acc: 0.8988 - val_loss: 0.1325 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      "326/326 - 0s - loss: 0.2835 - acc: 0.8865 - val_loss: 0.1325 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      "326/326 - 0s - loss: 0.2573 - acc: 0.8773 - val_loss: 0.1324 - val_acc: 1.0000\n",
      "Epoch 71/100\n",
      "326/326 - 0s - loss: 0.2332 - acc: 0.9141 - val_loss: 0.1330 - val_acc: 1.0000\n",
      "Epoch 72/100\n",
      "326/326 - 0s - loss: 0.2538 - acc: 0.8896 - val_loss: 0.1331 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      "326/326 - 0s - loss: 0.2544 - acc: 0.8926 - val_loss: 0.1341 - val_acc: 1.0000\n",
      "train time: 370470.000s\n",
      "f1_score:   0.556\n",
      "f1_score_train:   0.891\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89        41\n",
      "          1       0.38      1.00      0.56         5\n",
      "\n",
      "avg / total       0.93      0.83      0.86        46\n",
      "\n",
      "confusion matrix:\n",
      "[[33  8]\n",
      " [ 0  5]]\n"
     ]
    }
   ],
   "source": [
    "print('=' * 80)\n",
    "print(\"Keras Dense Neural Network\")\n",
    "results.append(benchmark(model))\n",
    "model_name.append(\"Keras Dense Neural Network\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the results from multiple Machine Learning Models (accuracy - train, accuracy - test, training time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuMAAAI1CAYAAAB8GvSWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a84339ff98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "indices = np.arange(len(results))\n",
    "\n",
    "results = [[x[i] for x in results] for i in range(4)]\n",
    "\n",
    "clf_names, f1_score_train, f1_score_test, training_time = results\n",
    "\n",
    "training_time = np.array(training_time) / np.max(training_time)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title(\"Score\")\n",
    "plt.barh(indices, f1_score_train, .2, label=\"f1_score_train\", color='r')\n",
    "plt.barh(indices+0.3, f1_score_test, .2, label=\"f1_score_test\", color='b')\n",
    "plt.barh(indices + .6, training_time, .2, label=\"training time\", color='g')\n",
    "plt.yticks(())\n",
    "plt.legend(loc='best')\n",
    "plt.subplots_adjust(left=.25)\n",
    "plt.subplots_adjust(top=.95)\n",
    "plt.subplots_adjust(bottom=.05)\n",
    "\n",
    "for i, c in zip(indices, model_name):\n",
    "    plt.text(-.3, i, c)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The above results show the Precision and Accuracy of the 'Yes' cases is maximum with RandomForestClassifier , after taking 3 components in PCA, with StandardScaler."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
