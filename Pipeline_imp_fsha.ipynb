{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ngram_range_inp=(1,2)\n",
    "filename = \"D:/Pepsico/input_data_1.xlsx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exclude = set(string.punctuation) \n",
    "wpt = nltk.WordPunctTokenizer()\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "newStopWords = ['from']\n",
    "stop_words.extend(newStopWords)\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "porter = PorterStemmer()\n",
    "\n",
    "def normalize_document(doc):\n",
    "    # tokenize document\n",
    "    tokens = doc.split()\n",
    "    # remove punctuation from each word\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "    # convert to lower case\n",
    "    lower_tokens = [w.lower() for w in tokens]\n",
    "    #remove spaces\n",
    "    stripped = [w.strip() for w in lower_tokens]\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    words = [word for word in stripped if word.isalpha()]\n",
    "    # filter stopwords out of document\n",
    "    filtered_tokens = [token for token in words if token not in stop_words]\n",
    "    # re-create document from filtered tokens\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "    return doc\n",
    "\n",
    "normalize_corpus = np.vectorize(normalize_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vectorization parameters\n",
    "\n",
    "# Range (inclusive) of n-gram sizes for tokenizing text.\n",
    "NGRAM_RANGE = ngram_range_inp\n",
    "\n",
    "# Limit on the number of features. We use the top 20K features.\n",
    "TOP_K = 20000\n",
    "\n",
    "# Whether text should be split into word or character n-grams.\n",
    "# One of 'word', 'char'.\n",
    "TOKEN_MODE = 'word'\n",
    "\n",
    "# Minimum document/corpus frequency below which a token will be discarded.\n",
    "MIN_DOCUMENT_FREQUENCY = 2\n",
    "\n",
    "# Limit on the length of text sequences. Sequences longer than this\n",
    "# will be truncated.\n",
    "MAX_SEQUENCE_LENGTH = 500\n",
    "\n",
    "\n",
    "def ngram_vectorize(train_texts, train_labels):\n",
    "    \"\"\"Vectorizes texts as ngram vectors.\n",
    "\n",
    "    1 text = 1 tf-idf vector the length of vocabulary of uni-grams + bi-grams.\n",
    "\n",
    "    # Arguments\n",
    "        train_texts: list, training text strings.\n",
    "        train_labels: np.ndarray, training labels.\n",
    "        val_texts: list, validation text strings.\n",
    "\n",
    "    # Returns\n",
    "        x_train, x_val: vectorized training and validation texts\n",
    "    \"\"\"\n",
    "    # Create keyword arguments to pass to the 'tf-idf' vectorizer.\n",
    "    kwargs = {\n",
    "            'ngram_range': NGRAM_RANGE,  # Use 1-grams + 2-grams.\n",
    "            'dtype': 'int32',\n",
    "            'strip_accents': 'unicode',\n",
    "            'decode_error': 'replace',\n",
    "            'analyzer': TOKEN_MODE,  # Split text into word tokens.\n",
    "            'min_df': MIN_DOCUMENT_FREQUENCY,\n",
    "    }\n",
    "    vectorizer = TfidfVectorizer(**kwargs)\n",
    "\n",
    "    # Learn vocabulary from training texts and vectorize training texts.\n",
    "    x_train = vectorizer.fit_transform(train_texts)\n",
    "\n",
    "    # Vectorize validation texts.\n",
    "    #x_val = vectorizer.transform(val_texts)\n",
    "\n",
    "    # Select top 'k' of the vectorized features.\n",
    "    #selector = SelectKBest(f_classif, k=min(TOP_K, x_train.shape[1]))\n",
    "    #selector.fit(x_train, train_labels)\n",
    "    #x_train = selector.transform(x_train)\n",
    "    #x_val = selector.transform(x_val)\n",
    "\n",
    "    x_train = x_train.astype('float32')\n",
    "    #x_val = x_val.astype('float32')\n",
    "    return x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fsha_data = pd.read_excel(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fsha_data= fsha_data.rename(columns={' pH': 'pH'})\n",
    "fsha_data= fsha_data.rename(columns={' otherFSA': 'otherFSA'})\n",
    "fsha_data= fsha_data.rename(columns={' targetMarket': 'targetMarket'})\n",
    "fsha_data= fsha_data.rename(columns={' newIngradient': 'newIngredient'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model preparation (taking few features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframe_model = fsha_data[['preservatives', 'pH', 'waterActivity', 'packaging', 'otherFSA', 'allergens', \n",
    "             'prod_storageDist', 'foodSafety_prodClaims', 'targetMarket', 'newIngredient']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = dataframe_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preservatives</th>\n",
       "      <th>pH</th>\n",
       "      <th>waterActivity</th>\n",
       "      <th>packaging</th>\n",
       "      <th>otherFSA</th>\n",
       "      <th>allergens</th>\n",
       "      <th>prod_storageDist</th>\n",
       "      <th>foodSafety_prodClaims</th>\n",
       "      <th>targetMarket</th>\n",
       "      <th>newIngredient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E262 Sodium acetates (i) Sodium acetate (ii) S...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Base allergens: None\\nTop seasoning: Milk\\nCro...</td>\n",
       "      <td>ambient</td>\n",
       "      <td>No preservatives</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Base allergens: None\\nTop seasoning: Milk, Glu...</td>\n",
       "      <td>ambient</td>\n",
       "      <td>No preservatives</td>\n",
       "      <td>no</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adhesive laminate with no Nitrogen flushing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wheat Gluten</td>\n",
       "      <td>Store in a cool dry place at ambient temperature</td>\n",
       "      <td>No claims made</td>\n",
       "      <td>Small pieces can be a choke hazard, Not suitab...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>not present in seasoning</td>\n",
       "      <td>not known yet for reformulated seasoning - exi...</td>\n",
       "      <td>Max 5% in seasoning, FP aim 1,8% and max 2,2%</td>\n",
       "      <td>Packed in a protective atmosphere</td>\n",
       "      <td>None</td>\n",
       "      <td>milk, Soya, Barley</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>no</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Pellet (&lt;0.6), Finished Product (&lt;0.15)</td>\n",
       "      <td>Nitrogen flushed?</td>\n",
       "      <td>Moisture Content of Pellet : 10 - 12 %</td>\n",
       "      <td>Inherent:\\nCheddar Playz: Cereals containing G...</td>\n",
       "      <td>Ambient</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Suitable for consumers, potential choking haza...</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>None</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Pellet (&lt;0.6), Finished Product (&lt;0.15)</td>\n",
       "      <td>Pellet WIP packaging not N2 flushed. 6 month s...</td>\n",
       "      <td>Moisture Content of Pellet : 10 - 12 %</td>\n",
       "      <td>Pellets Inherent:\\nCereals containing Gluten -...</td>\n",
       "      <td>Ambient</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Suitable for consumers, potential choking haza...</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Low</td>\n",
       "      <td>Lays is nitrogen flushed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Standard allergen management for Seasoning. Th...</td>\n",
       "      <td>RTE</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes, no change to current product</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>None</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>low moisture food</td>\n",
       "      <td>no modified atmosphere</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>Allergens in seasonings:\\nCQ69 Vegetable Blend...</td>\n",
       "      <td>Store in a dry, cool and away from sun place.</td>\n",
       "      <td>claim 1 \"from corn\"\\nclaim 2 \"not fried\"\\nclai...</td>\n",
       "      <td>People with allergies to milk, lactose, peanuts.</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>E262 Sodium acetates (i) Sodium acetate (ii) S...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>low, approximately 0,04</td>\n",
       "      <td>nitrogen flushed bags</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Inherent\\n\\nParmesan Cheese &amp; Roasted Garlic B...</td>\n",
       "      <td>ambient</td>\n",
       "      <td>50% less fat comparing to fried potato chips</td>\n",
       "      <td>no</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>May be in topping/seasoning ingredients TBC fi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Low water activity</td>\n",
       "      <td>Packaging conditions TBC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Inherent - Wheat, Gluten, Sulphites, Soya, Mil...</td>\n",
       "      <td>N/A ambient</td>\n",
       "      <td>Allergen suffers. Made in a factory that handl...</td>\n",
       "      <td>Allergen suffers. Made in a factory that handl...</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       preservatives  \\\n",
       "0  E262 Sodium acetates (i) Sodium acetate (ii) S...   \n",
       "1                                                NaN   \n",
       "2                                               None   \n",
       "3                           not present in seasoning   \n",
       "4                                               None   \n",
       "5                                               None   \n",
       "6                                                NaN   \n",
       "7                                               None   \n",
       "8  E262 Sodium acetates (i) Sodium acetate (ii) S...   \n",
       "9  May be in topping/seasoning ingredients TBC fi...   \n",
       "\n",
       "                                                  pH  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  not known yet for reformulated seasoning - exi...   \n",
       "4                                               n/a    \n",
       "5                                               n/a    \n",
       "6                                                NaN   \n",
       "7                                     Not applicable   \n",
       "8                                                NaN   \n",
       "9                                                NaN   \n",
       "\n",
       "                                   waterActivity  \\\n",
       "0                                            low   \n",
       "1                                            low   \n",
       "2                                            NaN   \n",
       "3  Max 5% in seasoning, FP aim 1,8% and max 2,2%   \n",
       "4        Pellet (<0.6), Finished Product (<0.15)   \n",
       "5        Pellet (<0.6), Finished Product (<0.15)   \n",
       "6                                            Low   \n",
       "7                              low moisture food   \n",
       "8                        low, approximately 0,04   \n",
       "9                             Low water activity   \n",
       "\n",
       "                                           packaging  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2        Adhesive laminate with no Nitrogen flushing   \n",
       "3                  Packed in a protective atmosphere   \n",
       "4                                  Nitrogen flushed?   \n",
       "5  Pellet WIP packaging not N2 flushed. 6 month s...   \n",
       "6                           Lays is nitrogen flushed   \n",
       "7                             no modified atmosphere   \n",
       "8                              nitrogen flushed bags   \n",
       "9                           Packaging conditions TBC   \n",
       "\n",
       "                                 otherFSA  \\\n",
       "0                                     NaN   \n",
       "1                                     NaN   \n",
       "2                                     NaN   \n",
       "3                                    None   \n",
       "4  Moisture Content of Pellet : 10 - 12 %   \n",
       "5  Moisture Content of Pellet : 10 - 12 %   \n",
       "6                                     NaN   \n",
       "7                          Not applicable   \n",
       "8                                     NaN   \n",
       "9                                     NaN   \n",
       "\n",
       "                                           allergens  \\\n",
       "0  Base allergens: None\\nTop seasoning: Milk\\nCro...   \n",
       "1  Base allergens: None\\nTop seasoning: Milk, Glu...   \n",
       "2                                       Wheat Gluten   \n",
       "3                                 milk, Soya, Barley   \n",
       "4  Inherent:\\nCheddar Playz: Cereals containing G...   \n",
       "5  Pellets Inherent:\\nCereals containing Gluten -...   \n",
       "6  Standard allergen management for Seasoning. Th...   \n",
       "7  Allergens in seasonings:\\nCQ69 Vegetable Blend...   \n",
       "8  Inherent\\n\\nParmesan Cheese & Roasted Garlic B...   \n",
       "9  Inherent - Wheat, Gluten, Sulphites, Soya, Mil...   \n",
       "\n",
       "                                   prod_storageDist  \\\n",
       "0                                           ambient   \n",
       "1                                           ambient   \n",
       "2  Store in a cool dry place at ambient temperature   \n",
       "3                                              none   \n",
       "4                                          Ambient    \n",
       "5                                          Ambient    \n",
       "6                                               RTE   \n",
       "7     Store in a dry, cool and away from sun place.   \n",
       "8                                           ambient   \n",
       "9                                       N/A ambient   \n",
       "\n",
       "                               foodSafety_prodClaims  \\\n",
       "0                                   No preservatives   \n",
       "1                                   No preservatives   \n",
       "2                                    No claims made    \n",
       "3                                               none   \n",
       "4                                               n/a    \n",
       "5                                               n/a    \n",
       "6                                               None   \n",
       "7  claim 1 \"from corn\"\\nclaim 2 \"not fried\"\\nclai...   \n",
       "8       50% less fat comparing to fried potato chips   \n",
       "9  Allergen suffers. Made in a factory that handl...   \n",
       "\n",
       "                                        targetMarket newIngredient  \n",
       "0                                                 No           Yes  \n",
       "1                                                 no           Yes  \n",
       "2  Small pieces can be a choke hazard, Not suitab...            No  \n",
       "3                                                 no            No  \n",
       "4  Suitable for consumers, potential choking haza...           Yes  \n",
       "5  Suitable for consumers, potential choking haza...           Yes  \n",
       "6                  Yes, no change to current product            No  \n",
       "7   People with allergies to milk, lactose, peanuts.           Yes  \n",
       "8                                                 no           Yes  \n",
       "9  Allergen suffers. Made in a factory that handl...           Yes  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-hot encoding of categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def categorical_encode(data):\n",
    "    #data = train_df['prod_storageDist']\n",
    "    values = array(data)\n",
    "    print(values)\n",
    "    # integer encode\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(values)\n",
    "    print(integer_encoded)\n",
    "    # binary encode\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "    print(onehot_encoded)\n",
    "    return onehot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Input for PCA (can be taken as cmd-line parameters)\n",
    "n_components = 2\n",
    "whiten = False\n",
    "random_state = 42\n",
    "svd_solver=\"full\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to pre process text data\n",
    "def preprocess_text(train_df,y):\n",
    "    storage_encoded = categorical_encode(train_df['prod_storageDist'])\n",
    "    norm_allergens = normalize_corpus(train_df['allergens'])\n",
    "    print(train_df['allergens'][0])\n",
    "    print(norm_allergens[0])\n",
    "    train_labels = y\n",
    "    print(storage_encoded.shape)\n",
    "    x_train = ngram_vectorize(norm_allergens, train_labels)\n",
    "    x_train=x_train.toarray()\n",
    "    print(x_train.shape)\n",
    "    pca = PCA(n_components=n_components,svd_solver=svd_solver,whiten=whiten, random_state=42)\n",
    "    x_pca = pca.fit_transform(x_train)\n",
    "    print(x_pca.shape)\n",
    "    x_train = np.concatenate((storage_encoded,x_pca),axis=1)\n",
    "    return x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert Yes/No labels in output to 1 or 0\n",
    "train_y=[]\n",
    "for i in range (len(fsha_data)):\n",
    "    if fsha_data[\"potentialMicrobial\"][i] =='Yes':\n",
    "        train_y.append(1)\n",
    "    else:\n",
    "        train_y.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ambient' 'ambient' 'Store in a cool dry place at ambient temperature'\n",
      " 'none' 'Ambient ' 'Ambient ' 'RTE'\n",
      " 'Store in a dry, cool and away from sun place.' 'ambient' 'N/A ambient']\n",
      "[5 5 3 6 0 0 2 4 5 1]\n",
      "[[0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]]\n",
      "Base allergens: None\n",
      "Top seasoning: Milk\n",
      "Cross-contact (Suadiye): Gluten, Peanuts, Soya\n",
      "Cross-contact (Tarsus): Gluten (Wheat, Barley), Peanuts, Soya\n",
      "base allergens none top seasoning milk crosscontact suadiye gluten peanuts soya crosscontact tarsus gluten wheat barley peanuts soya\n",
      "(10, 7)\n",
      "(10, 51)\n",
      "(10, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\103467\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "x_train = preprocess_text(train_df,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 9)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 0, 0, 1, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Data Pipeline to select best features and run Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selector = SelectKBest(f_classif, k=10)\n",
    "clf = svm.SVC(kernel='linear')\n",
    "selector_svm = Pipeline([('selector', selector), ('svc', clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\103467\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('selector', SelectKBest(k=5, score_func=<function f_classif at 0x0000000011C22510>)), ('svc', SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector_svm.set_params(selector__k=5, svc__C=.1).fit(x_train, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit ML Models from a List and print / save the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = [\"Ridge Classifier\", \"Linear SVC\"]\n",
    "\n",
    "classifiers = [\n",
    "    RidgeClassifier(tol=1e-2, solver=\"lsqr\"),\n",
    "    svm.SVC(kernel='linear')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = x_train,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 9)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datasets = [(X,y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 9)\n",
      "(1, 9)\n",
      "0.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for ds_cnt, ds in enumerate(datasets):\n",
    "    # preprocess dataset, split into training and test part\n",
    "    X, y = ds\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.1, random_state=42)\n",
    "    print(X_train.shape)\n",
    "    print(X_test.shape)\n",
    "     # iterate over classifiers\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        #ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "        clf.fit(X_train, y_train)\n",
    "        score = clf.score(X_test, y_test)\n",
    "        scores.append(score)\n",
    "        print(score)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index=np.argmax(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best classifier is:Linear SVC\n"
     ]
    }
   ],
   "source": [
    "print(\"Best classifier is:\"+names[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def benchmark_models(clf):\n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "    #print(clf)\n",
    "\n",
    "    clf.fit(x_train, y)\n",
    "\n",
    "    pred = clf.predict(x_train)\n",
    "\n",
    "    score = metrics.f1_score(y, pred)\n",
    "    print(\"accuracy:   %0.3f\" % score)\n",
    "\n",
    "    #clf_descr = str(clf).split('(')[0]\n",
    "    return  clf,score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Ridge Classifier\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "accuracy:   0.000\n",
      "================================================================================\n",
      "Support Vector Classifier\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "accuracy:   0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\103467\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "models=[]\n",
    "for clf, name in (\n",
    "     (RidgeClassifier(tol=1e-2, solver=\"lsqr\"), \"Ridge Classifier\"),\n",
    "        (svm.SVC(kernel='linear'), \"Support Vector Classifier\") ):\n",
    "    print('=' * 80)\n",
    "    print(name)\n",
    "    model,score = benchmark_models(clf)\n",
    "    models.append(model)\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
       "         max_iter=None, normalize=False, random_state=None, solver='lsqr',\n",
       "         tol=0.01), SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "   decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "   max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "   tol=0.001, verbose=False)]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the best model for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models[0]\n",
    "filename = 'D:/Pepsico/finalized_model.sav'\n",
    "pickle.dump(models[0], open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n"
     ]
    }
   ],
   "source": [
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.score(x_train, y)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
